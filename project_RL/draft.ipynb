{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyjoystick.sdl2 import Key, Joystick, run_event_loop\n",
    "from pprint import pprint\n",
    "from threading import Thread\n",
    "import time\n",
    "import serial\n",
    "from sklearn import linear_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set blue thresh\n",
    "lower_green = np.array([35,70,60])\n",
    "upper_green = np.array([120,255,255])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx = 1, fy = 1, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    # edges = cv2.Canny(mask, 100, 200)\n",
    "    cv2.imshow('green edges', mask)\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenpos0 = []\n",
    "greenpos1 = []\n",
    "for (index0,liste) in enumerate(edges):\n",
    "    for (index1,value) in enumerate(liste):\n",
    "        if value == 255:\n",
    "            greenpos0.append(index0)\n",
    "            greenpos1.append(index1)\n",
    "            # print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit(np.array(greenpos0).reshape(-1, 1), np.array(greenpos1).reshape(-1, 1))\n",
    "\n",
    "line_X = np.arange(min(greenpos0), max(greenpos0) + 1)[:, np.newaxis]\n",
    "line_y = ransac.predict(line_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (4.8, 6.4))\n",
    "# plt.xlim((0, 480))\n",
    "# plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(np.array(greenpos0).reshape(-1, 1)[inlier_mask], np.array(greenpos1).reshape(-1, 1)[inlier_mask], s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][-1,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][-1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][0,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Servo_t = [0, 29.85799098, 87.28123918, 49.99237628, 23.27381264], [54.25188891, 14.62139926, 51.21600907, 64.9204633, 113.30784031]\n",
    "\n",
    "A_t = [[-0.96566657, 0.49763318, 0.95705414, -0.62148105, -0.44530939], [0.90419815, -0.66050816, 0.60991016, 0.22840757, 0.80645628]]\n",
    "\n",
    "s_t = [[391, 402, 363, 365, 325], [360, 320, 441, 434, 471]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, 180))\n",
    "plt.ylim((0, 180))\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "print(ret)\n",
    "if ret :\n",
    "    print(ret)\n",
    "    cv2.imwrite('./first_frame.jpg', frame)\n",
    "    # cv2.imshow('test', frame)\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.npy', 'rb') as f:\n",
    "    Servo_t = np.load(f)\n",
    "    A_t = np.load(f)\n",
    "    s_t = np.load(f)\n",
    "    \n",
    "print(np.shape(Servo_t), np.shape(A_t), np.shape(s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[0, 0], s_t[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((-0.1, 180.1))\n",
    "plt.ylim((-0.1, 180.1))\n",
    "# plt.plot(Servo_t[0], Servo_t[1])\n",
    "plt.title('Servo angle inputs')\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(s_pos, target_pos):\n",
    "    # reward(s_t[:, 0], s_t[:, 1])\n",
    "    reward = np.linalg.norm(s_pos - target_pos)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(s_t[0, :]), max(s_t[0, :]), min(s_t[1, :]), max(s_t[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lis)\n",
    "episode = 10\n",
    "file_name = './img' + str(episode) + '.png'\n",
    "plt.savefig(file_name)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "tf.random.set_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(x_train), tf.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #第三步，models.Sequential()\n",
    "# model = tf.keras.models.Sequential([ #使用models.Sequential()来搭建神经网络\n",
    "#     tf.keras.layers.Dense(3, activation = \"softmax\", kernel_regularizer = tf.keras.regularizers.l2()) #全连接层，三个神经元，激活函数为softmax,使用l2正则化\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(irisModel, self).__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(3, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) #搭建网络块，这一层命名为d1\n",
    " \n",
    "    def call(self, x):\n",
    "        y = self.d1(x)\n",
    "        return  y\n",
    "\n",
    "model = irisModel()\n",
    "\n",
    "#第四步，model.compile()\n",
    "model.compile(  #使用model.compile()方法来配置训练方法\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1), #使用SGD优化器，学习率为0.1\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), #配置损失函数\n",
    "    metrics = ['sparse_categorical_accuracy'] #标注网络评价指标\n",
    ")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#第五步，model.fit()\n",
    "model.fit(  #使用model.fit()方法来执行训练过程，\n",
    "    x_train, y_train, #告知训练集的输入以及标签，\n",
    "    batch_size = 32, #每一批batch的大小为32，\n",
    "    epochs = 500, #迭代次数epochs为500\n",
    "    validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "    validation_freq = 20 #测试的间隔次数为20,每迭代20次测试一次准确率\n",
    ")\n",
    "\n",
    "#第六步，model.summary()\n",
    "model.summary() #打印神经网络结构，统计参数数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n",
      "value 0.6450147\n",
      "value -0.08118695\n",
      "value -0.23150498\n",
      "value -0.2319426\n",
      "value 0.59114623\n",
      "value -0.75850475\n",
      "value 0.3269378\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.2580397\n",
      "value -0.40707892\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.75803894\n",
      "value -0.23150408\n",
      "value 0.3095544\n",
      "value 0.26861793\n",
      "value -0.40707913\n",
      "value 0.323735\n",
      "value 0.3612615\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.5911461\n",
      "value 0.59114623\n",
      "value -0.7569668\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -1.4240078\n",
      "value 0.59114456\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.75861394\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.34505898\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.23149645\n",
      "value 0.32373512\n",
      "value -0.12266511\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26173222\n",
      "value 0.59114623\n",
      "value 0.11739713\n",
      "value 0.32373512\n",
      "value -0.6350396\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.3507497\n",
      "value 0.32373512\n",
      "value -0.23390377\n",
      "value -0.75853956\n",
      "value 0.24393946\n",
      "value 0.59107155\n",
      "value -0.2315048\n",
      "value 0.59114623\n",
      "value -0.40707892\n",
      "value 0.27229315\n",
      "value 0.59114623\n",
      "value 0.5911455\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23143107\n",
      "value -0.23150408\n",
      "value -0.0962643\n",
      "value 0.59114623\n",
      "value 0.24426359\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.6473147\n",
      "value -0.40707946\n",
      "value 0.59114623\n",
      "value -0.23150504\n",
      "value 0.59114623\n",
      "value -0.7583641\n",
      "value 0.32373512\n",
      "value 0.5757598\n",
      "value 0.59114623\n",
      "value 0.6472179\n",
      "value -0.39071947\n",
      "value -0.7139146\n",
      "value -0.75861144\n",
      "value 0.5833809\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.107035995\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.52131844\n",
      "value 0.5911359\n",
      "value 0.32373518\n",
      "value -0.23150408\n",
      "value 0.32400388\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4062937\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.66696143\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.74986315\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.3999202\n",
      "value 0.32373512\n",
      "value -0.18752253\n",
      "value -0.23150408\n",
      "value 0.25695825\n",
      "value 0.32373506\n",
      "value -0.23150408\n",
      "value -0.4070795\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.28266996\n",
      "value 0.59114623\n",
      "value 0.5450496\n",
      "value 0.2617566\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75832164\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.059395492\n",
      "value 0.5911342\n",
      "value 0.25877017\n",
      "value -0.23150408\n",
      "value -0.23494434\n",
      "value 0.19940478\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.23992169\n",
      "value 0.59114623\n",
      "value 0.58896184\n",
      "value -0.23150337\n",
      "value 0.59114623\n",
      "value -1.589718\n",
      "value 0.20189095\n",
      "value -0.23150593\n",
      "value 0.32373512\n",
      "value -1.4327105\n",
      "value 0.5911486\n",
      "value 0.59114623\n",
      "value 0.5889333\n",
      "value 0.59114623\n",
      "value 0.64043075\n",
      "value 0.25154275\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.113301694\n",
      "value 0.59114623\n",
      "value 0.32374704\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4070737\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114635\n",
      "value 0.32373542\n",
      "value 0.32373512\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150426\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.1442657\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32043058\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24398506\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707007\n",
      "value 0.59114623\n",
      "value -0.66847324\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23568809\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59062207\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.8216504\n",
      "value 0.32373512\n",
      "value -0.6521405\n",
      "value 0.59114623\n",
      "value -0.53595084\n",
      "value -1.4218881\n",
      "value 0.59081745\n",
      "value 0.59114623\n",
      "value -0.40707096\n",
      "value -0.236976\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.434478\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26322567\n",
      "value 0.59114623\n",
      "value -1.4240083\n",
      "value 0.3238485\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150402\n",
      "value 0.59114623\n",
      "value -0.40707037\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.7586123\n",
      "value 0.59114623\n",
      "value 0.39807868\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114015\n",
      "value 0.3171935\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4241072\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.323736\n",
      "value -1.4240799\n",
      "value 0.3237363\n",
      "value 0.58790904\n",
      "value 0.32373512\n",
      "value -0.23160172\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373494\n",
      "value -0.40564996\n",
      "value 0.26937127\n",
      "value 0.2519045\n",
      "value 0.59114623\n",
      "value -0.758268\n",
      "value -1.1093247\n",
      "value -0.23150408\n",
      "value -0.4057059\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.323735\n",
      "value 0.59114623\n",
      "value 0.3237365\n",
      "value 0.26171857\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.16182947\n",
      "value -0.23150408\n",
      "value 0.32151467\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.75861496\n",
      "value -0.5814961\n",
      "value -0.23147768\n",
      "value -0.7585298\n",
      "value 0.32373512\n",
      "value 0.19288534\n",
      "value 0.32373512\n",
      "value -0.16298017\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.5911555\n",
      "value -0.7585528\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.58732164\n",
      "value 0.16817391\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32374054\n",
      "value 0.59114623\n",
      "value -0.46500602\n",
      "value -0.65090376\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.4238759\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.38684246\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.4455415\n",
      "value 0.6261557\n",
      "value 0.5828347\n",
      "value -1.4268783\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59023607\n",
      "value 0.59114623\n",
      "value -0.0017516017\n",
      "value 0.5911459\n",
      "value 0.32373512\n",
      "value -0.75823355\n",
      "value 0.59114623\n",
      "value 0.32373524\n",
      "value 0.2532575\n",
      "value 0.59114623\n",
      "value -0.4070786\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75850165\n",
      "value 0.3394912\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.31911927\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -1.425225\n",
      "value 0.32375956\n",
      "value 0.59114623\n",
      "value -0.7303878\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.34235758\n",
      "value 0.59114623\n",
      "value -0.7586142\n",
      "value 0.32373512\n",
      "value -0.3896213\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.33313137\n",
      "value -1.8681086\n",
      "value 0.32373512\n",
      "value -0.7554165\n",
      "value 0.32373512\n",
      "value -0.47229713\n",
      "value 0.32373512\n",
      "value 0.5880114\n",
      "value 0.59114623\n",
      "value 0.64724827\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.7065061\n",
      "value -0.23150408\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.58265936\n",
      "value 0.64730424\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4638419\n",
      "value -1.4243534\n",
      "value 0.038555026\n",
      "value 0.59114623\n",
      "value -1.424041\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40392858\n",
      "value 0.59116817\n",
      "value 0.3237363\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.2618587\n",
      "value 0.25407785\n",
      "value 0.59114623\n",
      "value -0.23141533\n",
      "value 0.59114623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from DQ_Learning import DQNet\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with open('/home/mig5/Desktop/TR_DATA_RL/minibatch.npy', 'rb') as f:\n",
    "    minibatch = np.load(f, allow_pickle=True)\n",
    "    # experience = np.load(f, allow_pickle=True)\n",
    "\n",
    "print(np.shape(minibatch))\n",
    "DQL = DQNet()\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for (i, mini) in enumerate(minibatch):\n",
    "    value_ = DQL.get_best(mini[4], mini[1], get_action = False)\n",
    "    y_train.append(mini[3] + 0.99*value_)\n",
    "    x_train.append([mini[0][0], mini[0][1], mini[1][0], mini[1][1], mini[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 43911.7266 - mae: 176.4142\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42961.1797 - mae: 173.7402\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42080.9453 - mae: 171.3190\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41160.9570 - mae: 168.7957\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40261.5469 - mae: 166.3499\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39397.1562 - mae: 164.0227\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38555.3516 - mae: 161.7339\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37745.5469 - mae: 159.5746\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36959.1992 - mae: 157.4209\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36196.5859 - mae: 155.3671\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35456.2969 - mae: 153.3706\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34741.6836 - mae: 151.3696\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34054.5664 - mae: 149.5234\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33389.0234 - mae: 147.7420\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32739.8125 - mae: 145.9564\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32113.7520 - mae: 144.2499\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31504.3945 - mae: 142.6024\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30918.2520 - mae: 140.9837\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30350.4199 - mae: 139.4577\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29796.1758 - mae: 137.9017\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 29262.9941 - mae: 136.5036\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28744.3262 - mae: 135.1614\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28243.4238 - mae: 133.8305\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27762.1973 - mae: 132.5893\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27288.8711 - mae: 131.3314\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26833.7852 - mae: 130.1387\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26390.3281 - mae: 128.9575\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25961.6270 - mae: 127.8116\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25542.4785 - mae: 126.7358\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25139.7949 - mae: 125.7031\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24753.1953 - mae: 124.6935\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24377.3809 - mae: 123.7041\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24010.1055 - mae: 122.7384\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23652.1953 - mae: 121.7681\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 23309.6621 - mae: 120.8753\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22984.3965 - mae: 120.0311\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22663.7969 - mae: 119.1545\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22350.9238 - mae: 118.3202\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22049.0117 - mae: 117.5426\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21755.6367 - mae: 116.7803\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21471.0957 - mae: 116.0459\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21195.8398 - mae: 115.3249\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20930.0957 - mae: 114.6576\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20656.1055 - mae: 113.8095\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20439.8809 - mae: 113.4058\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20202.4180 - mae: 112.8657\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19969.9160 - mae: 112.3102\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19741.5254 - mae: 111.7498\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19523.2656 - mae: 111.2243\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19313.2305 - mae: 110.6964\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19106.9570 - mae: 110.2009\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18907.6387 - mae: 109.7228\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18713.6836 - mae: 109.2450\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18525.6953 - mae: 108.8038\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18345.1855 - mae: 108.3715\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18168.9609 - mae: 107.9391\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17999.8125 - mae: 107.5385\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17835.6953 - mae: 107.1360\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17678.1680 - mae: 106.7698\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17521.2402 - mae: 106.4004\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17372.3281 - mae: 106.0484\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17228.3242 - mae: 105.7198\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17088.0938 - mae: 105.3729\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16953.1836 - mae: 105.0625\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16822.8848 - mae: 104.7572\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16697.7969 - mae: 104.4642\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16576.6523 - mae: 104.1864\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16457.0078 - mae: 103.8793\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16341.0762 - mae: 103.6008\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16227.4053 - mae: 103.3424\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16119.2041 - mae: 103.0879\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16013.0283 - mae: 102.8249\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15910.7812 - mae: 102.5746\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15812.1904 - mae: 102.3422\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15715.0186 - mae: 102.1018\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15625.0225 - mae: 101.8913\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15537.7480 - mae: 101.6930\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15451.4805 - mae: 101.5118\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15367.4824 - mae: 101.3332\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15287.9961 - mae: 101.1596\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15208.2461 - mae: 100.9981\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15132.9971 - mae: 100.8388\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15057.3477 - mae: 100.6724\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14985.3047 - mae: 100.5232\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14917.3076 - mae: 100.3893\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14850.8945 - mae: 100.2506\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14786.3232 - mae: 100.1163\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14724.0869 - mae: 99.9976\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14662.5088 - mae: 99.8798\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14602.9941 - mae: 99.7773\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14545.3027 - mae: 99.6595\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14490.1572 - mae: 99.5771\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14437.2793 - mae: 99.4644\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14385.7305 - mae: 99.3556\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14334.5850 - mae: 99.2675\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14287.1982 - mae: 99.1723\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14240.5811 - mae: 99.0847\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14195.4336 - mae: 98.9959\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14150.3662 - mae: 98.9082\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14107.4785 - mae: 98.8395\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14066.2529 - mae: 98.7546\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14024.7559 - mae: 98.6743\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13985.5186 - mae: 98.5993\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13948.5938 - mae: 98.5330\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13912.7305 - mae: 98.4716\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13877.5020 - mae: 98.4078\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13843.7812 - mae: 98.3567\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13811.6904 - mae: 98.2984\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13780.6494 - mae: 98.2401\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13750.2666 - mae: 98.1944\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13721.4121 - mae: 98.1309\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13691.6836 - mae: 98.1083\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13663.5195 - mae: 98.0451\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13635.7080 - mae: 98.0110\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13608.9502 - mae: 97.9599\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13584.3887 - mae: 97.9247\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13559.9717 - mae: 97.8857\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13535.0312 - mae: 97.8520\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13511.9658 - mae: 97.8063\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13488.9619 - mae: 97.7737\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13467.3164 - mae: 97.7442\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13445.4746 - mae: 97.7047\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13425.2266 - mae: 97.6733\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13405.6943 - mae: 97.6468\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13386.7412 - mae: 97.6331\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13368.7402 - mae: 97.5896\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13349.9209 - mae: 97.5778\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13332.5010 - mae: 97.5485\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13315.8271 - mae: 97.5351\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13299.0957 - mae: 97.5067\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13283.2832 - mae: 97.4858\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13267.3994 - mae: 97.4663\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13253.0977 - mae: 97.4526\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13238.8574 - mae: 97.4311\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13224.7422 - mae: 97.4064\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13211.6973 - mae: 97.3909\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13198.7090 - mae: 97.3757\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13185.8682 - mae: 97.3597\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13174.2832 - mae: 97.3407\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13161.3652 - mae: 97.3225\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13150.6152 - mae: 97.3138\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13140.3887 - mae: 97.2971\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13129.0098 - mae: 97.2807\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13118.6572 - mae: 97.2683\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13108.2197 - mae: 97.2591\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13098.9209 - mae: 97.2490\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13089.2891 - mae: 97.2336\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13080.3818 - mae: 97.2197\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13071.3359 - mae: 97.2106\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13062.1123 - mae: 97.1964\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13053.5723 - mae: 97.1840\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13045.5264 - mae: 97.1754\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13036.3174 - mae: 97.1606\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13028.9824 - mae: 97.1501\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13021.4990 - mae: 97.1424\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13013.9854 - mae: 97.1306\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13006.6924 - mae: 97.1232\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 13000.3799 - mae: 97.1110\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12994.0117 - mae: 97.1037\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12988.2891 - mae: 97.1053\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12982.2432 - mae: 97.0936\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12976.3750 - mae: 97.0865\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12970.6016 - mae: 97.0836\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12965.0225 - mae: 97.0777\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12959.6807 - mae: 97.0715\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12954.6914 - mae: 97.0634\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12949.2451 - mae: 97.0585\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12944.1797 - mae: 97.0509\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12939.5117 - mae: 97.0458\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12935.0918 - mae: 97.0402\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12930.9150 - mae: 97.0341\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12926.2275 - mae: 97.0299\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12922.2822 - mae: 97.0298\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12918.7451 - mae: 97.0231\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12914.8320 - mae: 97.0201\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12911.2529 - mae: 97.0153\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12908.0732 - mae: 97.0127\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12904.6660 - mae: 97.0110\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12901.0000 - mae: 97.0094\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12897.8789 - mae: 97.0044\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12894.3018 - mae: 97.0057\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12891.4170 - mae: 97.0055\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12888.7344 - mae: 97.0018\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12885.6885 - mae: 96.9992\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12882.9297 - mae: 96.9973\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12880.3838 - mae: 96.9991\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12877.5537 - mae: 96.9982\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12875.3291 - mae: 96.9968\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12872.6562 - mae: 96.9967\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12870.1846 - mae: 96.9968\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12867.9541 - mae: 96.9956\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12866.0137 - mae: 96.9947\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12863.9316 - mae: 96.9932\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12862.1211 - mae: 96.9939\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12859.9209 - mae: 96.9918\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12857.5908 - mae: 96.9921\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12855.6924 - mae: 96.9897\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12853.1709 - mae: 96.9921\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12851.2900 - mae: 96.9879\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12849.3672 - mae: 96.9933\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12847.5039 - mae: 96.9900\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12845.5840 - mae: 96.9931\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12843.8418 - mae: 96.9869\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12841.2891 - mae: 96.9866\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12838.1562 - mae: 96.9752\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12833.3584 - mae: 96.9588\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12821.6641 - mae: 96.8969\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12837.2031 - mae: 96.9827\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12835.1719 - mae: 96.9797\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12832.3662 - mae: 96.9691\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12828.9785 - mae: 96.9509\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12823.3281 - mae: 96.9384\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12809.4717 - mae: 96.8384\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12794.8379 - mae: 96.7787\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12784.7607 - mae: 96.7216\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12774.8916 - mae: 96.6588\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12762.3223 - mae: 96.6092\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12760.8291 - mae: 96.6059\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12752.9980 - mae: 96.5644\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12751.1602 - mae: 96.5434\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12746.2412 - mae: 96.5375\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12744.8076 - mae: 96.5232\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12742.5537 - mae: 96.5309\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12739.5186 - mae: 96.5376\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12737.6797 - mae: 96.4874\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12737.4648 - mae: 96.5092\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12734.6445 - mae: 96.5124\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12733.4648 - mae: 96.5102\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.9443 - mae: 96.5047\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.5928 - mae: 96.4891\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12729.6426 - mae: 96.4856\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.6123 - mae: 96.5007\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.2490 - mae: 96.5000\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12726.3975 - mae: 96.4878\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12725.3057 - mae: 96.4958\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12724.5117 - mae: 96.4895\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12723.5938 - mae: 96.4988\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12722.6602 - mae: 96.4967\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12721.8887 - mae: 96.4935\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.5713 - mae: 96.5011\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.0352 - mae: 96.4894\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.9492 - mae: 96.4952\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.5996 - mae: 96.4958\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12717.9990 - mae: 96.5001\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.0654 - mae: 96.4934\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12716.5537 - mae: 96.4929\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12715.8887 - mae: 96.5011\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12715.2773 - mae: 96.4966\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.9326 - mae: 96.4978\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3428 - mae: 96.5058\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.9482 - mae: 96.4988\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.2080 - mae: 96.5036\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.5029 - mae: 96.5034\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.2031 - mae: 96.4985\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.8027 - mae: 96.4996\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.4209 - mae: 96.5063\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.1797 - mae: 96.5032\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.3789 - mae: 96.5049\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.1426 - mae: 96.5090\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12709.7217 - mae: 96.5018\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12709.3320 - mae: 96.5066\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12709.0068 - mae: 96.5094\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12708.6973 - mae: 96.5108\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12708.6836 - mae: 96.5112\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.8203 - mae: 96.5104\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.5918 - mae: 96.5138\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.4395 - mae: 96.5164\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.2002 - mae: 96.5185\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.9561 - mae: 96.5224\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.0156 - mae: 96.5172\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12705.8750 - mae: 96.5197\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.5098 - mae: 96.5191\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.6611 - mae: 96.5244\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.3096 - mae: 96.5179\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.8604 - mae: 96.5241\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.9004 - mae: 96.5270\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.2715 - mae: 96.5250\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.3672 - mae: 96.5320\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.1592 - mae: 96.5285\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.8555 - mae: 96.5293\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.6934 - mae: 96.5327\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.3857 - mae: 96.5334\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1631 - mae: 96.5354\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1123 - mae: 96.5319\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8857 - mae: 96.5339\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.7695 - mae: 96.5359\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8047 - mae: 96.5374\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3965 - mae: 96.5324\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.5371 - mae: 96.5414\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3857 - mae: 96.5419\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3721 - mae: 96.5393\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.0371 - mae: 96.5386\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.9082 - mae: 96.5440\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4941 - mae: 96.5416\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4326 - mae: 96.5407\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.5996 - mae: 96.5454\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.3867 - mae: 96.5460\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12701.4404 - mae: 96.5454\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.9082 - mae: 96.5460\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.0137 - mae: 96.5482\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.7109 - mae: 96.5471\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5501\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.6436 - mae: 96.5535\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5527\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.5430 - mae: 96.5557\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.2900 - mae: 96.5569\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.1016 - mae: 96.5510\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12700.0576 - mae: 96.5565\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9326 - mae: 96.5559\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.0088 - mae: 96.5583\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9141 - mae: 96.5558\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.5293 - mae: 96.5592\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6016 - mae: 96.5632\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.7227 - mae: 96.5628\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6914 - mae: 96.5625\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.4219 - mae: 96.5609\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.3857 - mae: 96.5603\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.5098 - mae: 96.5665\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.5947 - mae: 96.5647\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.4619 - mae: 96.5663\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1182 - mae: 96.5664\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.0762 - mae: 96.5675\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1240 - mae: 96.5691\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.9414 - mae: 96.5683\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7988 - mae: 96.5675\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.7480 - mae: 96.5697\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7266 - mae: 96.5693\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7402 - mae: 96.5702\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.6602 - mae: 96.5683\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.5059 - mae: 96.5703\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7832 - mae: 96.5713\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7559 - mae: 96.5734\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7783 - mae: 96.5760\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3975 - mae: 96.5749\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2959 - mae: 96.5753\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4893 - mae: 96.5785\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3916 - mae: 96.5777\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.2676 - mae: 96.5737\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4551 - mae: 96.5769\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0908 - mae: 96.5749\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2539 - mae: 96.5765\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1836 - mae: 96.5755\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2588 - mae: 96.5768\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2715 - mae: 96.5749\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1885 - mae: 96.5745\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3535 - mae: 96.5724\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1328 - mae: 96.5780\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0781 - mae: 96.5784\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9814 - mae: 96.5753\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2754 - mae: 96.5787\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1719 - mae: 96.5781\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1221 - mae: 96.5777\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4863 - mae: 96.5799\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9922 - mae: 96.5788\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1084 - mae: 96.5754\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8721 - mae: 96.5787\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2793 - mae: 96.5770\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9697 - mae: 96.5773\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3027 - mae: 96.5815\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0791 - mae: 96.5795\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1396 - mae: 96.5809\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6758 - mae: 96.5795\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6377 - mae: 96.5766\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8604 - mae: 96.5793\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6318 - mae: 96.5790\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1182 - mae: 96.5813\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9600 - mae: 96.5825\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7930 - mae: 96.5810\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7754 - mae: 96.5806\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0039 - mae: 96.5794\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8994 - mae: 96.5821\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8828 - mae: 96.5803\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9736 - mae: 96.5806\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1143 - mae: 96.5823\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0332 - mae: 96.5833\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9707 - mae: 96.5844\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7754 - mae: 96.5852\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.1230 - mae: 96.5833\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7314 - mae: 96.5817\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6465 - mae: 96.5794\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6846 - mae: 96.5824\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0215 - mae: 96.5842\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8096 - mae: 96.5829\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6533 - mae: 96.5827\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7207 - mae: 96.5809\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6992 - mae: 96.5833\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5322 - mae: 96.5853\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7832 - mae: 96.5892\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7451 - mae: 96.5853\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8984 - mae: 96.5893\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9404 - mae: 96.5885\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5400 - mae: 96.5857\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7656 - mae: 96.5895\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7373 - mae: 96.5890\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4033 - mae: 96.5882\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4980 - mae: 96.5880\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5723 - mae: 96.5876\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.4434 - mae: 96.5878\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6914 - mae: 96.5889\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6924 - mae: 96.5906\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5830 - mae: 96.5893\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4160 - mae: 96.5878\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6914 - mae: 96.5902\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5098 - mae: 96.5882\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8174 - mae: 96.5891\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5703 - mae: 96.5890\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5645 - mae: 96.5900\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6133 - mae: 96.5882\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4385 - mae: 96.5876\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2510 - mae: 96.5921\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4854 - mae: 96.5878\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5791 - mae: 96.5848\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5866\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4268 - mae: 96.5872\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5264 - mae: 96.5876\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.6689 - mae: 96.5905\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.8066 - mae: 96.5892\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6016 - mae: 96.5901\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4258 - mae: 96.5875\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12697.5361 - mae: 96.5904\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5566 - mae: 96.5901\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12697.2920 - mae: 96.5907\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3457 - mae: 96.5940\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.3418 - mae: 96.5917\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1260 - mae: 96.5914\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2939 - mae: 96.5923\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3262 - mae: 96.5932\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2480 - mae: 96.5914\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2959 - mae: 96.5928\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.2285 - mae: 96.5929\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4326 - mae: 96.5925\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5352 - mae: 96.5969\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5967\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5922\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7383 - mae: 96.5944\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5955\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2607 - mae: 96.5949\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6260 - mae: 96.5938\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1953 - mae: 96.5913\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4785 - mae: 96.5968\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6729 - mae: 96.5953\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3594 - mae: 96.5958\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2871 - mae: 96.5943\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3154 - mae: 96.5958\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4902 - mae: 96.5947\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5215 - mae: 96.5948\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3164 - mae: 96.5942\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5936\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5920\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5332 - mae: 96.5923\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3428 - mae: 96.5915\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1494 - mae: 96.5927\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3330 - mae: 96.5943\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1436 - mae: 96.5942\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1543 - mae: 96.5944\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.0996 - mae: 96.5930\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2627 - mae: 96.5943\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2861 - mae: 96.5932\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3096 - mae: 96.7425\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9707 - mae: 97.2263\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1328 - mae: 97.2280\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0820 - mae: 97.2281\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0918 - mae: 97.2267\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.2451 - mae: 97.2232\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0742 - mae: 97.2267\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1582 - mae: 97.2268\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0303 - mae: 97.2220\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9443 - mae: 97.2247\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0938 - mae: 97.2251\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8838 - mae: 97.2231\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1865 - mae: 97.2225\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9189 - mae: 97.2233\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0801 - mae: 97.2216\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0166 - mae: 97.2219\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9062 - mae: 97.2210\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1768 - mae: 97.2217\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12798.1816 - mae: 97.2213\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.8877 - mae: 97.2206\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0420 - mae: 97.2207\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7197 - mae: 97.2174\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9365 - mae: 97.2189\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7744 - mae: 97.2172\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0508 - mae: 97.2171\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7891 - mae: 97.2165\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7510 - mae: 97.2151\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12797.6504 - mae: 97.2126\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.6914 - mae: 97.2126\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7041 - mae: 97.2117\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9668 - mae: 97.2124\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.2080 - mae: 97.2113\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8975 - mae: 97.2141\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9854 - mae: 97.2146\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8623 - mae: 97.2117\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12797.8057 - mae: 97.2138\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7588 - mae: 97.2136\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8438 - mae: 97.2146\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8369 - mae: 97.2157\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8457 - mae: 97.2135\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.4336 - mae: 97.2147\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8789 - mae: 97.2152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48fdaea6a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"cp.ckpt\"\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "DQL.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "DQL.fit(np.array(x_train),\n",
    "        np.array(y_train),\n",
    "        epochs=500)\n",
    "# DQL.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.get_best(mini[4], mini[1], get_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 16.2087 - mae: 16.2087 - 169ms/epoch - 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from DQ_Learning import DQNet\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_path = \"/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model\"\n",
    "model = DQNet()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "            loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "            metrics = 'mae')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(np.array(x_train), np.array(y_train), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3584353.2500 - mae: 3584353.2500\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 266493520.0000 - mae: 266493520.0000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 154.0703 - mae: 154.0703\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 114.6900 - mae: 114.6900\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.4900 - mae: 114.4900\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.2900 - mae: 114.2900\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 114.0900 - mae: 114.0900\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 113.8900 - mae: 113.8900\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.6900 - mae: 113.6900\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.4900 - mae: 113.4900\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.2900 - mae: 113.2900\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 113.0900 - mae: 113.0900\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.8900 - mae: 112.8900\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.6900 - mae: 112.6900\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 112.4900 - mae: 112.4900\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 112.2900 - mae: 112.2900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.0900 - mae: 112.0900\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.8900 - mae: 111.8900\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.6900 - mae: 111.6900\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 111.4900 - mae: 111.4900 - val_loss: 115.6637 - val_mae: 115.6637\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 111.2900 - mae: 111.2900\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 111.0900 - mae: 111.0900\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.8900 - mae: 110.8900\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 110.6900 - mae: 110.6900\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.4900 - mae: 110.4900\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 110.2900 - mae: 110.2900\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.0900 - mae: 110.0900\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.8900 - mae: 109.8900\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.6900 - mae: 109.6900\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 109.4900 - mae: 109.4900\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.2900 - mae: 109.2900\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.0900 - mae: 109.0900\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 108.8900 - mae: 108.8900\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.6900 - mae: 108.6900\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 108.4900 - mae: 108.4900\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.2900 - mae: 108.2900\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.0900 - mae: 108.0900\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 107.8900 - mae: 107.8900\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 107.6900 - mae: 107.6900\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 107.4900 - mae: 107.4900 - val_loss: 111.6637 - val_mae: 111.6637\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.2900 - mae: 107.2900\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.0900 - mae: 107.0900\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.8900 - mae: 106.8900\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.6900 - mae: 106.6900\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 106.4900 - mae: 106.4900\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.2900 - mae: 106.2900\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.0900 - mae: 106.0900\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.8900 - mae: 105.8900\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.6900 - mae: 105.6900\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 105.4900 - mae: 105.4900\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.2900 - mae: 105.2900\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.0900 - mae: 105.0900\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.8900 - mae: 104.8900\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.6900 - mae: 104.6900\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.4900 - mae: 104.4900\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 104.2900 - mae: 104.2900\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 104.0900 - mae: 104.0900\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.8900 - mae: 103.8900\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 103.6900 - mae: 103.6900\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 103.4900 - mae: 103.4900 - val_loss: 107.6637 - val_mae: 107.6637\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.2900 - mae: 103.2900\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.0899 - mae: 103.0899\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.8900 - mae: 102.8900\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 102.6899 - mae: 102.6899\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.4899 - mae: 102.4899\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.2899 - mae: 102.2899\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 102.0899 - mae: 102.0899\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.8899 - mae: 101.8899\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.6899 - mae: 101.6899\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.4899 - mae: 101.4899\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 101.2899 - mae: 101.2899\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.0899 - mae: 101.0899\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.8899 - mae: 100.8899\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 100.6899 - mae: 100.6899\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.4899 - mae: 100.4899\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.2899 - mae: 100.2899\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.0899 - mae: 100.0899\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.8899 - mae: 99.8899\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.6899 - mae: 99.6899\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 99.4899 - mae: 99.4899 - val_loss: 103.6637 - val_mae: 103.6637\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.2899 - mae: 99.2899\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.0899 - mae: 99.0899\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.8899 - mae: 98.8899\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 98.6899 - mae: 98.6899\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.4899 - mae: 98.4899\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.2899 - mae: 98.2899\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.0899 - mae: 98.0899\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.8899 - mae: 97.8899\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 97.6899 - mae: 97.6899\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.4899 - mae: 97.4899\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.2899 - mae: 97.2899\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.0899 - mae: 97.0899\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 96.8899 - mae: 96.8899\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.6899 - mae: 96.6899\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 96.4899 - mae: 96.4899\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.2899 - mae: 96.2899\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.0899 - mae: 96.0899\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.8899 - mae: 95.8899\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.6899 - mae: 95.6899\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 95.4899 - mae: 95.4899 - val_loss: 99.6637 - val_mae: 99.6637\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.2899 - mae: 95.2899\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 95.0899 - mae: 95.0899\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.8899 - mae: 94.8899\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.6899 - mae: 94.6899\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.4899 - mae: 94.4899\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 94.2899 - mae: 94.2899\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.0899 - mae: 94.0899\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.8899 - mae: 93.8899\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.6899 - mae: 93.6899\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.4899 - mae: 93.4899\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.2899 - mae: 93.2899\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.0899 - mae: 93.0899\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 92.8899 - mae: 92.8899\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.6899 - mae: 92.6899\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.4899 - mae: 92.4899\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.2899 - mae: 92.2899\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 92.0899 - mae: 92.0899\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 91.8899 - mae: 91.8899\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 91.6899 - mae: 91.6899\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 91.4899 - mae: 91.4899 - val_loss: 95.6637 - val_mae: 95.6637\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 91.2899 - mae: 91.2899\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 91.0899 - mae: 91.0899\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 90.8899 - mae: 90.8899\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.6899 - mae: 90.6899\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 90.4899 - mae: 90.4899\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 90.2899 - mae: 90.2899\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.0899 - mae: 90.0899\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.8899 - mae: 89.8899\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.6899 - mae: 89.6899\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.4899 - mae: 89.4899\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 89.2899 - mae: 89.2899\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.0899 - mae: 89.0899\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.8899 - mae: 88.8899\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.6899 - mae: 88.6899\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 88.4899 - mae: 88.4899\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.2899 - mae: 88.2899\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.0899 - mae: 88.0899\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.8899 - mae: 87.8899\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 87.6899 - mae: 87.6899\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 87.4899 - mae: 87.4899 - val_loss: 91.6636 - val_mae: 91.6636\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.2899 - mae: 87.2899\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.0899 - mae: 87.0899\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 86.8899 - mae: 86.8899\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.6899 - mae: 86.6899\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.4899 - mae: 86.4899\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.2899 - mae: 86.2899\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.0899 - mae: 86.0899\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.8899 - mae: 85.8899\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 85.6899 - mae: 85.6899\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 85.4899 - mae: 85.4899\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.2899 - mae: 85.2899\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 85.0899 - mae: 85.0899\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 84.8899 - mae: 84.8899\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.6899 - mae: 84.6899\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 84.4899 - mae: 84.4899\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 84.2899 - mae: 84.2899\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.0899 - mae: 84.0899\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 83.8899 - mae: 83.8899\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.6899 - mae: 83.6899\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 83.4899 - mae: 83.4899 - val_loss: 87.6636 - val_mae: 87.6636\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.2899 - mae: 83.2899\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 83.0899 - mae: 83.0899\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.8899 - mae: 82.8899\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 82.6899 - mae: 82.6899\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.4899 - mae: 82.4899\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.2899 - mae: 82.2899\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.0899 - mae: 82.0899\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.8899 - mae: 81.8899\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.6899 - mae: 81.6899\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.4899 - mae: 81.4899\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 81.2899 - mae: 81.2899\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.0899 - mae: 81.0899\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.8899 - mae: 80.8899\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.6899 - mae: 80.6899\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 80.4899 - mae: 80.4899\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 80.2899 - mae: 80.2899\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 80.0899 - mae: 80.0899\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.8899 - mae: 79.8899\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 79.6899 - mae: 79.6899\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 79.4899 - mae: 79.4899 - val_loss: 83.6637 - val_mae: 83.6637\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 79.2899 - mae: 79.2899\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.0899 - mae: 79.0899\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.8899 - mae: 78.8899\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 78.6899 - mae: 78.6899\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.4899 - mae: 78.4899\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.2899 - mae: 78.2899\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.0900 - mae: 78.0900\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.8900 - mae: 77.8900\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.6900 - mae: 77.6900\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.4900 - mae: 77.4900\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.2900 - mae: 77.2900\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.0900 - mae: 77.0900\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.8900 - mae: 76.8900\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 76.6900 - mae: 76.6900\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 76.4900 - mae: 76.4900\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 76.2900 - mae: 76.2900\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.0900 - mae: 76.0900\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 75.8900 - mae: 75.8900\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 75.6900 - mae: 75.6900\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 75.4900 - mae: 75.4900 - val_loss: 79.6637 - val_mae: 79.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4aba668580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.fit(np.array(x_train), np.array(y_train),\n",
    "        batch_size = 64, #每一批batch的大小为32，\n",
    "        epochs = 200, #迭代次数epochs为500\n",
    "        validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "        validation_freq = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(target_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17ccdaaa970>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 345.6x460.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(target_pos_list[:, 0], target_pos_list[:, 1], s = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = np.load('../minibatch.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(419, 332), list([295, 525]), 6, -229.40139493908924,\n",
       "       list([419, 332])], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[421, 328]\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "from DQ_Learning import DQNet, environment, mask_detect, top_detection\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)\n",
    "    \n",
    "target_idx = np.random.randint(0, len(target_pos_list))\n",
    "target_pos = [target_pos_list[target_idx][0], target_pos_list[target_idx][1]]\n",
    "print(target_pos)\n",
    "\n",
    "checkpoint_path = \"./deepqlearning_model\"\n",
    "checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "model = DQNet()\n",
    "envir = environment()\n",
    "model.load_weights(checkpoint_path)\n",
    "model.compile(  optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "                loss = tf.keras.losses.MeanSquaredError(),\n",
    "                metrics = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    a = model.get_best(   state_current = [i*100, 320],\n",
    "                            target_pos = [421, 328],\n",
    "                            get_action = True)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[420, 320, 420, 524, 1]])).numpy()[0][0] == model.call(inputs = tf.constant([[420, 320, 420, 524, 2]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n",
      "-1764.6594\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(model.call(inputs = tf.constant([[3000, 320, 100, 603, i+1]])).numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ac1aa0e324239271716ea4bc0f1972974f6d8d50c2a2c3470023e155096e31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
