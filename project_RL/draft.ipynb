{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyjoystick.sdl2 import Key, Joystick, run_event_loop\n",
    "from pprint import pprint\n",
    "from threading import Thread\n",
    "import time\n",
    "import serial\n",
    "from sklearn import linear_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set blue thresh\n",
    "lower_green = np.array([35,70,60])\n",
    "upper_green = np.array([120,255,255])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx = 1, fy = 1, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    # edges = cv2.Canny(mask, 100, 200)\n",
    "    cv2.imshow('green edges', mask)\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenpos0 = []\n",
    "greenpos1 = []\n",
    "for (index0,liste) in enumerate(edges):\n",
    "    for (index1,value) in enumerate(liste):\n",
    "        if value == 255:\n",
    "            greenpos0.append(index0)\n",
    "            greenpos1.append(index1)\n",
    "            # print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit(np.array(greenpos0).reshape(-1, 1), np.array(greenpos1).reshape(-1, 1))\n",
    "\n",
    "line_X = np.arange(min(greenpos0), max(greenpos0) + 1)[:, np.newaxis]\n",
    "line_y = ransac.predict(line_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (4.8, 6.4))\n",
    "# plt.xlim((0, 480))\n",
    "# plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(np.array(greenpos0).reshape(-1, 1)[inlier_mask], np.array(greenpos1).reshape(-1, 1)[inlier_mask], s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][-1,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][-1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][0,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Servo_t = [0, 29.85799098, 87.28123918, 49.99237628, 23.27381264], [54.25188891, 14.62139926, 51.21600907, 64.9204633, 113.30784031]\n",
    "\n",
    "A_t = [[-0.96566657, 0.49763318, 0.95705414, -0.62148105, -0.44530939], [0.90419815, -0.66050816, 0.60991016, 0.22840757, 0.80645628]]\n",
    "\n",
    "s_t = [[391, 402, 363, 365, 325], [360, 320, 441, 434, 471]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, 180))\n",
    "plt.ylim((0, 180))\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "print(ret)\n",
    "if ret :\n",
    "    print(ret)\n",
    "    cv2.imwrite('./first_frame.jpg', frame)\n",
    "    # cv2.imshow('test', frame)\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.npy', 'rb') as f:\n",
    "    Servo_t = np.load(f)\n",
    "    A_t = np.load(f)\n",
    "    s_t = np.load(f)\n",
    "    \n",
    "print(np.shape(Servo_t), np.shape(A_t), np.shape(s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[0, 0], s_t[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((-0.1, 180.1))\n",
    "plt.ylim((-0.1, 180.1))\n",
    "# plt.plot(Servo_t[0], Servo_t[1])\n",
    "plt.title('Servo angle inputs')\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(s_pos, target_pos):\n",
    "    # reward(s_t[:, 0], s_t[:, 1])\n",
    "    reward = np.linalg.norm(s_pos - target_pos)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(s_t[0, :]), max(s_t[0, :]), min(s_t[1, :]), max(s_t[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lis)\n",
    "episode = 10\n",
    "file_name = './img' + str(episode) + '.png'\n",
    "plt.savefig(file_name)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "tf.random.set_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(x_train), tf.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #第三步，models.Sequential()\n",
    "# model = tf.keras.models.Sequential([ #使用models.Sequential()来搭建神经网络\n",
    "#     tf.keras.layers.Dense(3, activation = \"softmax\", kernel_regularizer = tf.keras.regularizers.l2()) #全连接层，三个神经元，激活函数为softmax,使用l2正则化\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(irisModel, self).__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(3, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) #搭建网络块，这一层命名为d1\n",
    " \n",
    "    def call(self, x):\n",
    "        y = self.d1(x)\n",
    "        return  y\n",
    "\n",
    "model = irisModel()\n",
    "\n",
    "#第四步，model.compile()\n",
    "model.compile(  #使用model.compile()方法来配置训练方法\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1), #使用SGD优化器，学习率为0.1\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), #配置损失函数\n",
    "    metrics = ['sparse_categorical_accuracy'] #标注网络评价指标\n",
    ")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#第五步，model.fit()\n",
    "model.fit(  #使用model.fit()方法来执行训练过程，\n",
    "    x_train, y_train, #告知训练集的输入以及标签，\n",
    "    batch_size = 32, #每一批batch的大小为32，\n",
    "    epochs = 500, #迭代次数epochs为500\n",
    "    validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "    validation_freq = 20 #测试的间隔次数为20,每迭代20次测试一次准确率\n",
    ")\n",
    "\n",
    "#第六步，model.summary()\n",
    "model.summary() #打印神经网络结构，统计参数数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n",
      "value 0.6450147\n",
      "value -0.08118695\n",
      "value -0.23150498\n",
      "value -0.2319426\n",
      "value 0.59114623\n",
      "value -0.75850475\n",
      "value 0.3269378\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.2580397\n",
      "value -0.40707892\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.75803894\n",
      "value -0.23150408\n",
      "value 0.3095544\n",
      "value 0.26861793\n",
      "value -0.40707913\n",
      "value 0.323735\n",
      "value 0.3612615\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.5911461\n",
      "value 0.59114623\n",
      "value -0.7569668\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -1.4240078\n",
      "value 0.59114456\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.75861394\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.34505898\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.23149645\n",
      "value 0.32373512\n",
      "value -0.12266511\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26173222\n",
      "value 0.59114623\n",
      "value 0.11739713\n",
      "value 0.32373512\n",
      "value -0.6350396\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.3507497\n",
      "value 0.32373512\n",
      "value -0.23390377\n",
      "value -0.75853956\n",
      "value 0.24393946\n",
      "value 0.59107155\n",
      "value -0.2315048\n",
      "value 0.59114623\n",
      "value -0.40707892\n",
      "value 0.27229315\n",
      "value 0.59114623\n",
      "value 0.5911455\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23143107\n",
      "value -0.23150408\n",
      "value -0.0962643\n",
      "value 0.59114623\n",
      "value 0.24426359\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.6473147\n",
      "value -0.40707946\n",
      "value 0.59114623\n",
      "value -0.23150504\n",
      "value 0.59114623\n",
      "value -0.7583641\n",
      "value 0.32373512\n",
      "value 0.5757598\n",
      "value 0.59114623\n",
      "value 0.6472179\n",
      "value -0.39071947\n",
      "value -0.7139146\n",
      "value -0.75861144\n",
      "value 0.5833809\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.107035995\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.52131844\n",
      "value 0.5911359\n",
      "value 0.32373518\n",
      "value -0.23150408\n",
      "value 0.32400388\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4062937\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.66696143\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.74986315\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.3999202\n",
      "value 0.32373512\n",
      "value -0.18752253\n",
      "value -0.23150408\n",
      "value 0.25695825\n",
      "value 0.32373506\n",
      "value -0.23150408\n",
      "value -0.4070795\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.28266996\n",
      "value 0.59114623\n",
      "value 0.5450496\n",
      "value 0.2617566\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75832164\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.059395492\n",
      "value 0.5911342\n",
      "value 0.25877017\n",
      "value -0.23150408\n",
      "value -0.23494434\n",
      "value 0.19940478\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.23992169\n",
      "value 0.59114623\n",
      "value 0.58896184\n",
      "value -0.23150337\n",
      "value 0.59114623\n",
      "value -1.589718\n",
      "value 0.20189095\n",
      "value -0.23150593\n",
      "value 0.32373512\n",
      "value -1.4327105\n",
      "value 0.5911486\n",
      "value 0.59114623\n",
      "value 0.5889333\n",
      "value 0.59114623\n",
      "value 0.64043075\n",
      "value 0.25154275\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.113301694\n",
      "value 0.59114623\n",
      "value 0.32374704\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4070737\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114635\n",
      "value 0.32373542\n",
      "value 0.32373512\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150426\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.1442657\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32043058\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24398506\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707007\n",
      "value 0.59114623\n",
      "value -0.66847324\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23568809\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59062207\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.8216504\n",
      "value 0.32373512\n",
      "value -0.6521405\n",
      "value 0.59114623\n",
      "value -0.53595084\n",
      "value -1.4218881\n",
      "value 0.59081745\n",
      "value 0.59114623\n",
      "value -0.40707096\n",
      "value -0.236976\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.434478\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26322567\n",
      "value 0.59114623\n",
      "value -1.4240083\n",
      "value 0.3238485\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150402\n",
      "value 0.59114623\n",
      "value -0.40707037\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.7586123\n",
      "value 0.59114623\n",
      "value 0.39807868\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114015\n",
      "value 0.3171935\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4241072\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.323736\n",
      "value -1.4240799\n",
      "value 0.3237363\n",
      "value 0.58790904\n",
      "value 0.32373512\n",
      "value -0.23160172\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373494\n",
      "value -0.40564996\n",
      "value 0.26937127\n",
      "value 0.2519045\n",
      "value 0.59114623\n",
      "value -0.758268\n",
      "value -1.1093247\n",
      "value -0.23150408\n",
      "value -0.4057059\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.323735\n",
      "value 0.59114623\n",
      "value 0.3237365\n",
      "value 0.26171857\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.16182947\n",
      "value -0.23150408\n",
      "value 0.32151467\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.75861496\n",
      "value -0.5814961\n",
      "value -0.23147768\n",
      "value -0.7585298\n",
      "value 0.32373512\n",
      "value 0.19288534\n",
      "value 0.32373512\n",
      "value -0.16298017\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.5911555\n",
      "value -0.7585528\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.58732164\n",
      "value 0.16817391\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32374054\n",
      "value 0.59114623\n",
      "value -0.46500602\n",
      "value -0.65090376\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.4238759\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.38684246\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.4455415\n",
      "value 0.6261557\n",
      "value 0.5828347\n",
      "value -1.4268783\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59023607\n",
      "value 0.59114623\n",
      "value -0.0017516017\n",
      "value 0.5911459\n",
      "value 0.32373512\n",
      "value -0.75823355\n",
      "value 0.59114623\n",
      "value 0.32373524\n",
      "value 0.2532575\n",
      "value 0.59114623\n",
      "value -0.4070786\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75850165\n",
      "value 0.3394912\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.31911927\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -1.425225\n",
      "value 0.32375956\n",
      "value 0.59114623\n",
      "value -0.7303878\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.34235758\n",
      "value 0.59114623\n",
      "value -0.7586142\n",
      "value 0.32373512\n",
      "value -0.3896213\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.33313137\n",
      "value -1.8681086\n",
      "value 0.32373512\n",
      "value -0.7554165\n",
      "value 0.32373512\n",
      "value -0.47229713\n",
      "value 0.32373512\n",
      "value 0.5880114\n",
      "value 0.59114623\n",
      "value 0.64724827\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.7065061\n",
      "value -0.23150408\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.58265936\n",
      "value 0.64730424\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4638419\n",
      "value -1.4243534\n",
      "value 0.038555026\n",
      "value 0.59114623\n",
      "value -1.424041\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40392858\n",
      "value 0.59116817\n",
      "value 0.3237363\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.2618587\n",
      "value 0.25407785\n",
      "value 0.59114623\n",
      "value -0.23141533\n",
      "value 0.59114623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from DQ_Learning import DQNet\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with open('/home/mig5/Desktop/TR_DATA_RL/minibatch.npy', 'rb') as f:\n",
    "    minibatch = np.load(f, allow_pickle=True)\n",
    "    # experience = np.load(f, allow_pickle=True)\n",
    "\n",
    "print(np.shape(minibatch))\n",
    "DQL = DQNet()\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for (i, mini) in enumerate(minibatch):\n",
    "    value_ = DQL.get_best(mini[4], mini[1], get_action = False)\n",
    "    y_train.append(mini[3] + 0.99*value_)\n",
    "    x_train.append([mini[0][0], mini[0][1], mini[1][0], mini[1][1], mini[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 43911.7266 - mae: 176.4142\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42961.1797 - mae: 173.7402\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42080.9453 - mae: 171.3190\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41160.9570 - mae: 168.7957\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40261.5469 - mae: 166.3499\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39397.1562 - mae: 164.0227\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38555.3516 - mae: 161.7339\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37745.5469 - mae: 159.5746\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36959.1992 - mae: 157.4209\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36196.5859 - mae: 155.3671\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35456.2969 - mae: 153.3706\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34741.6836 - mae: 151.3696\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34054.5664 - mae: 149.5234\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33389.0234 - mae: 147.7420\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32739.8125 - mae: 145.9564\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32113.7520 - mae: 144.2499\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31504.3945 - mae: 142.6024\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30918.2520 - mae: 140.9837\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30350.4199 - mae: 139.4577\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29796.1758 - mae: 137.9017\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 29262.9941 - mae: 136.5036\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28744.3262 - mae: 135.1614\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28243.4238 - mae: 133.8305\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27762.1973 - mae: 132.5893\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27288.8711 - mae: 131.3314\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26833.7852 - mae: 130.1387\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26390.3281 - mae: 128.9575\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25961.6270 - mae: 127.8116\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25542.4785 - mae: 126.7358\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25139.7949 - mae: 125.7031\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24753.1953 - mae: 124.6935\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24377.3809 - mae: 123.7041\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24010.1055 - mae: 122.7384\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23652.1953 - mae: 121.7681\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 23309.6621 - mae: 120.8753\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22984.3965 - mae: 120.0311\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22663.7969 - mae: 119.1545\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22350.9238 - mae: 118.3202\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22049.0117 - mae: 117.5426\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21755.6367 - mae: 116.7803\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21471.0957 - mae: 116.0459\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21195.8398 - mae: 115.3249\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20930.0957 - mae: 114.6576\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20656.1055 - mae: 113.8095\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20439.8809 - mae: 113.4058\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20202.4180 - mae: 112.8657\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19969.9160 - mae: 112.3102\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19741.5254 - mae: 111.7498\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19523.2656 - mae: 111.2243\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19313.2305 - mae: 110.6964\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19106.9570 - mae: 110.2009\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18907.6387 - mae: 109.7228\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18713.6836 - mae: 109.2450\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18525.6953 - mae: 108.8038\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18345.1855 - mae: 108.3715\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18168.9609 - mae: 107.9391\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17999.8125 - mae: 107.5385\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17835.6953 - mae: 107.1360\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17678.1680 - mae: 106.7698\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17521.2402 - mae: 106.4004\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17372.3281 - mae: 106.0484\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17228.3242 - mae: 105.7198\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17088.0938 - mae: 105.3729\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16953.1836 - mae: 105.0625\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16822.8848 - mae: 104.7572\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16697.7969 - mae: 104.4642\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16576.6523 - mae: 104.1864\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16457.0078 - mae: 103.8793\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16341.0762 - mae: 103.6008\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16227.4053 - mae: 103.3424\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16119.2041 - mae: 103.0879\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16013.0283 - mae: 102.8249\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15910.7812 - mae: 102.5746\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15812.1904 - mae: 102.3422\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15715.0186 - mae: 102.1018\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15625.0225 - mae: 101.8913\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15537.7480 - mae: 101.6930\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15451.4805 - mae: 101.5118\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15367.4824 - mae: 101.3332\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15287.9961 - mae: 101.1596\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15208.2461 - mae: 100.9981\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15132.9971 - mae: 100.8388\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15057.3477 - mae: 100.6724\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14985.3047 - mae: 100.5232\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14917.3076 - mae: 100.3893\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14850.8945 - mae: 100.2506\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14786.3232 - mae: 100.1163\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14724.0869 - mae: 99.9976\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14662.5088 - mae: 99.8798\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14602.9941 - mae: 99.7773\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14545.3027 - mae: 99.6595\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14490.1572 - mae: 99.5771\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14437.2793 - mae: 99.4644\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14385.7305 - mae: 99.3556\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14334.5850 - mae: 99.2675\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14287.1982 - mae: 99.1723\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14240.5811 - mae: 99.0847\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14195.4336 - mae: 98.9959\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14150.3662 - mae: 98.9082\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14107.4785 - mae: 98.8395\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14066.2529 - mae: 98.7546\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14024.7559 - mae: 98.6743\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13985.5186 - mae: 98.5993\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13948.5938 - mae: 98.5330\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13912.7305 - mae: 98.4716\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13877.5020 - mae: 98.4078\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13843.7812 - mae: 98.3567\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13811.6904 - mae: 98.2984\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13780.6494 - mae: 98.2401\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13750.2666 - mae: 98.1944\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13721.4121 - mae: 98.1309\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13691.6836 - mae: 98.1083\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13663.5195 - mae: 98.0451\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13635.7080 - mae: 98.0110\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13608.9502 - mae: 97.9599\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13584.3887 - mae: 97.9247\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13559.9717 - mae: 97.8857\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13535.0312 - mae: 97.8520\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13511.9658 - mae: 97.8063\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13488.9619 - mae: 97.7737\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13467.3164 - mae: 97.7442\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13445.4746 - mae: 97.7047\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13425.2266 - mae: 97.6733\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13405.6943 - mae: 97.6468\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13386.7412 - mae: 97.6331\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13368.7402 - mae: 97.5896\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13349.9209 - mae: 97.5778\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13332.5010 - mae: 97.5485\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13315.8271 - mae: 97.5351\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13299.0957 - mae: 97.5067\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13283.2832 - mae: 97.4858\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13267.3994 - mae: 97.4663\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13253.0977 - mae: 97.4526\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13238.8574 - mae: 97.4311\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13224.7422 - mae: 97.4064\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13211.6973 - mae: 97.3909\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13198.7090 - mae: 97.3757\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13185.8682 - mae: 97.3597\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13174.2832 - mae: 97.3407\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13161.3652 - mae: 97.3225\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13150.6152 - mae: 97.3138\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13140.3887 - mae: 97.2971\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13129.0098 - mae: 97.2807\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13118.6572 - mae: 97.2683\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13108.2197 - mae: 97.2591\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13098.9209 - mae: 97.2490\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13089.2891 - mae: 97.2336\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13080.3818 - mae: 97.2197\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13071.3359 - mae: 97.2106\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13062.1123 - mae: 97.1964\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13053.5723 - mae: 97.1840\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13045.5264 - mae: 97.1754\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13036.3174 - mae: 97.1606\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13028.9824 - mae: 97.1501\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13021.4990 - mae: 97.1424\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13013.9854 - mae: 97.1306\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13006.6924 - mae: 97.1232\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 13000.3799 - mae: 97.1110\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12994.0117 - mae: 97.1037\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12988.2891 - mae: 97.1053\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12982.2432 - mae: 97.0936\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12976.3750 - mae: 97.0865\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12970.6016 - mae: 97.0836\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12965.0225 - mae: 97.0777\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12959.6807 - mae: 97.0715\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12954.6914 - mae: 97.0634\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12949.2451 - mae: 97.0585\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12944.1797 - mae: 97.0509\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12939.5117 - mae: 97.0458\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12935.0918 - mae: 97.0402\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12930.9150 - mae: 97.0341\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12926.2275 - mae: 97.0299\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12922.2822 - mae: 97.0298\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12918.7451 - mae: 97.0231\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12914.8320 - mae: 97.0201\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12911.2529 - mae: 97.0153\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12908.0732 - mae: 97.0127\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12904.6660 - mae: 97.0110\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12901.0000 - mae: 97.0094\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12897.8789 - mae: 97.0044\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12894.3018 - mae: 97.0057\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12891.4170 - mae: 97.0055\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12888.7344 - mae: 97.0018\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12885.6885 - mae: 96.9992\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12882.9297 - mae: 96.9973\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12880.3838 - mae: 96.9991\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12877.5537 - mae: 96.9982\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12875.3291 - mae: 96.9968\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12872.6562 - mae: 96.9967\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12870.1846 - mae: 96.9968\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12867.9541 - mae: 96.9956\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12866.0137 - mae: 96.9947\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12863.9316 - mae: 96.9932\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12862.1211 - mae: 96.9939\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12859.9209 - mae: 96.9918\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12857.5908 - mae: 96.9921\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12855.6924 - mae: 96.9897\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12853.1709 - mae: 96.9921\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12851.2900 - mae: 96.9879\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12849.3672 - mae: 96.9933\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12847.5039 - mae: 96.9900\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12845.5840 - mae: 96.9931\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12843.8418 - mae: 96.9869\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12841.2891 - mae: 96.9866\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12838.1562 - mae: 96.9752\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12833.3584 - mae: 96.9588\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12821.6641 - mae: 96.8969\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12837.2031 - mae: 96.9827\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12835.1719 - mae: 96.9797\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12832.3662 - mae: 96.9691\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12828.9785 - mae: 96.9509\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12823.3281 - mae: 96.9384\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12809.4717 - mae: 96.8384\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12794.8379 - mae: 96.7787\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12784.7607 - mae: 96.7216\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12774.8916 - mae: 96.6588\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12762.3223 - mae: 96.6092\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12760.8291 - mae: 96.6059\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12752.9980 - mae: 96.5644\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12751.1602 - mae: 96.5434\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12746.2412 - mae: 96.5375\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12744.8076 - mae: 96.5232\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12742.5537 - mae: 96.5309\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12739.5186 - mae: 96.5376\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12737.6797 - mae: 96.4874\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12737.4648 - mae: 96.5092\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12734.6445 - mae: 96.5124\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12733.4648 - mae: 96.5102\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.9443 - mae: 96.5047\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.5928 - mae: 96.4891\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12729.6426 - mae: 96.4856\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.6123 - mae: 96.5007\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.2490 - mae: 96.5000\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12726.3975 - mae: 96.4878\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12725.3057 - mae: 96.4958\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12724.5117 - mae: 96.4895\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12723.5938 - mae: 96.4988\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12722.6602 - mae: 96.4967\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12721.8887 - mae: 96.4935\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.5713 - mae: 96.5011\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.0352 - mae: 96.4894\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.9492 - mae: 96.4952\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.5996 - mae: 96.4958\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12717.9990 - mae: 96.5001\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.0654 - mae: 96.4934\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12716.5537 - mae: 96.4929\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12715.8887 - mae: 96.5011\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12715.2773 - mae: 96.4966\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.9326 - mae: 96.4978\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3428 - mae: 96.5058\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.9482 - mae: 96.4988\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.2080 - mae: 96.5036\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.5029 - mae: 96.5034\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.2031 - mae: 96.4985\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.8027 - mae: 96.4996\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.4209 - mae: 96.5063\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.1797 - mae: 96.5032\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.3789 - mae: 96.5049\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.1426 - mae: 96.5090\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12709.7217 - mae: 96.5018\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12709.3320 - mae: 96.5066\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12709.0068 - mae: 96.5094\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12708.6973 - mae: 96.5108\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12708.6836 - mae: 96.5112\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.8203 - mae: 96.5104\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.5918 - mae: 96.5138\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.4395 - mae: 96.5164\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.2002 - mae: 96.5185\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.9561 - mae: 96.5224\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.0156 - mae: 96.5172\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12705.8750 - mae: 96.5197\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.5098 - mae: 96.5191\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.6611 - mae: 96.5244\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.3096 - mae: 96.5179\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.8604 - mae: 96.5241\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.9004 - mae: 96.5270\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.2715 - mae: 96.5250\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.3672 - mae: 96.5320\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.1592 - mae: 96.5285\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.8555 - mae: 96.5293\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.6934 - mae: 96.5327\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.3857 - mae: 96.5334\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1631 - mae: 96.5354\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1123 - mae: 96.5319\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8857 - mae: 96.5339\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.7695 - mae: 96.5359\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8047 - mae: 96.5374\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3965 - mae: 96.5324\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.5371 - mae: 96.5414\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3857 - mae: 96.5419\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3721 - mae: 96.5393\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.0371 - mae: 96.5386\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.9082 - mae: 96.5440\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4941 - mae: 96.5416\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4326 - mae: 96.5407\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.5996 - mae: 96.5454\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.3867 - mae: 96.5460\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12701.4404 - mae: 96.5454\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.9082 - mae: 96.5460\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.0137 - mae: 96.5482\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.7109 - mae: 96.5471\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5501\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.6436 - mae: 96.5535\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5527\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.5430 - mae: 96.5557\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.2900 - mae: 96.5569\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.1016 - mae: 96.5510\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12700.0576 - mae: 96.5565\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9326 - mae: 96.5559\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.0088 - mae: 96.5583\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9141 - mae: 96.5558\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.5293 - mae: 96.5592\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6016 - mae: 96.5632\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.7227 - mae: 96.5628\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6914 - mae: 96.5625\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.4219 - mae: 96.5609\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.3857 - mae: 96.5603\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.5098 - mae: 96.5665\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.5947 - mae: 96.5647\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.4619 - mae: 96.5663\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1182 - mae: 96.5664\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.0762 - mae: 96.5675\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1240 - mae: 96.5691\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.9414 - mae: 96.5683\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7988 - mae: 96.5675\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.7480 - mae: 96.5697\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7266 - mae: 96.5693\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7402 - mae: 96.5702\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.6602 - mae: 96.5683\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.5059 - mae: 96.5703\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7832 - mae: 96.5713\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7559 - mae: 96.5734\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7783 - mae: 96.5760\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3975 - mae: 96.5749\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2959 - mae: 96.5753\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4893 - mae: 96.5785\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3916 - mae: 96.5777\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.2676 - mae: 96.5737\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4551 - mae: 96.5769\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0908 - mae: 96.5749\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2539 - mae: 96.5765\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1836 - mae: 96.5755\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2588 - mae: 96.5768\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2715 - mae: 96.5749\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1885 - mae: 96.5745\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3535 - mae: 96.5724\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1328 - mae: 96.5780\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0781 - mae: 96.5784\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9814 - mae: 96.5753\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2754 - mae: 96.5787\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1719 - mae: 96.5781\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1221 - mae: 96.5777\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4863 - mae: 96.5799\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9922 - mae: 96.5788\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1084 - mae: 96.5754\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8721 - mae: 96.5787\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2793 - mae: 96.5770\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9697 - mae: 96.5773\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3027 - mae: 96.5815\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0791 - mae: 96.5795\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1396 - mae: 96.5809\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6758 - mae: 96.5795\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6377 - mae: 96.5766\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8604 - mae: 96.5793\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6318 - mae: 96.5790\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1182 - mae: 96.5813\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9600 - mae: 96.5825\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7930 - mae: 96.5810\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7754 - mae: 96.5806\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0039 - mae: 96.5794\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8994 - mae: 96.5821\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8828 - mae: 96.5803\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9736 - mae: 96.5806\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1143 - mae: 96.5823\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0332 - mae: 96.5833\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9707 - mae: 96.5844\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7754 - mae: 96.5852\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.1230 - mae: 96.5833\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7314 - mae: 96.5817\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6465 - mae: 96.5794\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6846 - mae: 96.5824\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0215 - mae: 96.5842\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8096 - mae: 96.5829\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6533 - mae: 96.5827\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7207 - mae: 96.5809\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6992 - mae: 96.5833\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5322 - mae: 96.5853\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7832 - mae: 96.5892\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7451 - mae: 96.5853\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8984 - mae: 96.5893\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9404 - mae: 96.5885\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5400 - mae: 96.5857\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7656 - mae: 96.5895\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7373 - mae: 96.5890\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4033 - mae: 96.5882\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4980 - mae: 96.5880\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5723 - mae: 96.5876\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.4434 - mae: 96.5878\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6914 - mae: 96.5889\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6924 - mae: 96.5906\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5830 - mae: 96.5893\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4160 - mae: 96.5878\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6914 - mae: 96.5902\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5098 - mae: 96.5882\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8174 - mae: 96.5891\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5703 - mae: 96.5890\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5645 - mae: 96.5900\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6133 - mae: 96.5882\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4385 - mae: 96.5876\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2510 - mae: 96.5921\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4854 - mae: 96.5878\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5791 - mae: 96.5848\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5866\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4268 - mae: 96.5872\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5264 - mae: 96.5876\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.6689 - mae: 96.5905\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.8066 - mae: 96.5892\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6016 - mae: 96.5901\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4258 - mae: 96.5875\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12697.5361 - mae: 96.5904\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5566 - mae: 96.5901\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12697.2920 - mae: 96.5907\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3457 - mae: 96.5940\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.3418 - mae: 96.5917\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1260 - mae: 96.5914\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2939 - mae: 96.5923\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3262 - mae: 96.5932\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2480 - mae: 96.5914\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2959 - mae: 96.5928\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.2285 - mae: 96.5929\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4326 - mae: 96.5925\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5352 - mae: 96.5969\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5967\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5922\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7383 - mae: 96.5944\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5955\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2607 - mae: 96.5949\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6260 - mae: 96.5938\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1953 - mae: 96.5913\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4785 - mae: 96.5968\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6729 - mae: 96.5953\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3594 - mae: 96.5958\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2871 - mae: 96.5943\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3154 - mae: 96.5958\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4902 - mae: 96.5947\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5215 - mae: 96.5948\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3164 - mae: 96.5942\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5936\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5920\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5332 - mae: 96.5923\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3428 - mae: 96.5915\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1494 - mae: 96.5927\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3330 - mae: 96.5943\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1436 - mae: 96.5942\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1543 - mae: 96.5944\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.0996 - mae: 96.5930\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2627 - mae: 96.5943\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2861 - mae: 96.5932\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3096 - mae: 96.7425\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9707 - mae: 97.2263\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1328 - mae: 97.2280\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0820 - mae: 97.2281\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0918 - mae: 97.2267\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.2451 - mae: 97.2232\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0742 - mae: 97.2267\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1582 - mae: 97.2268\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0303 - mae: 97.2220\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9443 - mae: 97.2247\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0938 - mae: 97.2251\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8838 - mae: 97.2231\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1865 - mae: 97.2225\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9189 - mae: 97.2233\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0801 - mae: 97.2216\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0166 - mae: 97.2219\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9062 - mae: 97.2210\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1768 - mae: 97.2217\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12798.1816 - mae: 97.2213\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.8877 - mae: 97.2206\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0420 - mae: 97.2207\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7197 - mae: 97.2174\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9365 - mae: 97.2189\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7744 - mae: 97.2172\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0508 - mae: 97.2171\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7891 - mae: 97.2165\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7510 - mae: 97.2151\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12797.6504 - mae: 97.2126\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.6914 - mae: 97.2126\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7041 - mae: 97.2117\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9668 - mae: 97.2124\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.2080 - mae: 97.2113\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8975 - mae: 97.2141\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9854 - mae: 97.2146\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8623 - mae: 97.2117\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12797.8057 - mae: 97.2138\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7588 - mae: 97.2136\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8438 - mae: 97.2146\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8369 - mae: 97.2157\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8457 - mae: 97.2135\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.4336 - mae: 97.2147\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8789 - mae: 97.2152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48fdaea6a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"cp.ckpt\"\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "DQL.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "DQL.fit(np.array(x_train),\n",
    "        np.array(y_train),\n",
    "        epochs=500)\n",
    "# DQL.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.get_best(mini[4], mini[1], get_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 16.2087 - mae: 16.2087 - 169ms/epoch - 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from DQ_Learning import DQNet\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_path = \"/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model\"\n",
    "model = DQNet()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "            loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "            metrics = 'mae')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(np.array(x_train), np.array(y_train), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3584353.2500 - mae: 3584353.2500\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 266493520.0000 - mae: 266493520.0000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 154.0703 - mae: 154.0703\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 114.6900 - mae: 114.6900\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.4900 - mae: 114.4900\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.2900 - mae: 114.2900\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 114.0900 - mae: 114.0900\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 113.8900 - mae: 113.8900\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.6900 - mae: 113.6900\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.4900 - mae: 113.4900\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.2900 - mae: 113.2900\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 113.0900 - mae: 113.0900\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.8900 - mae: 112.8900\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.6900 - mae: 112.6900\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 112.4900 - mae: 112.4900\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 112.2900 - mae: 112.2900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.0900 - mae: 112.0900\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.8900 - mae: 111.8900\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.6900 - mae: 111.6900\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 111.4900 - mae: 111.4900 - val_loss: 115.6637 - val_mae: 115.6637\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 111.2900 - mae: 111.2900\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 111.0900 - mae: 111.0900\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.8900 - mae: 110.8900\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 110.6900 - mae: 110.6900\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.4900 - mae: 110.4900\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 110.2900 - mae: 110.2900\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.0900 - mae: 110.0900\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.8900 - mae: 109.8900\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.6900 - mae: 109.6900\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 109.4900 - mae: 109.4900\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.2900 - mae: 109.2900\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.0900 - mae: 109.0900\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 108.8900 - mae: 108.8900\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.6900 - mae: 108.6900\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 108.4900 - mae: 108.4900\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.2900 - mae: 108.2900\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.0900 - mae: 108.0900\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 107.8900 - mae: 107.8900\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 107.6900 - mae: 107.6900\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 107.4900 - mae: 107.4900 - val_loss: 111.6637 - val_mae: 111.6637\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.2900 - mae: 107.2900\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.0900 - mae: 107.0900\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.8900 - mae: 106.8900\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.6900 - mae: 106.6900\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 106.4900 - mae: 106.4900\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.2900 - mae: 106.2900\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.0900 - mae: 106.0900\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.8900 - mae: 105.8900\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.6900 - mae: 105.6900\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 105.4900 - mae: 105.4900\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.2900 - mae: 105.2900\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.0900 - mae: 105.0900\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.8900 - mae: 104.8900\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.6900 - mae: 104.6900\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.4900 - mae: 104.4900\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 104.2900 - mae: 104.2900\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 104.0900 - mae: 104.0900\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.8900 - mae: 103.8900\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 103.6900 - mae: 103.6900\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 103.4900 - mae: 103.4900 - val_loss: 107.6637 - val_mae: 107.6637\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.2900 - mae: 103.2900\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.0899 - mae: 103.0899\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.8900 - mae: 102.8900\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 102.6899 - mae: 102.6899\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.4899 - mae: 102.4899\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.2899 - mae: 102.2899\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 102.0899 - mae: 102.0899\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.8899 - mae: 101.8899\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.6899 - mae: 101.6899\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.4899 - mae: 101.4899\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 101.2899 - mae: 101.2899\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.0899 - mae: 101.0899\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.8899 - mae: 100.8899\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 100.6899 - mae: 100.6899\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.4899 - mae: 100.4899\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.2899 - mae: 100.2899\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.0899 - mae: 100.0899\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.8899 - mae: 99.8899\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.6899 - mae: 99.6899\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 99.4899 - mae: 99.4899 - val_loss: 103.6637 - val_mae: 103.6637\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.2899 - mae: 99.2899\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.0899 - mae: 99.0899\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.8899 - mae: 98.8899\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 98.6899 - mae: 98.6899\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.4899 - mae: 98.4899\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.2899 - mae: 98.2899\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.0899 - mae: 98.0899\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.8899 - mae: 97.8899\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 97.6899 - mae: 97.6899\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.4899 - mae: 97.4899\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.2899 - mae: 97.2899\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.0899 - mae: 97.0899\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 96.8899 - mae: 96.8899\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.6899 - mae: 96.6899\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 96.4899 - mae: 96.4899\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.2899 - mae: 96.2899\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.0899 - mae: 96.0899\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.8899 - mae: 95.8899\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.6899 - mae: 95.6899\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 95.4899 - mae: 95.4899 - val_loss: 99.6637 - val_mae: 99.6637\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.2899 - mae: 95.2899\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 95.0899 - mae: 95.0899\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.8899 - mae: 94.8899\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.6899 - mae: 94.6899\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.4899 - mae: 94.4899\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 94.2899 - mae: 94.2899\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.0899 - mae: 94.0899\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.8899 - mae: 93.8899\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.6899 - mae: 93.6899\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.4899 - mae: 93.4899\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.2899 - mae: 93.2899\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.0899 - mae: 93.0899\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 92.8899 - mae: 92.8899\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.6899 - mae: 92.6899\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.4899 - mae: 92.4899\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.2899 - mae: 92.2899\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 92.0899 - mae: 92.0899\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 91.8899 - mae: 91.8899\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 91.6899 - mae: 91.6899\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 91.4899 - mae: 91.4899 - val_loss: 95.6637 - val_mae: 95.6637\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 91.2899 - mae: 91.2899\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 91.0899 - mae: 91.0899\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 90.8899 - mae: 90.8899\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.6899 - mae: 90.6899\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 90.4899 - mae: 90.4899\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 90.2899 - mae: 90.2899\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.0899 - mae: 90.0899\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.8899 - mae: 89.8899\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.6899 - mae: 89.6899\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.4899 - mae: 89.4899\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 89.2899 - mae: 89.2899\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.0899 - mae: 89.0899\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.8899 - mae: 88.8899\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.6899 - mae: 88.6899\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 88.4899 - mae: 88.4899\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.2899 - mae: 88.2899\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.0899 - mae: 88.0899\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.8899 - mae: 87.8899\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 87.6899 - mae: 87.6899\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 87.4899 - mae: 87.4899 - val_loss: 91.6636 - val_mae: 91.6636\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.2899 - mae: 87.2899\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.0899 - mae: 87.0899\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 86.8899 - mae: 86.8899\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.6899 - mae: 86.6899\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.4899 - mae: 86.4899\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.2899 - mae: 86.2899\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.0899 - mae: 86.0899\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.8899 - mae: 85.8899\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 85.6899 - mae: 85.6899\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 85.4899 - mae: 85.4899\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.2899 - mae: 85.2899\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 85.0899 - mae: 85.0899\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 84.8899 - mae: 84.8899\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.6899 - mae: 84.6899\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 84.4899 - mae: 84.4899\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 84.2899 - mae: 84.2899\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.0899 - mae: 84.0899\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 83.8899 - mae: 83.8899\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.6899 - mae: 83.6899\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 83.4899 - mae: 83.4899 - val_loss: 87.6636 - val_mae: 87.6636\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.2899 - mae: 83.2899\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 83.0899 - mae: 83.0899\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.8899 - mae: 82.8899\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 82.6899 - mae: 82.6899\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.4899 - mae: 82.4899\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.2899 - mae: 82.2899\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.0899 - mae: 82.0899\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.8899 - mae: 81.8899\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.6899 - mae: 81.6899\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.4899 - mae: 81.4899\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 81.2899 - mae: 81.2899\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.0899 - mae: 81.0899\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.8899 - mae: 80.8899\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.6899 - mae: 80.6899\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 80.4899 - mae: 80.4899\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 80.2899 - mae: 80.2899\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 80.0899 - mae: 80.0899\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.8899 - mae: 79.8899\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 79.6899 - mae: 79.6899\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 79.4899 - mae: 79.4899 - val_loss: 83.6637 - val_mae: 83.6637\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 79.2899 - mae: 79.2899\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.0899 - mae: 79.0899\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.8899 - mae: 78.8899\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 78.6899 - mae: 78.6899\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.4899 - mae: 78.4899\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.2899 - mae: 78.2899\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.0900 - mae: 78.0900\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.8900 - mae: 77.8900\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.6900 - mae: 77.6900\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.4900 - mae: 77.4900\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.2900 - mae: 77.2900\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.0900 - mae: 77.0900\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.8900 - mae: 76.8900\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 76.6900 - mae: 76.6900\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 76.4900 - mae: 76.4900\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 76.2900 - mae: 76.2900\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.0900 - mae: 76.0900\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 75.8900 - mae: 75.8900\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 75.6900 - mae: 75.6900\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 75.4900 - mae: 75.4900 - val_loss: 79.6637 - val_mae: 79.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4aba668580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.fit(np.array(x_train), np.array(y_train),\n",
    "        batch_size = 64, #每一批batch的大小为32，\n",
    "        epochs = 200, #迭代次数epochs为500\n",
    "        validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "        validation_freq = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)\n",
    "np.shape(target_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2ad8a8e370>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(target_pos_list[:, 0], target_pos_list[:, 1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5052, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_memory = np.load('../replay_memory50.npy', allow_pickle=True)\n",
    "np.shape(replay_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[351.0, 307.0, 119.0, 537.0, 6.0, -323.88269481403296, 351.0, 311.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_memory = np.ndarray.tolist(replay_memory)\n",
    "replay_memory[0]\n",
    "# state_current[0], state_current[1], target_pos[0], target_pos[1], \n",
    "# action_current, reward_current, state_next[0], state_next[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 561]\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    }
   ],
   "source": [
    "from DQ_Learning import environment\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DQNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation = tf.nn.tanh)\n",
    "        self.dense2 = tf.keras.layers.Dense(16, activation = tf.nn.tanh)\n",
    "        self.dense3 = tf.keras.layers.Dense(8, activation = tf.nn.tanh)\n",
    "        self.dense4 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        output = x\n",
    "        return output\n",
    "    \n",
    "    def get_best(self, state_current, target_pos, get_action = True):\n",
    "        action = 1\n",
    "        inputs = tf.constant([[state_current[0], state_current[1], \n",
    "                               target_pos[0], target_pos[1], action]])\n",
    "        value = self.call(inputs = inputs).numpy()[0][0]\n",
    "        # print(\"debug: best q value is: \", value)\n",
    "        \n",
    "        for i in range(8):\n",
    "            # i varies from 0 to 7, action of i+2 varies from 2 to 9\n",
    "            inputs = tf.constant([[state_current[0], state_current[1], \n",
    "                               target_pos[0], target_pos[1], i + 2]])\n",
    "            value_new = self.call(inputs = inputs).numpy()[0][0]\n",
    "            if value <= value_new:\n",
    "                value = value_new\n",
    "                action = i + 2\n",
    "        \n",
    "        return action if get_action else value\n",
    "\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)\n",
    "    \n",
    "target_idx = np.random.randint(0, len(target_pos_list))\n",
    "target_pos = [target_pos_list[target_idx][0], target_pos_list[target_idx][1]]\n",
    "print(target_pos)\n",
    "\n",
    "# checkpoint_path = \"./deepqlearning_model\"\n",
    "# checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "envir = environment()\n",
    "model = DQNet()\n",
    "model.save_weights(\"./predict_model\")\n",
    "model_ = DQNet()\n",
    "model_.load_weights(\"./predict_model\")\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "model_.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_current[0], state_current[1], target_pos[0], target_pos[1], \n",
    "# action_current, reward_current, state_next[0], state_next[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for (i, mini) in enumerate(replay_memory):\n",
    "    if mini[5] >= -10:\n",
    "        y_train.append(mini[5])\n",
    "    else:\n",
    "        value_ = model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False) #gdsqjmfkldjk\n",
    "        y_train.append(mini[5] + 0.9*value_)\n",
    "    x_train.append([mini[0], mini[1], mini[2], mini[3], mini[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.03087"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33055612"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.03087"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.load_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/predict_model')\n",
    "model_.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 [==============================] - 1s 2ms/step - loss: 7931.8853 - mae: 74.1926\n",
      "Epoch 2/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8779 - mae: 74.2107\n",
      "Epoch 3/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8613 - mae: 74.1853\n",
      "Epoch 4/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8984 - mae: 74.2028\n",
      "Epoch 5/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9238 - mae: 74.2085\n",
      "Epoch 6/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9004 - mae: 74.1959\n",
      "Epoch 7/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8901 - mae: 74.2034\n",
      "Epoch 8/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9595 - mae: 74.2035\n",
      "Epoch 9/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7932.0176 - mae: 74.2343\n",
      "Epoch 10/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8838 - mae: 74.2006\n",
      "Epoch 11/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8921 - mae: 74.2171\n",
      "Epoch 12/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9248 - mae: 74.2315\n",
      "Epoch 13/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7932.0015 - mae: 74.2101\n",
      "Epoch 14/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9106 - mae: 74.2144\n",
      "Epoch 15/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7932.0537 - mae: 74.2030\n",
      "Epoch 16/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9780 - mae: 74.2132\n",
      "Epoch 17/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9302 - mae: 74.1951\n",
      "Epoch 18/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9136 - mae: 74.1935\n",
      "Epoch 19/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9375 - mae: 74.2037\n",
      "Epoch 20/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8857 - mae: 74.2104\n",
      "Epoch 21/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8447 - mae: 74.2246\n",
      "Epoch 22/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8691 - mae: 74.2104\n",
      "Epoch 23/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.8496 - mae: 74.2021\n",
      "Epoch 24/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9800 - mae: 74.2150\n",
      "Epoch 25/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8857 - mae: 74.2116\n",
      "Epoch 26/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9106 - mae: 74.2057\n",
      "Epoch 27/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8574 - mae: 74.1980\n",
      "Epoch 28/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8882 - mae: 74.2209\n",
      "Epoch 29/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7932.0093 - mae: 74.2104\n",
      "Epoch 30/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8545 - mae: 74.2239\n",
      "Epoch 31/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9092 - mae: 74.2021\n",
      "Epoch 32/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9746 - mae: 74.2168\n",
      "Epoch 33/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9800 - mae: 74.2158\n",
      "Epoch 34/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9810 - mae: 74.2068\n",
      "Epoch 35/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.8804 - mae: 74.2009\n",
      "Epoch 36/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.8726 - mae: 74.2123\n",
      "Epoch 37/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9175 - mae: 74.2187\n",
      "Epoch 38/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7932.0029 - mae: 74.2057\n",
      "Epoch 39/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9351 - mae: 74.2278\n",
      "Epoch 40/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9185 - mae: 74.2114\n",
      "Epoch 41/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8945 - mae: 74.2065\n",
      "Epoch 42/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8979 - mae: 74.2206\n",
      "Epoch 43/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8662 - mae: 74.2087\n",
      "Epoch 44/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9160 - mae: 74.2039\n",
      "Epoch 45/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9028 - mae: 74.1916\n",
      "Epoch 46/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9424 - mae: 74.2048\n",
      "Epoch 47/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9507 - mae: 74.2089\n",
      "Epoch 48/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9150 - mae: 74.2156\n",
      "Epoch 49/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8857 - mae: 74.2203\n",
      "Epoch 50/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9858 - mae: 74.2190\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "model_.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50)\n",
    "model.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/predict_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-191.77814]], dtype=float32)>,\n",
       " -202.739198936567)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(tf.constant([x_train[10]])), y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0] == model.call(inputs = tf.constant([[42, 320, 420, 524, 2]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-191.77817\n",
      "-191.77817\n",
      "-191.77805\n",
      "-191.77795\n",
      "-191.77795\n",
      "-191.7778\n",
      "-191.7778\n",
      "-191.7779\n",
      "-191.77798\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(model.call(inputs = tf.constant([[42, 606, 174, 542, (i+1)*100]])).numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42.0, 606.0, 174.0, 542.0, 8.0, -140.63072210580447, 45.0, 598.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ac1aa0e324239271716ea4bc0f1972974f6d8d50c2a2c3470023e155096e31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
