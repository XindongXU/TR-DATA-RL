{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyjoystick.sdl2 import Key, Joystick, run_event_loop\n",
    "from pprint import pprint\n",
    "from threading import Thread\n",
    "import time\n",
    "import serial\n",
    "from sklearn import linear_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set blue thresh\n",
    "lower_green = np.array([35,70,60])\n",
    "upper_green = np.array([120,255,255])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx = 1, fy = 1, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    # edges = cv2.Canny(mask, 100, 200)\n",
    "    cv2.imshow('green edges', mask)\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenpos0 = []\n",
    "greenpos1 = []\n",
    "for (index0,liste) in enumerate(edges):\n",
    "    for (index1,value) in enumerate(liste):\n",
    "        if value == 255:\n",
    "            greenpos0.append(index0)\n",
    "            greenpos1.append(index1)\n",
    "            # print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit(np.array(greenpos0).reshape(-1, 1), np.array(greenpos1).reshape(-1, 1))\n",
    "\n",
    "line_X = np.arange(min(greenpos0), max(greenpos0) + 1)[:, np.newaxis]\n",
    "line_y = ransac.predict(line_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (4.8, 6.4))\n",
    "# plt.xlim((0, 480))\n",
    "# plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(np.array(greenpos0).reshape(-1, 1)[inlier_mask], np.array(greenpos1).reshape(-1, 1)[inlier_mask], s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][-1,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][-1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][0,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Servo_t = [0, 29.85799098, 87.28123918, 49.99237628, 23.27381264], [54.25188891, 14.62139926, 51.21600907, 64.9204633, 113.30784031]\n",
    "\n",
    "A_t = [[-0.96566657, 0.49763318, 0.95705414, -0.62148105, -0.44530939], [0.90419815, -0.66050816, 0.60991016, 0.22840757, 0.80645628]]\n",
    "\n",
    "s_t = [[391, 402, 363, 365, 325], [360, 320, 441, 434, 471]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, 180))\n",
    "plt.ylim((0, 180))\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "print(ret)\n",
    "if ret :\n",
    "    print(ret)\n",
    "    cv2.imwrite('./first_frame.jpg', frame)\n",
    "    # cv2.imshow('test', frame)\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.npy', 'rb') as f:\n",
    "    Servo_t = np.load(f)\n",
    "    A_t = np.load(f)\n",
    "    s_t = np.load(f)\n",
    "    \n",
    "print(np.shape(Servo_t), np.shape(A_t), np.shape(s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[0, 0], s_t[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((-0.1, 180.1))\n",
    "plt.ylim((-0.1, 180.1))\n",
    "# plt.plot(Servo_t[0], Servo_t[1])\n",
    "plt.title('Servo angle inputs')\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(s_pos, target_pos):\n",
    "    # reward(s_t[:, 0], s_t[:, 1])\n",
    "    reward = np.linalg.norm(s_pos - target_pos)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(s_t[0, :]), max(s_t[0, :]), min(s_t[1, :]), max(s_t[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lis)\n",
    "episode = 10\n",
    "file_name = './img' + str(episode) + '.png'\n",
    "plt.savefig(file_name)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "tf.random.set_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(x_train), tf.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #第三步，models.Sequential()\n",
    "# model = tf.keras.models.Sequential([ #使用models.Sequential()来搭建神经网络\n",
    "#     tf.keras.layers.Dense(3, activation = \"softmax\", kernel_regularizer = tf.keras.regularizers.l2()) #全连接层，三个神经元，激活函数为softmax,使用l2正则化\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(irisModel, self).__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(3, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) #搭建网络块，这一层命名为d1\n",
    " \n",
    "    def call(self, x):\n",
    "        y = self.d1(x)\n",
    "        return  y\n",
    "\n",
    "model = irisModel()\n",
    "\n",
    "#第四步，model.compile()\n",
    "model.compile(  #使用model.compile()方法来配置训练方法\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1), #使用SGD优化器，学习率为0.1\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), #配置损失函数\n",
    "    metrics = ['sparse_categorical_accuracy'] #标注网络评价指标\n",
    ")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#第五步，model.fit()\n",
    "model.fit(  #使用model.fit()方法来执行训练过程，\n",
    "    x_train, y_train, #告知训练集的输入以及标签，\n",
    "    batch_size = 32, #每一批batch的大小为32，\n",
    "    epochs = 500, #迭代次数epochs为500\n",
    "    validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "    validation_freq = 20 #测试的间隔次数为20,每迭代20次测试一次准确率\n",
    ")\n",
    "\n",
    "#第六步，model.summary()\n",
    "model.summary() #打印神经网络结构，统计参数数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n",
      "value 0.6450147\n",
      "value -0.08118695\n",
      "value -0.23150498\n",
      "value -0.2319426\n",
      "value 0.59114623\n",
      "value -0.75850475\n",
      "value 0.3269378\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.2580397\n",
      "value -0.40707892\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.75803894\n",
      "value -0.23150408\n",
      "value 0.3095544\n",
      "value 0.26861793\n",
      "value -0.40707913\n",
      "value 0.323735\n",
      "value 0.3612615\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.5911461\n",
      "value 0.59114623\n",
      "value -0.7569668\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -1.4240078\n",
      "value 0.59114456\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.75861394\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.34505898\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.23149645\n",
      "value 0.32373512\n",
      "value -0.12266511\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26173222\n",
      "value 0.59114623\n",
      "value 0.11739713\n",
      "value 0.32373512\n",
      "value -0.6350396\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.3507497\n",
      "value 0.32373512\n",
      "value -0.23390377\n",
      "value -0.75853956\n",
      "value 0.24393946\n",
      "value 0.59107155\n",
      "value -0.2315048\n",
      "value 0.59114623\n",
      "value -0.40707892\n",
      "value 0.27229315\n",
      "value 0.59114623\n",
      "value 0.5911455\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23143107\n",
      "value -0.23150408\n",
      "value -0.0962643\n",
      "value 0.59114623\n",
      "value 0.24426359\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.6473147\n",
      "value -0.40707946\n",
      "value 0.59114623\n",
      "value -0.23150504\n",
      "value 0.59114623\n",
      "value -0.7583641\n",
      "value 0.32373512\n",
      "value 0.5757598\n",
      "value 0.59114623\n",
      "value 0.6472179\n",
      "value -0.39071947\n",
      "value -0.7139146\n",
      "value -0.75861144\n",
      "value 0.5833809\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.107035995\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.52131844\n",
      "value 0.5911359\n",
      "value 0.32373518\n",
      "value -0.23150408\n",
      "value 0.32400388\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4062937\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.66696143\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.74986315\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.3999202\n",
      "value 0.32373512\n",
      "value -0.18752253\n",
      "value -0.23150408\n",
      "value 0.25695825\n",
      "value 0.32373506\n",
      "value -0.23150408\n",
      "value -0.4070795\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.28266996\n",
      "value 0.59114623\n",
      "value 0.5450496\n",
      "value 0.2617566\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75832164\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.059395492\n",
      "value 0.5911342\n",
      "value 0.25877017\n",
      "value -0.23150408\n",
      "value -0.23494434\n",
      "value 0.19940478\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.23992169\n",
      "value 0.59114623\n",
      "value 0.58896184\n",
      "value -0.23150337\n",
      "value 0.59114623\n",
      "value -1.589718\n",
      "value 0.20189095\n",
      "value -0.23150593\n",
      "value 0.32373512\n",
      "value -1.4327105\n",
      "value 0.5911486\n",
      "value 0.59114623\n",
      "value 0.5889333\n",
      "value 0.59114623\n",
      "value 0.64043075\n",
      "value 0.25154275\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.113301694\n",
      "value 0.59114623\n",
      "value 0.32374704\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4070737\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114635\n",
      "value 0.32373542\n",
      "value 0.32373512\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150426\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.1442657\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32043058\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24398506\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707007\n",
      "value 0.59114623\n",
      "value -0.66847324\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23568809\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59062207\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.8216504\n",
      "value 0.32373512\n",
      "value -0.6521405\n",
      "value 0.59114623\n",
      "value -0.53595084\n",
      "value -1.4218881\n",
      "value 0.59081745\n",
      "value 0.59114623\n",
      "value -0.40707096\n",
      "value -0.236976\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.434478\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26322567\n",
      "value 0.59114623\n",
      "value -1.4240083\n",
      "value 0.3238485\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150402\n",
      "value 0.59114623\n",
      "value -0.40707037\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.7586123\n",
      "value 0.59114623\n",
      "value 0.39807868\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114015\n",
      "value 0.3171935\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4241072\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.323736\n",
      "value -1.4240799\n",
      "value 0.3237363\n",
      "value 0.58790904\n",
      "value 0.32373512\n",
      "value -0.23160172\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373494\n",
      "value -0.40564996\n",
      "value 0.26937127\n",
      "value 0.2519045\n",
      "value 0.59114623\n",
      "value -0.758268\n",
      "value -1.1093247\n",
      "value -0.23150408\n",
      "value -0.4057059\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.323735\n",
      "value 0.59114623\n",
      "value 0.3237365\n",
      "value 0.26171857\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.16182947\n",
      "value -0.23150408\n",
      "value 0.32151467\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.75861496\n",
      "value -0.5814961\n",
      "value -0.23147768\n",
      "value -0.7585298\n",
      "value 0.32373512\n",
      "value 0.19288534\n",
      "value 0.32373512\n",
      "value -0.16298017\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.5911555\n",
      "value -0.7585528\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.58732164\n",
      "value 0.16817391\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32374054\n",
      "value 0.59114623\n",
      "value -0.46500602\n",
      "value -0.65090376\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.4238759\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.38684246\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.4455415\n",
      "value 0.6261557\n",
      "value 0.5828347\n",
      "value -1.4268783\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59023607\n",
      "value 0.59114623\n",
      "value -0.0017516017\n",
      "value 0.5911459\n",
      "value 0.32373512\n",
      "value -0.75823355\n",
      "value 0.59114623\n",
      "value 0.32373524\n",
      "value 0.2532575\n",
      "value 0.59114623\n",
      "value -0.4070786\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75850165\n",
      "value 0.3394912\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.31911927\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -1.425225\n",
      "value 0.32375956\n",
      "value 0.59114623\n",
      "value -0.7303878\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.34235758\n",
      "value 0.59114623\n",
      "value -0.7586142\n",
      "value 0.32373512\n",
      "value -0.3896213\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.33313137\n",
      "value -1.8681086\n",
      "value 0.32373512\n",
      "value -0.7554165\n",
      "value 0.32373512\n",
      "value -0.47229713\n",
      "value 0.32373512\n",
      "value 0.5880114\n",
      "value 0.59114623\n",
      "value 0.64724827\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.7065061\n",
      "value -0.23150408\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.58265936\n",
      "value 0.64730424\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4638419\n",
      "value -1.4243534\n",
      "value 0.038555026\n",
      "value 0.59114623\n",
      "value -1.424041\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40392858\n",
      "value 0.59116817\n",
      "value 0.3237363\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.2618587\n",
      "value 0.25407785\n",
      "value 0.59114623\n",
      "value -0.23141533\n",
      "value 0.59114623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from DQ_Learning import DQNet\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with open('/home/mig5/Desktop/TR_DATA_RL/minibatch.npy', 'rb') as f:\n",
    "    minibatch = np.load(f, allow_pickle=True)\n",
    "    # experience = np.load(f, allow_pickle=True)\n",
    "\n",
    "print(np.shape(minibatch))\n",
    "DQL = DQNet()\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for (i, mini) in enumerate(minibatch):\n",
    "    value_ = DQL.get_best(mini[4], mini[1], get_action = False)\n",
    "    y_train.append(mini[3] + 0.99*value_)\n",
    "    x_train.append([mini[0][0], mini[0][1], mini[1][0], mini[1][1], mini[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 43911.7266 - mae: 176.4142\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42961.1797 - mae: 173.7402\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42080.9453 - mae: 171.3190\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41160.9570 - mae: 168.7957\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40261.5469 - mae: 166.3499\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39397.1562 - mae: 164.0227\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38555.3516 - mae: 161.7339\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37745.5469 - mae: 159.5746\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36959.1992 - mae: 157.4209\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36196.5859 - mae: 155.3671\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35456.2969 - mae: 153.3706\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34741.6836 - mae: 151.3696\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34054.5664 - mae: 149.5234\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33389.0234 - mae: 147.7420\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32739.8125 - mae: 145.9564\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32113.7520 - mae: 144.2499\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31504.3945 - mae: 142.6024\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30918.2520 - mae: 140.9837\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30350.4199 - mae: 139.4577\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29796.1758 - mae: 137.9017\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 29262.9941 - mae: 136.5036\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28744.3262 - mae: 135.1614\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28243.4238 - mae: 133.8305\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27762.1973 - mae: 132.5893\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27288.8711 - mae: 131.3314\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26833.7852 - mae: 130.1387\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26390.3281 - mae: 128.9575\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25961.6270 - mae: 127.8116\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25542.4785 - mae: 126.7358\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25139.7949 - mae: 125.7031\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24753.1953 - mae: 124.6935\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24377.3809 - mae: 123.7041\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24010.1055 - mae: 122.7384\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23652.1953 - mae: 121.7681\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 23309.6621 - mae: 120.8753\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22984.3965 - mae: 120.0311\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22663.7969 - mae: 119.1545\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22350.9238 - mae: 118.3202\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22049.0117 - mae: 117.5426\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21755.6367 - mae: 116.7803\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21471.0957 - mae: 116.0459\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21195.8398 - mae: 115.3249\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20930.0957 - mae: 114.6576\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20656.1055 - mae: 113.8095\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20439.8809 - mae: 113.4058\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20202.4180 - mae: 112.8657\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19969.9160 - mae: 112.3102\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19741.5254 - mae: 111.7498\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19523.2656 - mae: 111.2243\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19313.2305 - mae: 110.6964\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19106.9570 - mae: 110.2009\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18907.6387 - mae: 109.7228\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18713.6836 - mae: 109.2450\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18525.6953 - mae: 108.8038\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18345.1855 - mae: 108.3715\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18168.9609 - mae: 107.9391\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17999.8125 - mae: 107.5385\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17835.6953 - mae: 107.1360\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17678.1680 - mae: 106.7698\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17521.2402 - mae: 106.4004\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17372.3281 - mae: 106.0484\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17228.3242 - mae: 105.7198\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17088.0938 - mae: 105.3729\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16953.1836 - mae: 105.0625\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16822.8848 - mae: 104.7572\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16697.7969 - mae: 104.4642\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16576.6523 - mae: 104.1864\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16457.0078 - mae: 103.8793\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16341.0762 - mae: 103.6008\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16227.4053 - mae: 103.3424\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16119.2041 - mae: 103.0879\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16013.0283 - mae: 102.8249\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15910.7812 - mae: 102.5746\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15812.1904 - mae: 102.3422\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15715.0186 - mae: 102.1018\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15625.0225 - mae: 101.8913\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15537.7480 - mae: 101.6930\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15451.4805 - mae: 101.5118\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15367.4824 - mae: 101.3332\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15287.9961 - mae: 101.1596\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15208.2461 - mae: 100.9981\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15132.9971 - mae: 100.8388\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15057.3477 - mae: 100.6724\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14985.3047 - mae: 100.5232\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14917.3076 - mae: 100.3893\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14850.8945 - mae: 100.2506\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14786.3232 - mae: 100.1163\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14724.0869 - mae: 99.9976\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14662.5088 - mae: 99.8798\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14602.9941 - mae: 99.7773\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14545.3027 - mae: 99.6595\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14490.1572 - mae: 99.5771\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14437.2793 - mae: 99.4644\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14385.7305 - mae: 99.3556\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14334.5850 - mae: 99.2675\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14287.1982 - mae: 99.1723\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14240.5811 - mae: 99.0847\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14195.4336 - mae: 98.9959\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14150.3662 - mae: 98.9082\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14107.4785 - mae: 98.8395\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14066.2529 - mae: 98.7546\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14024.7559 - mae: 98.6743\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13985.5186 - mae: 98.5993\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13948.5938 - mae: 98.5330\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13912.7305 - mae: 98.4716\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13877.5020 - mae: 98.4078\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13843.7812 - mae: 98.3567\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13811.6904 - mae: 98.2984\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13780.6494 - mae: 98.2401\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13750.2666 - mae: 98.1944\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13721.4121 - mae: 98.1309\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13691.6836 - mae: 98.1083\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13663.5195 - mae: 98.0451\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13635.7080 - mae: 98.0110\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13608.9502 - mae: 97.9599\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13584.3887 - mae: 97.9247\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13559.9717 - mae: 97.8857\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13535.0312 - mae: 97.8520\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13511.9658 - mae: 97.8063\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13488.9619 - mae: 97.7737\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13467.3164 - mae: 97.7442\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13445.4746 - mae: 97.7047\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13425.2266 - mae: 97.6733\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13405.6943 - mae: 97.6468\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13386.7412 - mae: 97.6331\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13368.7402 - mae: 97.5896\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13349.9209 - mae: 97.5778\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13332.5010 - mae: 97.5485\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13315.8271 - mae: 97.5351\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13299.0957 - mae: 97.5067\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13283.2832 - mae: 97.4858\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13267.3994 - mae: 97.4663\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13253.0977 - mae: 97.4526\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13238.8574 - mae: 97.4311\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13224.7422 - mae: 97.4064\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13211.6973 - mae: 97.3909\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13198.7090 - mae: 97.3757\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13185.8682 - mae: 97.3597\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13174.2832 - mae: 97.3407\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13161.3652 - mae: 97.3225\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13150.6152 - mae: 97.3138\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13140.3887 - mae: 97.2971\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13129.0098 - mae: 97.2807\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13118.6572 - mae: 97.2683\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13108.2197 - mae: 97.2591\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13098.9209 - mae: 97.2490\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13089.2891 - mae: 97.2336\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13080.3818 - mae: 97.2197\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13071.3359 - mae: 97.2106\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13062.1123 - mae: 97.1964\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13053.5723 - mae: 97.1840\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13045.5264 - mae: 97.1754\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13036.3174 - mae: 97.1606\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13028.9824 - mae: 97.1501\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13021.4990 - mae: 97.1424\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13013.9854 - mae: 97.1306\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13006.6924 - mae: 97.1232\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 13000.3799 - mae: 97.1110\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12994.0117 - mae: 97.1037\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12988.2891 - mae: 97.1053\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12982.2432 - mae: 97.0936\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12976.3750 - mae: 97.0865\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12970.6016 - mae: 97.0836\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12965.0225 - mae: 97.0777\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12959.6807 - mae: 97.0715\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12954.6914 - mae: 97.0634\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12949.2451 - mae: 97.0585\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12944.1797 - mae: 97.0509\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12939.5117 - mae: 97.0458\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12935.0918 - mae: 97.0402\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12930.9150 - mae: 97.0341\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12926.2275 - mae: 97.0299\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12922.2822 - mae: 97.0298\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12918.7451 - mae: 97.0231\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12914.8320 - mae: 97.0201\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12911.2529 - mae: 97.0153\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12908.0732 - mae: 97.0127\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12904.6660 - mae: 97.0110\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12901.0000 - mae: 97.0094\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12897.8789 - mae: 97.0044\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12894.3018 - mae: 97.0057\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12891.4170 - mae: 97.0055\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12888.7344 - mae: 97.0018\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12885.6885 - mae: 96.9992\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12882.9297 - mae: 96.9973\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12880.3838 - mae: 96.9991\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12877.5537 - mae: 96.9982\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12875.3291 - mae: 96.9968\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12872.6562 - mae: 96.9967\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12870.1846 - mae: 96.9968\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12867.9541 - mae: 96.9956\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12866.0137 - mae: 96.9947\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12863.9316 - mae: 96.9932\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12862.1211 - mae: 96.9939\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12859.9209 - mae: 96.9918\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12857.5908 - mae: 96.9921\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12855.6924 - mae: 96.9897\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12853.1709 - mae: 96.9921\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12851.2900 - mae: 96.9879\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12849.3672 - mae: 96.9933\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12847.5039 - mae: 96.9900\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12845.5840 - mae: 96.9931\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12843.8418 - mae: 96.9869\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12841.2891 - mae: 96.9866\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12838.1562 - mae: 96.9752\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12833.3584 - mae: 96.9588\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12821.6641 - mae: 96.8969\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12837.2031 - mae: 96.9827\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12835.1719 - mae: 96.9797\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12832.3662 - mae: 96.9691\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12828.9785 - mae: 96.9509\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12823.3281 - mae: 96.9384\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12809.4717 - mae: 96.8384\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12794.8379 - mae: 96.7787\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12784.7607 - mae: 96.7216\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12774.8916 - mae: 96.6588\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12762.3223 - mae: 96.6092\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12760.8291 - mae: 96.6059\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12752.9980 - mae: 96.5644\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12751.1602 - mae: 96.5434\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12746.2412 - mae: 96.5375\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12744.8076 - mae: 96.5232\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12742.5537 - mae: 96.5309\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12739.5186 - mae: 96.5376\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12737.6797 - mae: 96.4874\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12737.4648 - mae: 96.5092\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12734.6445 - mae: 96.5124\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12733.4648 - mae: 96.5102\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.9443 - mae: 96.5047\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.5928 - mae: 96.4891\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12729.6426 - mae: 96.4856\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.6123 - mae: 96.5007\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.2490 - mae: 96.5000\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12726.3975 - mae: 96.4878\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12725.3057 - mae: 96.4958\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12724.5117 - mae: 96.4895\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12723.5938 - mae: 96.4988\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12722.6602 - mae: 96.4967\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12721.8887 - mae: 96.4935\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.5713 - mae: 96.5011\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.0352 - mae: 96.4894\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.9492 - mae: 96.4952\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.5996 - mae: 96.4958\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12717.9990 - mae: 96.5001\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.0654 - mae: 96.4934\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12716.5537 - mae: 96.4929\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12715.8887 - mae: 96.5011\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12715.2773 - mae: 96.4966\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.9326 - mae: 96.4978\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3428 - mae: 96.5058\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.9482 - mae: 96.4988\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.2080 - mae: 96.5036\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.5029 - mae: 96.5034\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.2031 - mae: 96.4985\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.8027 - mae: 96.4996\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.4209 - mae: 96.5063\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.1797 - mae: 96.5032\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.3789 - mae: 96.5049\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.1426 - mae: 96.5090\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12709.7217 - mae: 96.5018\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12709.3320 - mae: 96.5066\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12709.0068 - mae: 96.5094\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12708.6973 - mae: 96.5108\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12708.6836 - mae: 96.5112\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.8203 - mae: 96.5104\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.5918 - mae: 96.5138\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.4395 - mae: 96.5164\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.2002 - mae: 96.5185\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.9561 - mae: 96.5224\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.0156 - mae: 96.5172\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12705.8750 - mae: 96.5197\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.5098 - mae: 96.5191\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.6611 - mae: 96.5244\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.3096 - mae: 96.5179\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.8604 - mae: 96.5241\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.9004 - mae: 96.5270\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.2715 - mae: 96.5250\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.3672 - mae: 96.5320\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.1592 - mae: 96.5285\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.8555 - mae: 96.5293\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.6934 - mae: 96.5327\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.3857 - mae: 96.5334\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1631 - mae: 96.5354\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1123 - mae: 96.5319\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8857 - mae: 96.5339\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.7695 - mae: 96.5359\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8047 - mae: 96.5374\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3965 - mae: 96.5324\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.5371 - mae: 96.5414\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3857 - mae: 96.5419\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3721 - mae: 96.5393\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.0371 - mae: 96.5386\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.9082 - mae: 96.5440\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4941 - mae: 96.5416\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4326 - mae: 96.5407\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.5996 - mae: 96.5454\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.3867 - mae: 96.5460\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12701.4404 - mae: 96.5454\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.9082 - mae: 96.5460\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.0137 - mae: 96.5482\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.7109 - mae: 96.5471\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5501\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.6436 - mae: 96.5535\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5527\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.5430 - mae: 96.5557\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.2900 - mae: 96.5569\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.1016 - mae: 96.5510\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12700.0576 - mae: 96.5565\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9326 - mae: 96.5559\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.0088 - mae: 96.5583\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9141 - mae: 96.5558\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.5293 - mae: 96.5592\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6016 - mae: 96.5632\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.7227 - mae: 96.5628\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6914 - mae: 96.5625\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.4219 - mae: 96.5609\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.3857 - mae: 96.5603\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.5098 - mae: 96.5665\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.5947 - mae: 96.5647\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.4619 - mae: 96.5663\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1182 - mae: 96.5664\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.0762 - mae: 96.5675\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1240 - mae: 96.5691\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.9414 - mae: 96.5683\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7988 - mae: 96.5675\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.7480 - mae: 96.5697\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7266 - mae: 96.5693\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7402 - mae: 96.5702\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.6602 - mae: 96.5683\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.5059 - mae: 96.5703\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7832 - mae: 96.5713\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7559 - mae: 96.5734\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7783 - mae: 96.5760\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3975 - mae: 96.5749\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2959 - mae: 96.5753\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4893 - mae: 96.5785\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3916 - mae: 96.5777\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.2676 - mae: 96.5737\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4551 - mae: 96.5769\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0908 - mae: 96.5749\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2539 - mae: 96.5765\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1836 - mae: 96.5755\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2588 - mae: 96.5768\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2715 - mae: 96.5749\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1885 - mae: 96.5745\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3535 - mae: 96.5724\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1328 - mae: 96.5780\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0781 - mae: 96.5784\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9814 - mae: 96.5753\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2754 - mae: 96.5787\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1719 - mae: 96.5781\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1221 - mae: 96.5777\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4863 - mae: 96.5799\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9922 - mae: 96.5788\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1084 - mae: 96.5754\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8721 - mae: 96.5787\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2793 - mae: 96.5770\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9697 - mae: 96.5773\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3027 - mae: 96.5815\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0791 - mae: 96.5795\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1396 - mae: 96.5809\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6758 - mae: 96.5795\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6377 - mae: 96.5766\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8604 - mae: 96.5793\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6318 - mae: 96.5790\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1182 - mae: 96.5813\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9600 - mae: 96.5825\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7930 - mae: 96.5810\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7754 - mae: 96.5806\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0039 - mae: 96.5794\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8994 - mae: 96.5821\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8828 - mae: 96.5803\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9736 - mae: 96.5806\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1143 - mae: 96.5823\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0332 - mae: 96.5833\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9707 - mae: 96.5844\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7754 - mae: 96.5852\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.1230 - mae: 96.5833\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7314 - mae: 96.5817\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6465 - mae: 96.5794\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6846 - mae: 96.5824\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0215 - mae: 96.5842\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8096 - mae: 96.5829\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6533 - mae: 96.5827\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7207 - mae: 96.5809\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6992 - mae: 96.5833\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5322 - mae: 96.5853\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7832 - mae: 96.5892\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7451 - mae: 96.5853\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8984 - mae: 96.5893\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9404 - mae: 96.5885\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5400 - mae: 96.5857\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7656 - mae: 96.5895\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7373 - mae: 96.5890\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4033 - mae: 96.5882\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4980 - mae: 96.5880\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5723 - mae: 96.5876\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.4434 - mae: 96.5878\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6914 - mae: 96.5889\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6924 - mae: 96.5906\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5830 - mae: 96.5893\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4160 - mae: 96.5878\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6914 - mae: 96.5902\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5098 - mae: 96.5882\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8174 - mae: 96.5891\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5703 - mae: 96.5890\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5645 - mae: 96.5900\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6133 - mae: 96.5882\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4385 - mae: 96.5876\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2510 - mae: 96.5921\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4854 - mae: 96.5878\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5791 - mae: 96.5848\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5866\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4268 - mae: 96.5872\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5264 - mae: 96.5876\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.6689 - mae: 96.5905\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.8066 - mae: 96.5892\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6016 - mae: 96.5901\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4258 - mae: 96.5875\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12697.5361 - mae: 96.5904\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5566 - mae: 96.5901\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12697.2920 - mae: 96.5907\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3457 - mae: 96.5940\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.3418 - mae: 96.5917\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1260 - mae: 96.5914\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2939 - mae: 96.5923\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3262 - mae: 96.5932\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2480 - mae: 96.5914\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2959 - mae: 96.5928\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.2285 - mae: 96.5929\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4326 - mae: 96.5925\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5352 - mae: 96.5969\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5967\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5922\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7383 - mae: 96.5944\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5955\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2607 - mae: 96.5949\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6260 - mae: 96.5938\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1953 - mae: 96.5913\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4785 - mae: 96.5968\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6729 - mae: 96.5953\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3594 - mae: 96.5958\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2871 - mae: 96.5943\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3154 - mae: 96.5958\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4902 - mae: 96.5947\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5215 - mae: 96.5948\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3164 - mae: 96.5942\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5936\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5920\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5332 - mae: 96.5923\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3428 - mae: 96.5915\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1494 - mae: 96.5927\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3330 - mae: 96.5943\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1436 - mae: 96.5942\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1543 - mae: 96.5944\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.0996 - mae: 96.5930\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2627 - mae: 96.5943\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2861 - mae: 96.5932\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3096 - mae: 96.7425\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9707 - mae: 97.2263\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1328 - mae: 97.2280\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0820 - mae: 97.2281\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0918 - mae: 97.2267\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.2451 - mae: 97.2232\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0742 - mae: 97.2267\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1582 - mae: 97.2268\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0303 - mae: 97.2220\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9443 - mae: 97.2247\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0938 - mae: 97.2251\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8838 - mae: 97.2231\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1865 - mae: 97.2225\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9189 - mae: 97.2233\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0801 - mae: 97.2216\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0166 - mae: 97.2219\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9062 - mae: 97.2210\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1768 - mae: 97.2217\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12798.1816 - mae: 97.2213\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.8877 - mae: 97.2206\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0420 - mae: 97.2207\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7197 - mae: 97.2174\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9365 - mae: 97.2189\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7744 - mae: 97.2172\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0508 - mae: 97.2171\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7891 - mae: 97.2165\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7510 - mae: 97.2151\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12797.6504 - mae: 97.2126\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.6914 - mae: 97.2126\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7041 - mae: 97.2117\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9668 - mae: 97.2124\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.2080 - mae: 97.2113\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8975 - mae: 97.2141\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9854 - mae: 97.2146\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8623 - mae: 97.2117\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12797.8057 - mae: 97.2138\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7588 - mae: 97.2136\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8438 - mae: 97.2146\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8369 - mae: 97.2157\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8457 - mae: 97.2135\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.4336 - mae: 97.2147\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8789 - mae: 97.2152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48fdaea6a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"cp.ckpt\"\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "DQL.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "DQL.fit(np.array(x_train),\n",
    "        np.array(y_train),\n",
    "        epochs=500)\n",
    "# DQL.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.get_best(mini[4], mini[1], get_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 16.2087 - mae: 16.2087 - 169ms/epoch - 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from DQ_Learning import DQNet\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_path = \"/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model\"\n",
    "model = DQNet()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "            loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "            metrics = 'mae')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(np.array(x_train), np.array(y_train), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3584353.2500 - mae: 3584353.2500\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 266493520.0000 - mae: 266493520.0000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 154.0703 - mae: 154.0703\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 114.6900 - mae: 114.6900\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.4900 - mae: 114.4900\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.2900 - mae: 114.2900\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 114.0900 - mae: 114.0900\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 113.8900 - mae: 113.8900\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.6900 - mae: 113.6900\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.4900 - mae: 113.4900\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.2900 - mae: 113.2900\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 113.0900 - mae: 113.0900\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.8900 - mae: 112.8900\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.6900 - mae: 112.6900\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 112.4900 - mae: 112.4900\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 112.2900 - mae: 112.2900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.0900 - mae: 112.0900\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.8900 - mae: 111.8900\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.6900 - mae: 111.6900\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 111.4900 - mae: 111.4900 - val_loss: 115.6637 - val_mae: 115.6637\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 111.2900 - mae: 111.2900\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 111.0900 - mae: 111.0900\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.8900 - mae: 110.8900\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 110.6900 - mae: 110.6900\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.4900 - mae: 110.4900\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 110.2900 - mae: 110.2900\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.0900 - mae: 110.0900\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.8900 - mae: 109.8900\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.6900 - mae: 109.6900\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 109.4900 - mae: 109.4900\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.2900 - mae: 109.2900\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.0900 - mae: 109.0900\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 108.8900 - mae: 108.8900\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.6900 - mae: 108.6900\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 108.4900 - mae: 108.4900\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.2900 - mae: 108.2900\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.0900 - mae: 108.0900\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 107.8900 - mae: 107.8900\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 107.6900 - mae: 107.6900\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 107.4900 - mae: 107.4900 - val_loss: 111.6637 - val_mae: 111.6637\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.2900 - mae: 107.2900\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.0900 - mae: 107.0900\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.8900 - mae: 106.8900\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.6900 - mae: 106.6900\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 106.4900 - mae: 106.4900\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.2900 - mae: 106.2900\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.0900 - mae: 106.0900\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.8900 - mae: 105.8900\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.6900 - mae: 105.6900\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 105.4900 - mae: 105.4900\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.2900 - mae: 105.2900\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.0900 - mae: 105.0900\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.8900 - mae: 104.8900\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.6900 - mae: 104.6900\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.4900 - mae: 104.4900\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 104.2900 - mae: 104.2900\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 104.0900 - mae: 104.0900\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.8900 - mae: 103.8900\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 103.6900 - mae: 103.6900\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 103.4900 - mae: 103.4900 - val_loss: 107.6637 - val_mae: 107.6637\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.2900 - mae: 103.2900\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.0899 - mae: 103.0899\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.8900 - mae: 102.8900\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 102.6899 - mae: 102.6899\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.4899 - mae: 102.4899\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.2899 - mae: 102.2899\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 102.0899 - mae: 102.0899\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.8899 - mae: 101.8899\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.6899 - mae: 101.6899\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.4899 - mae: 101.4899\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 101.2899 - mae: 101.2899\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.0899 - mae: 101.0899\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.8899 - mae: 100.8899\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 100.6899 - mae: 100.6899\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.4899 - mae: 100.4899\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.2899 - mae: 100.2899\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.0899 - mae: 100.0899\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.8899 - mae: 99.8899\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.6899 - mae: 99.6899\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 99.4899 - mae: 99.4899 - val_loss: 103.6637 - val_mae: 103.6637\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.2899 - mae: 99.2899\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.0899 - mae: 99.0899\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.8899 - mae: 98.8899\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 98.6899 - mae: 98.6899\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.4899 - mae: 98.4899\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.2899 - mae: 98.2899\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.0899 - mae: 98.0899\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.8899 - mae: 97.8899\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 97.6899 - mae: 97.6899\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.4899 - mae: 97.4899\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.2899 - mae: 97.2899\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.0899 - mae: 97.0899\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 96.8899 - mae: 96.8899\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.6899 - mae: 96.6899\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 96.4899 - mae: 96.4899\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.2899 - mae: 96.2899\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.0899 - mae: 96.0899\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.8899 - mae: 95.8899\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.6899 - mae: 95.6899\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 95.4899 - mae: 95.4899 - val_loss: 99.6637 - val_mae: 99.6637\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.2899 - mae: 95.2899\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 95.0899 - mae: 95.0899\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.8899 - mae: 94.8899\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.6899 - mae: 94.6899\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.4899 - mae: 94.4899\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 94.2899 - mae: 94.2899\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.0899 - mae: 94.0899\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.8899 - mae: 93.8899\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.6899 - mae: 93.6899\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.4899 - mae: 93.4899\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.2899 - mae: 93.2899\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.0899 - mae: 93.0899\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 92.8899 - mae: 92.8899\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.6899 - mae: 92.6899\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.4899 - mae: 92.4899\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.2899 - mae: 92.2899\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 92.0899 - mae: 92.0899\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 91.8899 - mae: 91.8899\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 91.6899 - mae: 91.6899\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 91.4899 - mae: 91.4899 - val_loss: 95.6637 - val_mae: 95.6637\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 91.2899 - mae: 91.2899\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 91.0899 - mae: 91.0899\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 90.8899 - mae: 90.8899\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.6899 - mae: 90.6899\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 90.4899 - mae: 90.4899\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 90.2899 - mae: 90.2899\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.0899 - mae: 90.0899\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.8899 - mae: 89.8899\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.6899 - mae: 89.6899\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.4899 - mae: 89.4899\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 89.2899 - mae: 89.2899\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.0899 - mae: 89.0899\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.8899 - mae: 88.8899\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.6899 - mae: 88.6899\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 88.4899 - mae: 88.4899\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.2899 - mae: 88.2899\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.0899 - mae: 88.0899\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.8899 - mae: 87.8899\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 87.6899 - mae: 87.6899\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 87.4899 - mae: 87.4899 - val_loss: 91.6636 - val_mae: 91.6636\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.2899 - mae: 87.2899\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.0899 - mae: 87.0899\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 86.8899 - mae: 86.8899\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.6899 - mae: 86.6899\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.4899 - mae: 86.4899\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.2899 - mae: 86.2899\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.0899 - mae: 86.0899\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.8899 - mae: 85.8899\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 85.6899 - mae: 85.6899\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 85.4899 - mae: 85.4899\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.2899 - mae: 85.2899\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 85.0899 - mae: 85.0899\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 84.8899 - mae: 84.8899\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.6899 - mae: 84.6899\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 84.4899 - mae: 84.4899\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 84.2899 - mae: 84.2899\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.0899 - mae: 84.0899\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 83.8899 - mae: 83.8899\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.6899 - mae: 83.6899\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 83.4899 - mae: 83.4899 - val_loss: 87.6636 - val_mae: 87.6636\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.2899 - mae: 83.2899\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 83.0899 - mae: 83.0899\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.8899 - mae: 82.8899\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 82.6899 - mae: 82.6899\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.4899 - mae: 82.4899\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.2899 - mae: 82.2899\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.0899 - mae: 82.0899\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.8899 - mae: 81.8899\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.6899 - mae: 81.6899\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.4899 - mae: 81.4899\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 81.2899 - mae: 81.2899\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.0899 - mae: 81.0899\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.8899 - mae: 80.8899\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.6899 - mae: 80.6899\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 80.4899 - mae: 80.4899\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 80.2899 - mae: 80.2899\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 80.0899 - mae: 80.0899\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.8899 - mae: 79.8899\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 79.6899 - mae: 79.6899\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 79.4899 - mae: 79.4899 - val_loss: 83.6637 - val_mae: 83.6637\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 79.2899 - mae: 79.2899\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.0899 - mae: 79.0899\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.8899 - mae: 78.8899\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 78.6899 - mae: 78.6899\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.4899 - mae: 78.4899\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.2899 - mae: 78.2899\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.0900 - mae: 78.0900\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.8900 - mae: 77.8900\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.6900 - mae: 77.6900\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.4900 - mae: 77.4900\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.2900 - mae: 77.2900\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.0900 - mae: 77.0900\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.8900 - mae: 76.8900\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 76.6900 - mae: 76.6900\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 76.4900 - mae: 76.4900\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 76.2900 - mae: 76.2900\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.0900 - mae: 76.0900\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 75.8900 - mae: 75.8900\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 75.6900 - mae: 75.6900\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 75.4900 - mae: 75.4900 - val_loss: 79.6637 - val_mae: 79.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4aba668580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.fit(np.array(x_train), np.array(y_train),\n",
    "        batch_size = 64, #每一批batch的大小为32，\n",
    "        epochs = 200, #迭代次数epochs为500\n",
    "        validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "        validation_freq = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)\n",
    "np.shape(target_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa6e5c281c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(target_pos_list[:, 0], target_pos_list[:, 1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1214, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_memory = np.load('../replay_memory_fix.npy', allow_pickle=True)\n",
    "np.shape(replay_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[351.0, 307.0, 119.0, 537.0, 6.0, -323.88269481403296, 351.0, 311.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_memory = np.ndarray.tolist(replay_memory)\n",
    "replay_memory[0]\n",
    "# state_current[0], state_current[1], target_pos[0], target_pos[1], \n",
    "# action_current, reward_current, state_next[0], state_next[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 561]\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    }
   ],
   "source": [
    "from DQ_Learning import environment\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DQNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation = tf.nn.tanh)\n",
    "        self.dense2 = tf.keras.layers.Dense(16, activation = tf.nn.tanh)\n",
    "        self.dense3 = tf.keras.layers.Dense(8, activation = tf.nn.tanh)\n",
    "        self.dense4 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        output = x\n",
    "        return output\n",
    "    \n",
    "    def get_best(self, state_current, target_pos, get_action = True):\n",
    "        action = 1\n",
    "        inputs = tf.constant([[state_current[0], state_current[1], \n",
    "                               target_pos[0], target_pos[1], action]])\n",
    "        value = self.call(inputs = inputs).numpy()[0][0]\n",
    "        # print(\"debug: best q value is: \", value)\n",
    "        \n",
    "        for i in range(8):\n",
    "            # i varies from 0 to 7, action of i+2 varies from 2 to 9\n",
    "            inputs = tf.constant([[state_current[0], state_current[1], \n",
    "                               target_pos[0], target_pos[1], i + 2]])\n",
    "            value_new = self.call(inputs = inputs).numpy()[0][0]\n",
    "            if value <= value_new:\n",
    "                value = value_new\n",
    "                action = i + 2\n",
    "        \n",
    "        return action if get_action else value\n",
    "\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)\n",
    "    \n",
    "target_idx = np.random.randint(0, len(target_pos_list))\n",
    "target_pos = [target_pos_list[target_idx][0], target_pos_list[target_idx][1]]\n",
    "print(target_pos)\n",
    "\n",
    "# checkpoint_path = \"./deepqlearning_model\"\n",
    "# checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "envir = environment()\n",
    "model = DQNet()\n",
    "model.save_weights(\"./predict_model\")\n",
    "model_ = DQNet()\n",
    "model_.load_weights(\"./predict_model\")\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "model_.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_current[0], state_current[1], target_pos[0], target_pos[1], \n",
    "# action_current, reward_current, state_next[0], state_next[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for (i, mini) in enumerate(replay_memory):\n",
    "    if mini[5] >= -10:\n",
    "        y_train.append(mini[5])\n",
    "    else:\n",
    "        value_ = model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False) #gdsqjmfkldjk\n",
    "        y_train.append(mini[5] + 0.9*value_)\n",
    "    x_train.append([mini[0], mini[1], mini[2], mini[3], mini[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.03087"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33055612"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-143.03087"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.load_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/predict_model')\n",
    "model_.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 [==============================] - 1s 2ms/step - loss: 7931.8853 - mae: 74.1926\n",
      "Epoch 2/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8779 - mae: 74.2107\n",
      "Epoch 3/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8613 - mae: 74.1853\n",
      "Epoch 4/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8984 - mae: 74.2028\n",
      "Epoch 5/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9238 - mae: 74.2085\n",
      "Epoch 6/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9004 - mae: 74.1959\n",
      "Epoch 7/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8901 - mae: 74.2034\n",
      "Epoch 8/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9595 - mae: 74.2035\n",
      "Epoch 9/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7932.0176 - mae: 74.2343\n",
      "Epoch 10/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8838 - mae: 74.2006\n",
      "Epoch 11/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8921 - mae: 74.2171\n",
      "Epoch 12/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9248 - mae: 74.2315\n",
      "Epoch 13/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7932.0015 - mae: 74.2101\n",
      "Epoch 14/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9106 - mae: 74.2144\n",
      "Epoch 15/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7932.0537 - mae: 74.2030\n",
      "Epoch 16/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9780 - mae: 74.2132\n",
      "Epoch 17/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9302 - mae: 74.1951\n",
      "Epoch 18/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9136 - mae: 74.1935\n",
      "Epoch 19/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9375 - mae: 74.2037\n",
      "Epoch 20/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8857 - mae: 74.2104\n",
      "Epoch 21/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8447 - mae: 74.2246\n",
      "Epoch 22/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8691 - mae: 74.2104\n",
      "Epoch 23/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.8496 - mae: 74.2021\n",
      "Epoch 24/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9800 - mae: 74.2150\n",
      "Epoch 25/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8857 - mae: 74.2116\n",
      "Epoch 26/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9106 - mae: 74.2057\n",
      "Epoch 27/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8574 - mae: 74.1980\n",
      "Epoch 28/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8882 - mae: 74.2209\n",
      "Epoch 29/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7932.0093 - mae: 74.2104\n",
      "Epoch 30/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8545 - mae: 74.2239\n",
      "Epoch 31/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9092 - mae: 74.2021\n",
      "Epoch 32/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9746 - mae: 74.2168\n",
      "Epoch 33/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9800 - mae: 74.2158\n",
      "Epoch 34/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9810 - mae: 74.2068\n",
      "Epoch 35/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.8804 - mae: 74.2009\n",
      "Epoch 36/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.8726 - mae: 74.2123\n",
      "Epoch 37/50\n",
      "158/158 [==============================] - 0s 3ms/step - loss: 7931.9175 - mae: 74.2187\n",
      "Epoch 38/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7932.0029 - mae: 74.2057\n",
      "Epoch 39/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9351 - mae: 74.2278\n",
      "Epoch 40/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.9185 - mae: 74.2114\n",
      "Epoch 41/50\n",
      "158/158 [==============================] - 0s 2ms/step - loss: 7931.8945 - mae: 74.2065\n",
      "Epoch 42/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8979 - mae: 74.2206\n",
      "Epoch 43/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8662 - mae: 74.2087\n",
      "Epoch 44/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9160 - mae: 74.2039\n",
      "Epoch 45/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9028 - mae: 74.1916\n",
      "Epoch 46/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9424 - mae: 74.2048\n",
      "Epoch 47/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9507 - mae: 74.2089\n",
      "Epoch 48/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9150 - mae: 74.2156\n",
      "Epoch 49/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.8857 - mae: 74.2203\n",
      "Epoch 50/50\n",
      "158/158 [==============================] - 0s 1ms/step - loss: 7931.9858 - mae: 74.2190\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "model_.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=50)\n",
    "model.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/predict_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-191.77814]], dtype=float32)>,\n",
       " -202.739198936567)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(tf.constant([x_train[10]])), y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[42, 320, 420, 524, 1]])).numpy()[0][0] == model.call(inputs = tf.constant([[42, 320, 420, 524, 2]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-191.77817\n",
      "-191.77817\n",
      "-191.77805\n",
      "-191.77795\n",
      "-191.77795\n",
      "-191.7778\n",
      "-191.7778\n",
      "-191.7779\n",
      "-191.77798\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(model.call(inputs = tf.constant([[42, 606, 174, 542, (i+1)*100]])).numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42.0, 606.0, 174.0, 542.0, 8.0, -140.63072210580447, 45.0, 598.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 553]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fa6e5f85610>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DQ_Learning_fix import DQNet, environment, mask_detect, top_detection\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "target_pos = [67, 553] # [120, 110]\n",
    "print(target_pos)\n",
    "\n",
    "checkpoint_path = \"./predict_model\"\n",
    "checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "model = DQNet()\n",
    "envir = environment()\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5449781"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_best([27, 500], target_pos, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.69051754]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.68322617]], dtype=float32)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[59, 505, 67, 553, 1]])), model.call(inputs = tf.constant([[59, 505, 67, 553, 9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ac1aa0e324239271716ea4bc0f1972974f6d8d50c2a2c3470023e155096e31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
