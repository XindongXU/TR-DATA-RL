{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyjoystick.sdl2 import Key, Joystick, run_event_loop\n",
    "from pprint import pprint\n",
    "from threading import Thread\n",
    "import time\n",
    "import serial\n",
    "from sklearn import linear_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set blue thresh\n",
    "lower_green = np.array([35,70,60])\n",
    "upper_green = np.array([120,255,255])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx = 1, fy = 1, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    # edges = cv2.Canny(mask, 100, 200)\n",
    "    cv2.imshow('green edges', mask)\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenpos0 = []\n",
    "greenpos1 = []\n",
    "for (index0,liste) in enumerate(edges):\n",
    "    for (index1,value) in enumerate(liste):\n",
    "        if value == 255:\n",
    "            greenpos0.append(index0)\n",
    "            greenpos1.append(index1)\n",
    "            # print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit(np.array(greenpos0).reshape(-1, 1), np.array(greenpos1).reshape(-1, 1))\n",
    "\n",
    "line_X = np.arange(min(greenpos0), max(greenpos0) + 1)[:, np.newaxis]\n",
    "line_y = ransac.predict(line_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (4.8, 6.4))\n",
    "# plt.xlim((0, 480))\n",
    "# plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(np.array(greenpos0).reshape(-1, 1)[inlier_mask], np.array(greenpos1).reshape(-1, 1)[inlier_mask], s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][-1,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][-1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][0,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Servo_t = [0, 29.85799098, 87.28123918, 49.99237628, 23.27381264], [54.25188891, 14.62139926, 51.21600907, 64.9204633, 113.30784031]\n",
    "\n",
    "A_t = [[-0.96566657, 0.49763318, 0.95705414, -0.62148105, -0.44530939], [0.90419815, -0.66050816, 0.60991016, 0.22840757, 0.80645628]]\n",
    "\n",
    "s_t = [[391, 402, 363, 365, 325], [360, 320, 441, 434, 471]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, 180))\n",
    "plt.ylim((0, 180))\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "print(ret)\n",
    "if ret :\n",
    "    print(ret)\n",
    "    cv2.imwrite('./first_frame.jpg', frame)\n",
    "    # cv2.imshow('test', frame)\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.npy', 'rb') as f:\n",
    "    Servo_t = np.load(f)\n",
    "    A_t = np.load(f)\n",
    "    s_t = np.load(f)\n",
    "    \n",
    "print(np.shape(Servo_t), np.shape(A_t), np.shape(s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[0, 0], s_t[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((-0.1, 180.1))\n",
    "plt.ylim((-0.1, 180.1))\n",
    "# plt.plot(Servo_t[0], Servo_t[1])\n",
    "plt.title('Servo angle inputs')\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(s_pos, target_pos):\n",
    "    # reward(s_t[:, 0], s_t[:, 1])\n",
    "    reward = np.linalg.norm(s_pos - target_pos)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(s_t[0, :]), max(s_t[0, :]), min(s_t[1, :]), max(s_t[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lis)\n",
    "episode = 10\n",
    "file_name = './img' + str(episode) + '.png'\n",
    "plt.savefig(file_name)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "tf.random.set_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(x_train), tf.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #第三步，models.Sequential()\n",
    "# model = tf.keras.models.Sequential([ #使用models.Sequential()来搭建神经网络\n",
    "#     tf.keras.layers.Dense(3, activation = \"softmax\", kernel_regularizer = tf.keras.regularizers.l2()) #全连接层，三个神经元，激活函数为softmax,使用l2正则化\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(irisModel, self).__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(3, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) #搭建网络块，这一层命名为d1\n",
    " \n",
    "    def call(self, x):\n",
    "        y = self.d1(x)\n",
    "        return  y\n",
    "\n",
    "model = irisModel()\n",
    "\n",
    "#第四步，model.compile()\n",
    "model.compile(  #使用model.compile()方法来配置训练方法\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1), #使用SGD优化器，学习率为0.1\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), #配置损失函数\n",
    "    metrics = ['sparse_categorical_accuracy'] #标注网络评价指标\n",
    ")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#第五步，model.fit()\n",
    "model.fit(  #使用model.fit()方法来执行训练过程，\n",
    "    x_train, y_train, #告知训练集的输入以及标签，\n",
    "    batch_size = 32, #每一批batch的大小为32，\n",
    "    epochs = 500, #迭代次数epochs为500\n",
    "    validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "    validation_freq = 20 #测试的间隔次数为20,每迭代20次测试一次准确率\n",
    ")\n",
    "\n",
    "#第六步，model.summary()\n",
    "model.summary() #打印神经网络结构，统计参数数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n",
      "value 0.6450147\n",
      "value -0.08118695\n",
      "value -0.23150498\n",
      "value -0.2319426\n",
      "value 0.59114623\n",
      "value -0.75850475\n",
      "value 0.3269378\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.2580397\n",
      "value -0.40707892\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.75803894\n",
      "value -0.23150408\n",
      "value 0.3095544\n",
      "value 0.26861793\n",
      "value -0.40707913\n",
      "value 0.323735\n",
      "value 0.3612615\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.5911461\n",
      "value 0.59114623\n",
      "value -0.7569668\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -1.4240078\n",
      "value 0.59114456\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.75861394\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.34505898\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.23149645\n",
      "value 0.32373512\n",
      "value -0.12266511\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26173222\n",
      "value 0.59114623\n",
      "value 0.11739713\n",
      "value 0.32373512\n",
      "value -0.6350396\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.3507497\n",
      "value 0.32373512\n",
      "value -0.23390377\n",
      "value -0.75853956\n",
      "value 0.24393946\n",
      "value 0.59107155\n",
      "value -0.2315048\n",
      "value 0.59114623\n",
      "value -0.40707892\n",
      "value 0.27229315\n",
      "value 0.59114623\n",
      "value 0.5911455\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23143107\n",
      "value -0.23150408\n",
      "value -0.0962643\n",
      "value 0.59114623\n",
      "value 0.24426359\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.6473147\n",
      "value -0.40707946\n",
      "value 0.59114623\n",
      "value -0.23150504\n",
      "value 0.59114623\n",
      "value -0.7583641\n",
      "value 0.32373512\n",
      "value 0.5757598\n",
      "value 0.59114623\n",
      "value 0.6472179\n",
      "value -0.39071947\n",
      "value -0.7139146\n",
      "value -0.75861144\n",
      "value 0.5833809\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.107035995\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.52131844\n",
      "value 0.5911359\n",
      "value 0.32373518\n",
      "value -0.23150408\n",
      "value 0.32400388\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4062937\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.66696143\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.74986315\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.3999202\n",
      "value 0.32373512\n",
      "value -0.18752253\n",
      "value -0.23150408\n",
      "value 0.25695825\n",
      "value 0.32373506\n",
      "value -0.23150408\n",
      "value -0.4070795\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.28266996\n",
      "value 0.59114623\n",
      "value 0.5450496\n",
      "value 0.2617566\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75832164\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.059395492\n",
      "value 0.5911342\n",
      "value 0.25877017\n",
      "value -0.23150408\n",
      "value -0.23494434\n",
      "value 0.19940478\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.23992169\n",
      "value 0.59114623\n",
      "value 0.58896184\n",
      "value -0.23150337\n",
      "value 0.59114623\n",
      "value -1.589718\n",
      "value 0.20189095\n",
      "value -0.23150593\n",
      "value 0.32373512\n",
      "value -1.4327105\n",
      "value 0.5911486\n",
      "value 0.59114623\n",
      "value 0.5889333\n",
      "value 0.59114623\n",
      "value 0.64043075\n",
      "value 0.25154275\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.113301694\n",
      "value 0.59114623\n",
      "value 0.32374704\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.4070737\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114635\n",
      "value 0.32373542\n",
      "value 0.32373512\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150426\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.1442657\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32043058\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24398506\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value -0.40707007\n",
      "value 0.59114623\n",
      "value -0.66847324\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23568809\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59062207\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.8216504\n",
      "value 0.32373512\n",
      "value -0.6521405\n",
      "value 0.59114623\n",
      "value -0.53595084\n",
      "value -1.4218881\n",
      "value 0.59081745\n",
      "value 0.59114623\n",
      "value -0.40707096\n",
      "value -0.236976\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.434478\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.26322567\n",
      "value 0.59114623\n",
      "value -1.4240083\n",
      "value 0.3238485\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value -0.23150402\n",
      "value 0.59114623\n",
      "value -0.40707037\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.7586123\n",
      "value 0.59114623\n",
      "value 0.39807868\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114015\n",
      "value 0.3171935\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4241072\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.323736\n",
      "value -1.4240799\n",
      "value 0.3237363\n",
      "value 0.58790904\n",
      "value 0.32373512\n",
      "value -0.23160172\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32373494\n",
      "value -0.40564996\n",
      "value 0.26937127\n",
      "value 0.2519045\n",
      "value 0.59114623\n",
      "value -0.758268\n",
      "value -1.1093247\n",
      "value -0.23150408\n",
      "value -0.4057059\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.323735\n",
      "value 0.59114623\n",
      "value 0.3237365\n",
      "value 0.26171857\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.16182947\n",
      "value -0.23150408\n",
      "value 0.32151467\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.75861496\n",
      "value -0.5814961\n",
      "value -0.23147768\n",
      "value -0.7585298\n",
      "value 0.32373512\n",
      "value 0.19288534\n",
      "value 0.32373512\n",
      "value -0.16298017\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.5911555\n",
      "value -0.7585528\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.58732164\n",
      "value 0.16817391\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.32374054\n",
      "value 0.59114623\n",
      "value -0.46500602\n",
      "value -0.65090376\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.4238759\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.38684246\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.4455415\n",
      "value 0.6261557\n",
      "value 0.5828347\n",
      "value -1.4268783\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59023607\n",
      "value 0.59114623\n",
      "value -0.0017516017\n",
      "value 0.5911459\n",
      "value 0.32373512\n",
      "value -0.75823355\n",
      "value 0.59114623\n",
      "value 0.32373524\n",
      "value 0.2532575\n",
      "value 0.59114623\n",
      "value -0.4070786\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value -0.7586149\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.75850165\n",
      "value 0.3394912\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.31911927\n",
      "value -0.23150408\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -1.425225\n",
      "value 0.32375956\n",
      "value 0.59114623\n",
      "value -0.7303878\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.24417132\n",
      "value -0.23150408\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.34235758\n",
      "value 0.59114623\n",
      "value -0.7586142\n",
      "value 0.32373512\n",
      "value -0.3896213\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.33313137\n",
      "value -1.8681086\n",
      "value 0.32373512\n",
      "value -0.7554165\n",
      "value 0.32373512\n",
      "value -0.47229713\n",
      "value 0.32373512\n",
      "value 0.5880114\n",
      "value 0.59114623\n",
      "value 0.64724827\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -1.7065061\n",
      "value -0.23150408\n",
      "value 0.64731544\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.58265936\n",
      "value 0.64730424\n",
      "value 0.32373512\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value -1.4638419\n",
      "value -1.4243534\n",
      "value 0.038555026\n",
      "value 0.59114623\n",
      "value -1.424041\n",
      "value 0.32373512\n",
      "value -0.23150408\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value -0.40392858\n",
      "value 0.59116817\n",
      "value 0.3237363\n",
      "value 0.59114623\n",
      "value 0.64731544\n",
      "value 0.59114623\n",
      "value -0.40707913\n",
      "value 0.59114623\n",
      "value 0.32373512\n",
      "value 0.59114623\n",
      "value -0.23150408\n",
      "value 0.2618587\n",
      "value 0.25407785\n",
      "value 0.59114623\n",
      "value -0.23141533\n",
      "value 0.59114623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from DQ_Learning import DQNet\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with open('/home/mig5/Desktop/TR_DATA_RL/minibatch.npy', 'rb') as f:\n",
    "    minibatch = np.load(f, allow_pickle=True)\n",
    "    # experience = np.load(f, allow_pickle=True)\n",
    "\n",
    "print(np.shape(minibatch))\n",
    "DQL = DQNet()\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for (i, mini) in enumerate(minibatch):\n",
    "    value_ = DQL.get_best(mini[4], mini[1], get_action = False)\n",
    "    y_train.append(mini[3] + 0.99*value_)\n",
    "    x_train.append([mini[0][0], mini[0][1], mini[1][0], mini[1][1], mini[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 43911.7266 - mae: 176.4142\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42961.1797 - mae: 173.7402\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 42080.9453 - mae: 171.3190\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 41160.9570 - mae: 168.7957\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 40261.5469 - mae: 166.3499\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 39397.1562 - mae: 164.0227\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 38555.3516 - mae: 161.7339\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 37745.5469 - mae: 159.5746\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36959.1992 - mae: 157.4209\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 36196.5859 - mae: 155.3671\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 35456.2969 - mae: 153.3706\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34741.6836 - mae: 151.3696\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 34054.5664 - mae: 149.5234\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33389.0234 - mae: 147.7420\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32739.8125 - mae: 145.9564\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 32113.7520 - mae: 144.2499\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31504.3945 - mae: 142.6024\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30918.2520 - mae: 140.9837\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 30350.4199 - mae: 139.4577\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 29796.1758 - mae: 137.9017\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 29262.9941 - mae: 136.5036\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28744.3262 - mae: 135.1614\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28243.4238 - mae: 133.8305\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27762.1973 - mae: 132.5893\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27288.8711 - mae: 131.3314\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26833.7852 - mae: 130.1387\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26390.3281 - mae: 128.9575\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25961.6270 - mae: 127.8116\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25542.4785 - mae: 126.7358\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 25139.7949 - mae: 125.7031\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24753.1953 - mae: 124.6935\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24377.3809 - mae: 123.7041\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 24010.1055 - mae: 122.7384\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23652.1953 - mae: 121.7681\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 23309.6621 - mae: 120.8753\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22984.3965 - mae: 120.0311\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 22663.7969 - mae: 119.1545\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22350.9238 - mae: 118.3202\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 22049.0117 - mae: 117.5426\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21755.6367 - mae: 116.7803\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21471.0957 - mae: 116.0459\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 21195.8398 - mae: 115.3249\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20930.0957 - mae: 114.6576\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20656.1055 - mae: 113.8095\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20439.8809 - mae: 113.4058\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20202.4180 - mae: 112.8657\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19969.9160 - mae: 112.3102\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19741.5254 - mae: 111.7498\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19523.2656 - mae: 111.2243\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19313.2305 - mae: 110.6964\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 19106.9570 - mae: 110.2009\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18907.6387 - mae: 109.7228\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18713.6836 - mae: 109.2450\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18525.6953 - mae: 108.8038\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18345.1855 - mae: 108.3715\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18168.9609 - mae: 107.9391\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17999.8125 - mae: 107.5385\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17835.6953 - mae: 107.1360\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17678.1680 - mae: 106.7698\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17521.2402 - mae: 106.4004\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17372.3281 - mae: 106.0484\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17228.3242 - mae: 105.7198\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17088.0938 - mae: 105.3729\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16953.1836 - mae: 105.0625\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16822.8848 - mae: 104.7572\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16697.7969 - mae: 104.4642\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16576.6523 - mae: 104.1864\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16457.0078 - mae: 103.8793\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16341.0762 - mae: 103.6008\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16227.4053 - mae: 103.3424\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16119.2041 - mae: 103.0879\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16013.0283 - mae: 102.8249\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15910.7812 - mae: 102.5746\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15812.1904 - mae: 102.3422\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15715.0186 - mae: 102.1018\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15625.0225 - mae: 101.8913\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15537.7480 - mae: 101.6930\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15451.4805 - mae: 101.5118\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15367.4824 - mae: 101.3332\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15287.9961 - mae: 101.1596\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15208.2461 - mae: 100.9981\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15132.9971 - mae: 100.8388\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 15057.3477 - mae: 100.6724\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14985.3047 - mae: 100.5232\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14917.3076 - mae: 100.3893\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14850.8945 - mae: 100.2506\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14786.3232 - mae: 100.1163\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14724.0869 - mae: 99.9976\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14662.5088 - mae: 99.8798\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 14602.9941 - mae: 99.7773\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14545.3027 - mae: 99.6595\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14490.1572 - mae: 99.5771\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14437.2793 - mae: 99.4644\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14385.7305 - mae: 99.3556\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14334.5850 - mae: 99.2675\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14287.1982 - mae: 99.1723\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14240.5811 - mae: 99.0847\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14195.4336 - mae: 98.9959\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14150.3662 - mae: 98.9082\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14107.4785 - mae: 98.8395\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14066.2529 - mae: 98.7546\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14024.7559 - mae: 98.6743\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13985.5186 - mae: 98.5993\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13948.5938 - mae: 98.5330\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13912.7305 - mae: 98.4716\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13877.5020 - mae: 98.4078\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13843.7812 - mae: 98.3567\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13811.6904 - mae: 98.2984\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13780.6494 - mae: 98.2401\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13750.2666 - mae: 98.1944\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13721.4121 - mae: 98.1309\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13691.6836 - mae: 98.1083\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13663.5195 - mae: 98.0451\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13635.7080 - mae: 98.0110\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13608.9502 - mae: 97.9599\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13584.3887 - mae: 97.9247\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13559.9717 - mae: 97.8857\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13535.0312 - mae: 97.8520\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13511.9658 - mae: 97.8063\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13488.9619 - mae: 97.7737\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13467.3164 - mae: 97.7442\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13445.4746 - mae: 97.7047\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13425.2266 - mae: 97.6733\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13405.6943 - mae: 97.6468\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13386.7412 - mae: 97.6331\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13368.7402 - mae: 97.5896\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13349.9209 - mae: 97.5778\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13332.5010 - mae: 97.5485\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13315.8271 - mae: 97.5351\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13299.0957 - mae: 97.5067\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13283.2832 - mae: 97.4858\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13267.3994 - mae: 97.4663\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13253.0977 - mae: 97.4526\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13238.8574 - mae: 97.4311\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13224.7422 - mae: 97.4064\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13211.6973 - mae: 97.3909\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13198.7090 - mae: 97.3757\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13185.8682 - mae: 97.3597\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13174.2832 - mae: 97.3407\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13161.3652 - mae: 97.3225\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13150.6152 - mae: 97.3138\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13140.3887 - mae: 97.2971\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13129.0098 - mae: 97.2807\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13118.6572 - mae: 97.2683\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13108.2197 - mae: 97.2591\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13098.9209 - mae: 97.2490\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13089.2891 - mae: 97.2336\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13080.3818 - mae: 97.2197\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13071.3359 - mae: 97.2106\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13062.1123 - mae: 97.1964\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13053.5723 - mae: 97.1840\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13045.5264 - mae: 97.1754\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13036.3174 - mae: 97.1606\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13028.9824 - mae: 97.1501\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13021.4990 - mae: 97.1424\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13013.9854 - mae: 97.1306\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13006.6924 - mae: 97.1232\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 13000.3799 - mae: 97.1110\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12994.0117 - mae: 97.1037\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12988.2891 - mae: 97.1053\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12982.2432 - mae: 97.0936\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12976.3750 - mae: 97.0865\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12970.6016 - mae: 97.0836\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12965.0225 - mae: 97.0777\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12959.6807 - mae: 97.0715\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12954.6914 - mae: 97.0634\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12949.2451 - mae: 97.0585\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12944.1797 - mae: 97.0509\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12939.5117 - mae: 97.0458\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12935.0918 - mae: 97.0402\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12930.9150 - mae: 97.0341\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12926.2275 - mae: 97.0299\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12922.2822 - mae: 97.0298\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12918.7451 - mae: 97.0231\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12914.8320 - mae: 97.0201\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12911.2529 - mae: 97.0153\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12908.0732 - mae: 97.0127\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12904.6660 - mae: 97.0110\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12901.0000 - mae: 97.0094\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12897.8789 - mae: 97.0044\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12894.3018 - mae: 97.0057\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12891.4170 - mae: 97.0055\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12888.7344 - mae: 97.0018\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12885.6885 - mae: 96.9992\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12882.9297 - mae: 96.9973\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12880.3838 - mae: 96.9991\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12877.5537 - mae: 96.9982\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12875.3291 - mae: 96.9968\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12872.6562 - mae: 96.9967\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12870.1846 - mae: 96.9968\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12867.9541 - mae: 96.9956\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12866.0137 - mae: 96.9947\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12863.9316 - mae: 96.9932\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12862.1211 - mae: 96.9939\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12859.9209 - mae: 96.9918\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12857.5908 - mae: 96.9921\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12855.6924 - mae: 96.9897\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12853.1709 - mae: 96.9921\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12851.2900 - mae: 96.9879\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12849.3672 - mae: 96.9933\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12847.5039 - mae: 96.9900\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12845.5840 - mae: 96.9931\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12843.8418 - mae: 96.9869\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12841.2891 - mae: 96.9866\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12838.1562 - mae: 96.9752\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12833.3584 - mae: 96.9588\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12821.6641 - mae: 96.8969\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12837.2031 - mae: 96.9827\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12835.1719 - mae: 96.9797\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12832.3662 - mae: 96.9691\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12828.9785 - mae: 96.9509\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12823.3281 - mae: 96.9384\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12809.4717 - mae: 96.8384\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12794.8379 - mae: 96.7787\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12784.7607 - mae: 96.7216\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12774.8916 - mae: 96.6588\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12762.3223 - mae: 96.6092\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12760.8291 - mae: 96.6059\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12752.9980 - mae: 96.5644\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12751.1602 - mae: 96.5434\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12746.2412 - mae: 96.5375\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12744.8076 - mae: 96.5232\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12742.5537 - mae: 96.5309\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12739.5186 - mae: 96.5376\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12737.6797 - mae: 96.4874\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12737.4648 - mae: 96.5092\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12734.6445 - mae: 96.5124\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12733.4648 - mae: 96.5102\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.9443 - mae: 96.5047\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12731.5928 - mae: 96.4891\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12729.6426 - mae: 96.4856\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.6123 - mae: 96.5007\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12728.2490 - mae: 96.5000\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12726.3975 - mae: 96.4878\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12725.3057 - mae: 96.4958\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12724.5117 - mae: 96.4895\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12723.5938 - mae: 96.4988\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12722.6602 - mae: 96.4967\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12721.8887 - mae: 96.4935\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.5713 - mae: 96.5011\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12720.0352 - mae: 96.4894\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.9492 - mae: 96.4952\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.5996 - mae: 96.4958\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12717.9990 - mae: 96.5001\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12718.0654 - mae: 96.4934\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12716.5537 - mae: 96.4929\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12715.8887 - mae: 96.5011\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12715.2773 - mae: 96.4966\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.9326 - mae: 96.4978\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3428 - mae: 96.5058\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.9482 - mae: 96.4988\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12713.2080 - mae: 96.5036\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.5029 - mae: 96.5034\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12712.2031 - mae: 96.4985\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.8027 - mae: 96.4996\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.4209 - mae: 96.5063\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12711.1797 - mae: 96.5032\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.3789 - mae: 96.5049\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12710.1426 - mae: 96.5090\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12709.7217 - mae: 96.5018\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12709.3320 - mae: 96.5066\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12709.0068 - mae: 96.5094\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12708.6973 - mae: 96.5108\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12708.6836 - mae: 96.5112\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.8203 - mae: 96.5104\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.5918 - mae: 96.5138\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.4395 - mae: 96.5164\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12707.2002 - mae: 96.5185\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.9561 - mae: 96.5224\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12706.0156 - mae: 96.5172\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12705.8750 - mae: 96.5197\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.5098 - mae: 96.5191\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.6611 - mae: 96.5244\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12705.3096 - mae: 96.5179\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.8604 - mae: 96.5241\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.9004 - mae: 96.5270\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.2715 - mae: 96.5250\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.3672 - mae: 96.5320\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12704.1592 - mae: 96.5285\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.8555 - mae: 96.5293\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.6934 - mae: 96.5327\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.3857 - mae: 96.5334\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1631 - mae: 96.5354\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12703.1123 - mae: 96.5319\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8857 - mae: 96.5339\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.7695 - mae: 96.5359\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12702.8047 - mae: 96.5374\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3965 - mae: 96.5324\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.5371 - mae: 96.5414\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3857 - mae: 96.5419\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.3721 - mae: 96.5393\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12702.0371 - mae: 96.5386\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.9082 - mae: 96.5440\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4941 - mae: 96.5416\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.4326 - mae: 96.5407\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.5996 - mae: 96.5454\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.3867 - mae: 96.5460\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12701.4404 - mae: 96.5454\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.9082 - mae: 96.5460\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12701.0137 - mae: 96.5482\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.7109 - mae: 96.5471\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5501\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.6436 - mae: 96.5535\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12700.4160 - mae: 96.5527\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.5430 - mae: 96.5557\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.2900 - mae: 96.5569\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.1016 - mae: 96.5510\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12700.0576 - mae: 96.5565\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9326 - mae: 96.5559\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12700.0088 - mae: 96.5583\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.9141 - mae: 96.5558\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.5293 - mae: 96.5592\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6016 - mae: 96.5632\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.7227 - mae: 96.5628\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.6914 - mae: 96.5625\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.4219 - mae: 96.5609\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12699.3857 - mae: 96.5603\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.5098 - mae: 96.5665\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.5947 - mae: 96.5647\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.4619 - mae: 96.5663\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1182 - mae: 96.5664\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12699.0762 - mae: 96.5675\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12699.1240 - mae: 96.5691\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.9414 - mae: 96.5683\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7988 - mae: 96.5675\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.7480 - mae: 96.5697\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7266 - mae: 96.5693\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7402 - mae: 96.5702\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.6602 - mae: 96.5683\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.5059 - mae: 96.5703\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7832 - mae: 96.5713\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7559 - mae: 96.5734\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.7783 - mae: 96.5760\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3975 - mae: 96.5749\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2959 - mae: 96.5753\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4893 - mae: 96.5785\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3916 - mae: 96.5777\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.2676 - mae: 96.5737\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4551 - mae: 96.5769\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0908 - mae: 96.5749\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2539 - mae: 96.5765\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1836 - mae: 96.5755\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2588 - mae: 96.5768\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2715 - mae: 96.5749\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1885 - mae: 96.5745\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3535 - mae: 96.5724\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1328 - mae: 96.5780\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0781 - mae: 96.5784\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9814 - mae: 96.5753\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.2754 - mae: 96.5787\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1719 - mae: 96.5781\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1221 - mae: 96.5777\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.4863 - mae: 96.5799\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9922 - mae: 96.5788\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1084 - mae: 96.5754\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8721 - mae: 96.5787\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2793 - mae: 96.5770\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9697 - mae: 96.5773\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.3027 - mae: 96.5815\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0791 - mae: 96.5795\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1396 - mae: 96.5809\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6758 - mae: 96.5795\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6377 - mae: 96.5766\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8604 - mae: 96.5793\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6318 - mae: 96.5790\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12698.1182 - mae: 96.5813\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9600 - mae: 96.5825\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7930 - mae: 96.5810\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7754 - mae: 96.5806\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0039 - mae: 96.5794\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.8994 - mae: 96.5821\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8828 - mae: 96.5803\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9736 - mae: 96.5806\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.1143 - mae: 96.5823\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0332 - mae: 96.5833\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9707 - mae: 96.5844\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7754 - mae: 96.5852\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12698.1230 - mae: 96.5833\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7314 - mae: 96.5817\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6465 - mae: 96.5794\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6846 - mae: 96.5824\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.0215 - mae: 96.5842\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8096 - mae: 96.5829\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6533 - mae: 96.5827\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7207 - mae: 96.5809\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6992 - mae: 96.5833\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5322 - mae: 96.5853\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7832 - mae: 96.5892\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7451 - mae: 96.5853\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8984 - mae: 96.5893\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.9404 - mae: 96.5885\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5400 - mae: 96.5857\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7656 - mae: 96.5895\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.7373 - mae: 96.5890\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4033 - mae: 96.5882\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4980 - mae: 96.5880\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5723 - mae: 96.5876\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.4434 - mae: 96.5878\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.6914 - mae: 96.5889\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6924 - mae: 96.5906\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5830 - mae: 96.5893\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4160 - mae: 96.5878\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6914 - mae: 96.5902\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5098 - mae: 96.5882\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.8174 - mae: 96.5891\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5703 - mae: 96.5890\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5645 - mae: 96.5900\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6133 - mae: 96.5882\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4385 - mae: 96.5876\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12698.2510 - mae: 96.5921\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4854 - mae: 96.5878\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5791 - mae: 96.5848\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5866\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4268 - mae: 96.5872\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5264 - mae: 96.5876\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.6689 - mae: 96.5905\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.8066 - mae: 96.5892\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6016 - mae: 96.5901\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4258 - mae: 96.5875\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12697.5361 - mae: 96.5904\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5566 - mae: 96.5901\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12697.2920 - mae: 96.5907\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3457 - mae: 96.5940\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.3418 - mae: 96.5917\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1260 - mae: 96.5914\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2939 - mae: 96.5923\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3262 - mae: 96.5932\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2480 - mae: 96.5914\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2959 - mae: 96.5928\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12697.2285 - mae: 96.5929\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4326 - mae: 96.5925\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5352 - mae: 96.5969\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5459 - mae: 96.5967\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5922\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.7383 - mae: 96.5944\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4043 - mae: 96.5955\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2607 - mae: 96.5949\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6260 - mae: 96.5938\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.1953 - mae: 96.5913\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4785 - mae: 96.5968\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.6729 - mae: 96.5953\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3594 - mae: 96.5958\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2871 - mae: 96.5943\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3154 - mae: 96.5958\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4902 - mae: 96.5947\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.5215 - mae: 96.5948\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3164 - mae: 96.5942\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5936\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.4102 - mae: 96.5920\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12697.5332 - mae: 96.5923\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3428 - mae: 96.5915\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1494 - mae: 96.5927\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.3330 - mae: 96.5943\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1436 - mae: 96.5942\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.1543 - mae: 96.5944\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.0996 - mae: 96.5930\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2627 - mae: 96.5943\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12697.2861 - mae: 96.5932\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12714.3096 - mae: 96.7425\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9707 - mae: 97.2263\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1328 - mae: 97.2280\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0820 - mae: 97.2281\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0918 - mae: 97.2267\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.2451 - mae: 97.2232\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0742 - mae: 97.2267\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1582 - mae: 97.2268\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0303 - mae: 97.2220\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9443 - mae: 97.2247\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0938 - mae: 97.2251\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8838 - mae: 97.2231\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1865 - mae: 97.2225\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9189 - mae: 97.2233\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0801 - mae: 97.2216\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0166 - mae: 97.2219\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9062 - mae: 97.2210\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.1768 - mae: 97.2217\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12798.1816 - mae: 97.2213\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.8877 - mae: 97.2206\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.0420 - mae: 97.2207\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7197 - mae: 97.2174\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.9365 - mae: 97.2189\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7744 - mae: 97.2172\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.0508 - mae: 97.2171\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7891 - mae: 97.2165\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.7510 - mae: 97.2151\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12797.6504 - mae: 97.2126\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.6914 - mae: 97.2126\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7041 - mae: 97.2117\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9668 - mae: 97.2124\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12798.2080 - mae: 97.2113\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8975 - mae: 97.2141\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.9854 - mae: 97.2146\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8623 - mae: 97.2117\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12797.8057 - mae: 97.2138\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 12797.7588 - mae: 97.2136\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8438 - mae: 97.2146\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8369 - mae: 97.2157\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8457 - mae: 97.2135\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12798.4336 - mae: 97.2147\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 12797.8789 - mae: 97.2152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f48fdaea6a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_path = \"cp.ckpt\"\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "DQL.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "DQL.fit(np.array(x_train),\n",
    "        np.array(y_train),\n",
    "        epochs=500)\n",
    "# DQL.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.get_best(mini[4], mini[1], get_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 16.2087 - mae: 16.2087 - 169ms/epoch - 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from DQ_Learning import DQNet\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_path = \"/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model\"\n",
    "model = DQNet()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "            loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "            metrics = 'mae')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(np.array(x_train), np.array(y_train), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3584353.2500 - mae: 3584353.2500\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 266493520.0000 - mae: 266493520.0000\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 154.0703 - mae: 154.0703\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 114.6900 - mae: 114.6900\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.4900 - mae: 114.4900\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 114.2900 - mae: 114.2900\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 114.0900 - mae: 114.0900\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 113.8900 - mae: 113.8900\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.6900 - mae: 113.6900\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.4900 - mae: 113.4900\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 113.2900 - mae: 113.2900\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 113.0900 - mae: 113.0900\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.8900 - mae: 112.8900\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.6900 - mae: 112.6900\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 112.4900 - mae: 112.4900\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 112.2900 - mae: 112.2900\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 112.0900 - mae: 112.0900\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.8900 - mae: 111.8900\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 111.6900 - mae: 111.6900\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 111.4900 - mae: 111.4900 - val_loss: 115.6637 - val_mae: 115.6637\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 111.2900 - mae: 111.2900\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 111.0900 - mae: 111.0900\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.8900 - mae: 110.8900\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 110.6900 - mae: 110.6900\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.4900 - mae: 110.4900\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 110.2900 - mae: 110.2900\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 110.0900 - mae: 110.0900\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.8900 - mae: 109.8900\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.6900 - mae: 109.6900\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 109.4900 - mae: 109.4900\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.2900 - mae: 109.2900\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 109.0900 - mae: 109.0900\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 108.8900 - mae: 108.8900\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.6900 - mae: 108.6900\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 108.4900 - mae: 108.4900\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.2900 - mae: 108.2900\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 108.0900 - mae: 108.0900\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 107.8900 - mae: 107.8900\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 107.6900 - mae: 107.6900\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 107.4900 - mae: 107.4900 - val_loss: 111.6637 - val_mae: 111.6637\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.2900 - mae: 107.2900\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.0900 - mae: 107.0900\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.8900 - mae: 106.8900\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.6900 - mae: 106.6900\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 106.4900 - mae: 106.4900\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 106.2900 - mae: 106.2900\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 106.0900 - mae: 106.0900\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.8900 - mae: 105.8900\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.6900 - mae: 105.6900\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 105.4900 - mae: 105.4900\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.2900 - mae: 105.2900\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 105.0900 - mae: 105.0900\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.8900 - mae: 104.8900\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.6900 - mae: 104.6900\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 104.4900 - mae: 104.4900\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 104.2900 - mae: 104.2900\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 104.0900 - mae: 104.0900\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.8900 - mae: 103.8900\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 103.6900 - mae: 103.6900\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 103.4900 - mae: 103.4900 - val_loss: 107.6637 - val_mae: 107.6637\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.2900 - mae: 103.2900\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 103.0899 - mae: 103.0899\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.8900 - mae: 102.8900\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 102.6899 - mae: 102.6899\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.4899 - mae: 102.4899\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 102.2899 - mae: 102.2899\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 102.0899 - mae: 102.0899\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.8899 - mae: 101.8899\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.6899 - mae: 101.6899\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.4899 - mae: 101.4899\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 101.2899 - mae: 101.2899\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 101.0899 - mae: 101.0899\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.8899 - mae: 100.8899\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 100.6899 - mae: 100.6899\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.4899 - mae: 100.4899\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.2899 - mae: 100.2899\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 100.0899 - mae: 100.0899\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.8899 - mae: 99.8899\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.6899 - mae: 99.6899\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 99.4899 - mae: 99.4899 - val_loss: 103.6637 - val_mae: 103.6637\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 99.2899 - mae: 99.2899\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 99.0899 - mae: 99.0899\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.8899 - mae: 98.8899\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 98.6899 - mae: 98.6899\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.4899 - mae: 98.4899\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.2899 - mae: 98.2899\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 98.0899 - mae: 98.0899\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.8899 - mae: 97.8899\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 97.6899 - mae: 97.6899\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 97.4899 - mae: 97.4899\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.2899 - mae: 97.2899\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 97.0899 - mae: 97.0899\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 96.8899 - mae: 96.8899\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.6899 - mae: 96.6899\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 96.4899 - mae: 96.4899\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.2899 - mae: 96.2899\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 96.0899 - mae: 96.0899\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.8899 - mae: 95.8899\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 95.6899 - mae: 95.6899\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 95.4899 - mae: 95.4899 - val_loss: 99.6637 - val_mae: 99.6637\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.2899 - mae: 95.2899\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 95.0899 - mae: 95.0899\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.8899 - mae: 94.8899\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 94.6899 - mae: 94.6899\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.4899 - mae: 94.4899\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 94.2899 - mae: 94.2899\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 94.0899 - mae: 94.0899\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.8899 - mae: 93.8899\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 93.6899 - mae: 93.6899\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.4899 - mae: 93.4899\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 93.2899 - mae: 93.2899\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.0899 - mae: 93.0899\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 92.8899 - mae: 92.8899\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.6899 - mae: 92.6899\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.4899 - mae: 92.4899\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.2899 - mae: 92.2899\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 92.0899 - mae: 92.0899\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 91.8899 - mae: 91.8899\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 91.6899 - mae: 91.6899\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 91.4899 - mae: 91.4899 - val_loss: 95.6637 - val_mae: 95.6637\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 91.2899 - mae: 91.2899\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 91.0899 - mae: 91.0899\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 90.8899 - mae: 90.8899\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.6899 - mae: 90.6899\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 90.4899 - mae: 90.4899\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 90.2899 - mae: 90.2899\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 90.0899 - mae: 90.0899\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.8899 - mae: 89.8899\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.6899 - mae: 89.6899\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.4899 - mae: 89.4899\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 89.2899 - mae: 89.2899\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 89.0899 - mae: 89.0899\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.8899 - mae: 88.8899\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.6899 - mae: 88.6899\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 88.4899 - mae: 88.4899\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.2899 - mae: 88.2899\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 88.0899 - mae: 88.0899\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.8899 - mae: 87.8899\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 87.6899 - mae: 87.6899\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 87.4899 - mae: 87.4899 - val_loss: 91.6636 - val_mae: 91.6636\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.2899 - mae: 87.2899\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 87.0899 - mae: 87.0899\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 86.8899 - mae: 86.8899\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.6899 - mae: 86.6899\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.4899 - mae: 86.4899\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.2899 - mae: 86.2899\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 86.0899 - mae: 86.0899\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.8899 - mae: 85.8899\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 85.6899 - mae: 85.6899\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 85.4899 - mae: 85.4899\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.2899 - mae: 85.2899\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 85.0899 - mae: 85.0899\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 84.8899 - mae: 84.8899\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.6899 - mae: 84.6899\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 84.4899 - mae: 84.4899\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 84.2899 - mae: 84.2899\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.0899 - mae: 84.0899\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 83.8899 - mae: 83.8899\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.6899 - mae: 83.6899\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 83.4899 - mae: 83.4899 - val_loss: 87.6636 - val_mae: 87.6636\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.2899 - mae: 83.2899\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 83.0899 - mae: 83.0899\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.8899 - mae: 82.8899\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 82.6899 - mae: 82.6899\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.4899 - mae: 82.4899\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 82.2899 - mae: 82.2899\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.0899 - mae: 82.0899\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.8899 - mae: 81.8899\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.6899 - mae: 81.6899\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.4899 - mae: 81.4899\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 81.2899 - mae: 81.2899\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 81.0899 - mae: 81.0899\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.8899 - mae: 80.8899\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 80.6899 - mae: 80.6899\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 80.4899 - mae: 80.4899\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 80.2899 - mae: 80.2899\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 80.0899 - mae: 80.0899\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.8899 - mae: 79.8899\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 79.6899 - mae: 79.6899\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 79.4899 - mae: 79.4899 - val_loss: 83.6637 - val_mae: 83.6637\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 79.2899 - mae: 79.2899\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 79.0899 - mae: 79.0899\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.8899 - mae: 78.8899\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 78.6899 - mae: 78.6899\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.4899 - mae: 78.4899\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.2899 - mae: 78.2899\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 78.0900 - mae: 78.0900\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.8900 - mae: 77.8900\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.6900 - mae: 77.6900\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 77.4900 - mae: 77.4900\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.2900 - mae: 77.2900\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 77.0900 - mae: 77.0900\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.8900 - mae: 76.8900\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 76.6900 - mae: 76.6900\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 76.4900 - mae: 76.4900\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 76.2900 - mae: 76.2900\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 76.0900 - mae: 76.0900\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 75.8900 - mae: 75.8900\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 75.6900 - mae: 75.6900\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 75.4900 - mae: 75.4900 - val_loss: 79.6637 - val_mae: 79.6637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4aba668580>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQL.fit(np.array(x_train), np.array(y_train),\n",
    "        batch_size = 64, #每一批batch的大小为32，\n",
    "        epochs = 200, #迭代次数epochs为500\n",
    "        validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "        validation_freq = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pos_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd4880e61c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAIYCAYAAAAxe9hSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqOklEQVR4nO3df3RU5YH/8U9CfvBzJgZJhhwTQKXFVFALGKa6p0dJiZq6tebsVg/alKXylQ0WiKVrdhVbtsdw6DlV6Cps6xb4nqrsst/FVgrY8EOoOgSIsuXXRlBqUJhklWYGqEx+Pd8/JNcORJJJJjPzTN6vc+45ufc+M/PcB53PPM997r0pxhgjAAASXGq8KwAAQE8QWAAAKxBYAAArEFgAACsQWAAAKxBYAAArEFgAACukxbsCvdHR0aGTJ09qxIgRSklJiXd1AAC9ZIzRmTNnlJeXp9TUy/ehrAyskydPKj8/P97VAABEyYkTJ3TVVVddtoyVgTVixAhJnx6gy+WKc20AAL0VDAaVn5/vfK9fjpWB1TkM6HK5CCwASAI9Ob3DpAsAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBWsvFs7EKm29g49u+Nd7f3jaU0dm62K265R2iB+rwE2IbAwIDy74109s/UdGUlvHPtIkjS/eHx8KwUgIgQWEl40ekd7/3ha5sLf5sJ6ItUPQPcILCS8aPSOpo7N1hvHPpKRlHJhPZHqB6B7BBYSXjR6RxW3XeO8V2cvKJHqB6B7BBYSXjR6R2mDUvut19OfvTcAnyGwkPD6s3cUDYlePyBZpBhjTPfFEkswGJTb7VYgEJDL5Yp3dYCoYhIHBpJIvs/pYQEJhkkcQNf42QYkGCZxAF0jsIAEM3VstlIu/M0kDuAzEQfWhx9+qAceeEAjR47UkCFDNHHiRO3bt8/Zb4zR4sWLNXr0aA0ZMkTFxcU6evRo2HucPn1aM2fOlMvlUlZWlmbPnq2zZ8/2/WiAJFBx2zVaUPwF3XrtlVpQ/IUeTeJoa+/Q8q1H9cDztVq+9aja2jtiUFMgtiI6h/WnP/1Jt9xyi2677TZt3rxZo0aN0tGjR3XFFVc4ZZYtW6YVK1Zo7dq1GjdunJ544gmVlJTo8OHDGjx4sCRp5syZOnXqlGpqatTa2qpZs2Zpzpw5evHFF6N7dICFejMFn/NeGAgimiX42GOP6Y033tDvf//7LvcbY5SXl6dHH31U3//+9yVJgUBAubm5WrNmje677z4dOXJEhYWF2rt3r6ZMmSJJ2rJli+666y598MEHysvL67YezBKMP2ayJZYHnq/V6xeCSpJuvfZK/eq7RXGsEdAzkXyfR/QN85vf/EZTpkzR3/zN3ygnJ0c33XSTfvGLXzj7jx8/Lr/fr+LiYmeb2+1WUVGRfD6fJMnn8ykrK8sJK0kqLi5Wamqqamtru/zcUCikYDAYtiC+On/Rv37sIz2z9R09u+PdeFdpQOO8FwaCiALrvffe08qVKzV+/Hi9+uqrmjt3rr73ve9p7dq1kiS/3y9Jys3NDXtdbm6us8/v9ysnJydsf1pamrKzs50yF6uurpbb7XaW/Pz8SKqNfsBMtsTSm/NegG0iOofV0dGhKVOm6KmnnpIk3XTTTTp48KBWrVql8vLyfqmgJFVVVamystJZDwaDhFYUnf2kRXeseF3+wHl53IO15Xu3aviQjMu+htsRJZb+vPUUkCgi6mGNHj1ahYWFYduuu+46NTQ0SJI8Ho8kqbGxMaxMY2Ojs8/j8aipqSlsf1tbm06fPu2UuVhmZqZcLlfYgui5Y8Xr+uBPn6itw+iDP32iO1a83u1r+EUPINYi6mHdcsstqq+vD9v2zjvvaMyYMZKkcePGyePxaNu2bbrxxhslfdobqq2t1dy5cyVJXq9Xzc3Nqqur0+TJkyVJ27dvV0dHh4qKOEkcD6eaP7lkvbtJFfyiBxBrEQXWwoUL9ZWvfEVPPfWU/vZv/1Z79uzRz3/+c/385z+XJKWkpGjBggX68Y9/rPHjxzvT2vPy8nTPPfdI+rRHdscdd+ihhx7SqlWr1Nraqnnz5um+++7r0QxBRN+wzDQFz7eFrUdzmnRPZxQy8xDA5UQUWFOnTtWGDRtUVVWlJUuWaNy4cXrmmWc0c+ZMp8wPfvADnTt3TnPmzFFzc7NuvfVWbdmyxbkGS5JeeOEFzZs3T9OnT1dqaqrKysq0YsWK6B0VIvKlPJd8750OW4/mpIqehh/XEgG4nIhvfvv1r39dX//61z93f0pKipYsWaIlS5Z8bpns7GwuEk4g066+UrvfO+1MoJh29ZWSFLVJFT0NP2Yexh+9XCQy7taOyz7PKRrPeOrpjEJmHsYfvVwkMgILnzuBIlpfVD19wCEPQow/erlIZAQW+l1PZxQy8zD+6OUikRFYABz0cpHICCwADnq5SGRM/wEAWIHAAgBYgSFBWInrhRIH/xaIFQILVuJ6ocTBvwVihZ9BsBLXCyUO/i0QKwQWrMQTdhMH/xaIFYYEYSWuF0oc/FsgVlKMMab7YoklGAzK7XYrEAjwMEcAsFgk3+cMCQIArMCQIAYMpl8DdiOwMGAw/RqwGz8vMWAw/RqwG4GFAYPp14DdGBLEgMH06/jjPCL6gsDCgMGjM+KP84joC37aAIgZziOiLwgsoBtt7R1avvWoHni+Vsu3HlVbe0e8q2QtziOiLxgSBLrBMFb0cB4RfUFgAd1gGCt6OI+IvmBIEOgGw1ixwdArukMPC+gGw1ixwdArukNgAd1gGCs2GHpFdxgSBJAQGHpFd+hhAUgIDL2iOwQWgITA0Cu6Q2ABUcJ98oD+RWABUcIsN6B/8fMPiBJmuQH9i8ACooRZbkD/YkgQiBJmufUfzg9CIrCAqGGWW/9ZvvUd/WzHu5Kk1499pLb2dj1aMiHOtUKs8RMFQML7v7vfv+w6BgYCC0DCC7V2XHYdAwOBBSDh3Zifddl1DAwEFhBjPEYjcmtmTZX36pHKGpIu79UjtWbW1HhXCXHApAsgxrjAOHKDM9L00pxp8a4G4oweFhBjXGAM9A6BBcRYIl1gzPAkbMKQIBBjiXSBMcOTsAmBBcRYIl1gzPAkbMKQIDCAJdLwJNAdeljAAJZIw5PRwD0HkxuBBSSw8y1tmrVmn46cCuq60S6t/s4UDc6I3v+2iTQ8GQ2ck0tu/PQAEtisNfvke+9jNX/SKt97H2vWmn3xrlJC45xcciOwgAR25FTwsuuJIJGmxnNOLrkxJAgksOtGu+R77+Ow9a7E89xNIg3DJds5OYQjsIAEtvo7Uy45h9WVeIZGIg3DJds5OYQjsIAE1tN76MUzNKaOzdYbxz6SEcNw6F8EFpAE4hkaDMMhVggsIAnEMzQYhkOsEFhAEiA0MBAwrR0AYAV6WADigtsoIVIEFoC4SKTrt2AHAgtAXMRzKj69OzsRWADiIp5T8end2YnAAhAX8ZyKn0h350DPEVgA4iKeU/G5O4edCCwAAw5357ATgQXAOn2dNMGF1nYisABYh0kTA1NE8zh/+MMfKiUlJWyZMGGCs//8+fOqqKjQyJEjNXz4cJWVlamxsTHsPRoaGlRaWqqhQ4cqJydHixYtUltbW3SOBsCAwKSJgSniHtaXvvQlbd269bM3SPvsLRYuXKjf/va3Wr9+vdxut+bNm6d7771Xb7zxhiSpvb1dpaWl8ng8evPNN3Xq1Cl9+9vfVnp6up566qkoHA6QXLheqGtMmhiYIg6stLQ0eTyeS7YHAgH927/9m1588UXdfvvtkqTVq1fruuuu0+7duzVt2jT97ne/0+HDh7V161bl5ubqxhtv1D//8z/rH/7hH/TDH/5QGRkZfT8iIIkw9NU1Jk0MTBH/VDt69Kjy8vJ09dVXa+bMmWpoaJAk1dXVqbW1VcXFxU7ZCRMmqKCgQD6fT5Lk8/k0ceJE5ebmOmVKSkoUDAZ16NChz/3MUCikYDAYtgADAUNfXeucNPGr7xZpfvF4ep0DRET/ykVFRVqzZo22bNmilStX6vjx4/qrv/ornTlzRn6/XxkZGcrKygp7TW5urvx+vyTJ7/eHhVXn/s59n6e6ulput9tZ8vPzI6k2YK2pY7OVcuFvhr4w0EU0JHjnnXc6f0+aNElFRUUaM2aM/uM//kNDhgyJeuU6VVVVqbKy0lkPBoOEFgYEhr6Az/RpWntWVpa+8IUv6NixY/ra176mlpYWNTc3h/WyGhsbnXNeHo9He/bsCXuPzlmEXZ0X65SZmanMzMy+VBWwEtcLAZ/p08Dv2bNn9e6772r06NGaPHmy0tPTtW3bNmd/fX29Ghoa5PV6JUler1cHDhxQU1OTU6ampkYul0uFhYV9qQoAIMlF1MP6/ve/r7vvvltjxozRyZMn9eSTT2rQoEG6//775Xa7NXv2bFVWVio7O1sul0uPPPKIvF6vpk2bJkmaMWOGCgsL9eCDD2rZsmXy+/16/PHHVVFRQQ8KAHBZEQXWBx98oPvvv18ff/yxRo0apVtvvVW7d+/WqFGjJElPP/20UlNTVVZWplAopJKSEj333HPO6wcNGqSNGzdq7ty58nq9GjZsmMrLy7VkyZLoHhUAXMC1bMkjxRhjui+WWILBoNxutwKBgFwuV7yrAyCBLd961LmWLUXSguIvcF4wgUTyfc7PDABJjWvZkgeBBSCpcS1b8uBu7QCSGteyJQ8CC0BS649r2ZjIER8EFgBEiJsSxwc/CQAgQkzkiA8CCwAixESO+GBIEAAu6Om5KSZyxAeBBQAX9PTcFDcljg+GBAHgAs5NJTYCCwAu4NxUYmNIEAAu4NxUYiOwAOACzk0lNoYEAQBWILAAAFYgsAAAViCwAABWILAAAFYgsAAAViCwAABWILAAAFbgwmEA6CWePBxbBBYA9BJPHo4tfgoAQC9xd/fYIrAAoJd6enf3tvYOLd96VA88X6vlW4+qrb0jZnVMJgwJAkAv9fTu7gwdRgeBBQC91NO7uzN0GB0MCQJAP+PBkNFBDwsA+hkPhowOAgsA+hkPhowOhgQBAFYgsAAAViCwAABWILAAAFYgsAAAViCwAABWYFo7AMQAjyLpOwILAGKA+wn2HfEOADHA/QT7jsACgBjgfoJ9x5AgAMQA9xPsOwILAGKA+wn2HUOCAAArEFgAACsQWAAAKxBYAAArEFgAACsQWAAAKzCtHQASBPcbvDwCCwASBPcbvDyiGwASBPcbvDx6WAAQR385DNjeYZzt3G/wUgQWAMTRXw4DpkjyXj1Sg1JTuN9gFwgsAIiji4cBB6Wm6FffLYpnlRIW57AAII547EjP0cMCgDjisSM9R2ABQBzx2JGeY0gQAGAFAgsAYAUCCwBgBQILAGAFAgsAYAUCCwBgBQILAGAFrsMCgATF87HCEVgAkKB4Pla4PkX10qVLlZKSogULFjjbzp8/r4qKCo0cOVLDhw9XWVmZGhsbw17X0NCg0tJSDR06VDk5OVq0aJHa2tr6UhUASDo8HytcrwNr7969+td//VdNmjQpbPvChQv1yiuvaP369dq5c6dOnjype++919nf3t6u0tJStbS06M0339TatWu1Zs0aLV68uPdHAQBJiBvjXsT0wpkzZ8z48eNNTU2N+epXv2rmz59vjDGmubnZpKenm/Xr1ztljxw5YiQZn89njDFm06ZNJjU11fj9fqfMypUrjcvlMqFQqEefHwgEjCQTCAR6U30AsEJrW7t5puYdM/MXu80zNe+Y1rb2eFcp6iL5Pu9VD6uiokKlpaUqLi4O215XV6fW1taw7RMmTFBBQYF8Pp8kyefzaeLEicrNzXXKlJSUKBgM6tChQ11+XigUUjAYDFsAINl13hj3V98t0vzi8QN6woXUi0kX69at01tvvaW9e/dess/v9ysjI0NZWVlh23Nzc+X3+50yfxlWnfs793WlurpaP/rRjyKtKgAgiUQU1ydOnND8+fP1wgsvaPDgwf1Vp0tUVVUpEAg4y4kTJ2L22QCQCNraO7R861E98Hytlm89qrb2jnhXKeYi6mHV1dWpqalJX/7yl51t7e3t2rVrl/7lX/5Fr776qlpaWtTc3BzWy2psbJTH45EkeTwe7dmzJ+x9O2cRdpa5WGZmpjIzMyOpKgAkFaa4R9jDmj59ug4cOKD9+/c7y5QpUzRz5kzn7/T0dG3bts15TX19vRoaGuT1eiVJXq9XBw4cUFNTk1OmpqZGLpdLhYWFUTosAEguTHGPsIc1YsQIXX/99WHbhg0bppEjRzrbZ8+ercrKSmVnZ8vlcumRRx6R1+vVtGnTJEkzZsxQYWGhHnzwQS1btkx+v1+PP/64Kioq6EUBwOeYOjZbbxz7SEYDd4p71O908fTTTys1NVVlZWUKhUIqKSnRc8895+wfNGiQNm7cqLlz58rr9WrYsGEqLy/XkiVLol0VAEgaFbddI0lht2kaaFKMMab7YoklGAzK7XYrEAjI5XLFuzoAgF6K5Pt8YE/qBwBYg8ACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYIeqPFwEA9L+29g49u+PdsMeNpA1K7j4IgQUAFnp2x7t6Zus7MpLeOPaRJGl+8fj4VqqfJXccA0ASamvv0P976wN1PszQ6NMHOyY7AgsALPPsjnfVcPrPYdumjs2OU21ih8ACAMtc3JsqyB6qituuiVNtYofAAgDLTB2brZQLf6dIKvvyVUk/4UJi0gUAWKezN/WXMwQHAgILACyTNig16WcEdiX5+5AAgKRAYAEArEBgAQCsQGABAKxAYAEArEBgAQCsQGABAKxAYAEArEBgAQCsQGABAKzArZkAwHID5enDBBYAWG6gPH04+SIYAAaYvX88PSCePkxgAYDlJhdccdn1ZEFgAYDtUszl15MEgQUAlqt7v/my68mCwAIAy00dm62UC3+nXFhPRswSBADLVdx2jSSFTWtPRgQWAFgubVBqUk5jvxhDggAAKxBYAAArEFgAACsQWAAAKxBYAAArEFgAACswrR0ALMfjRQAAVli+9R39bMe7kqTXj32ktvZ2PVoyIc61ir7ki2AAsFxbe4eWbz2qB56v1fKtR9XW3nHZ8v93d8Nl15MFPSwASDCRPJCxrb1DZ0NtYdtCre39XcW4oIcFAAkmkgcyPrvjXbV3hD9O5Iar3P1XuTgisAAgwURy9/Xa9z66ZNuUAu7WDgCIgUjuvt7wp08u2fbKwVNadFfyTbogsAAgwURy9/Uz51v7uTaJgyFBALBY4ehLz1d986a8ONSk/xFYAGCx1d+ZomnjsjU4LVXuIWl65LZr9MjtyflsLIYEAcBigzPStO7/eONdjZighwUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALBCRIG1cuVKTZo0SS6XSy6XS16vV5s3b3b2nz9/XhUVFRo5cqSGDx+usrIyNTY2hr1HQ0ODSktLNXToUOXk5GjRokVqa2u7+KMAAAgTUWBdddVVWrp0qerq6rRv3z7dfvvt+sY3vqFDhw5JkhYuXKhXXnlF69ev186dO3Xy5Ende++9zuvb29tVWlqqlpYWvfnmm1q7dq3WrFmjxYsXR/eoAADJx/TRFVdcYZ5//nnT3Nxs0tPTzfr16519R44cMZKMz+czxhizadMmk5qaavx+v1Nm5cqVxuVymVAo1OPPDAQCRpIJBAJ9rT4AII4i+T7v9Tms9vZ2rVu3TufOnZPX61VdXZ1aW1tVXFzslJkwYYIKCgrk8/kkST6fTxMnTlRubq5TpqSkRMFg0OmldSUUCikYDIYtAICBJeLAOnDggIYPH67MzEw9/PDD2rBhgwoLC+X3+5WRkaGsrKyw8rm5ufL7/ZIkv98fFlad+zv3fZ7q6mq53W5nyc/Pj7TaAADLRRxYX/ziF7V//37V1tZq7ty5Ki8v1+HDh/ujbo6qqioFAgFnOXHiRL9+HgAg8UT8PKyMjAxde+21kqTJkydr7969Wr58ub71rW+ppaVFzc3NYb2sxsZGeTweSZLH49GePXvC3q9zFmFnma5kZmYqMzMz0qoCAJJIn6/D6ujoUCgU0uTJk5Wenq5t27Y5++rr69XQ0CCv99OHi3m9Xh04cEBNTU1OmZqaGrlcLhUWFva1KgCAJBZRD6uqqkp33nmnCgoKdObMGb344ot67bXX9Oqrr8rtdmv27NmqrKxUdna2XC6XHnnkEXm9Xk2bNk2SNGPGDBUWFurBBx/UsmXL5Pf79fjjj6uiooIeFADgsiIKrKamJn3729/WqVOn5Ha7NWnSJL366qv62te+Jkl6+umnlZqaqrKyMoVCIZWUlOi5555zXj9o0CBt3LhRc+fOldfr1bBhw1ReXq4lS5ZE96gAAEknxRhj4l2JSAWDQbndbgUCAblcrnhXBwDQS5F8n3MvQQCAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUILACAFQgsAIAVCCwAgBUiCqzq6mpNnTpVI0aMUE5Oju655x7V19eHlTl//rwqKio0cuRIDR8+XGVlZWpsbAwr09DQoNLSUg0dOlQ5OTlatGiR2tra+n40AICkFVFg7dy5UxUVFdq9e7dqamrU2tqqGTNm6Ny5c06ZhQsX6pVXXtH69eu1c+dOnTx5Uvfee6+zv729XaWlpWppadGbb76ptWvXas2aNVq8eHH0jgoAkHxMHzQ1NRlJZufOncYYY5qbm016erpZv369U+bIkSNGkvH5fMYYYzZt2mRSU1ON3+93yqxcudK4XC4TCoV69LmBQMBIMoFAoC/VBwDEWSTf5306hxUIBCRJ2dnZkqS6ujq1traquLjYKTNhwgQVFBTI5/NJknw+nyZOnKjc3FynTElJiYLBoA4dOtTl54RCIQWDwbAFADCw9DqwOjo6tGDBAt1yyy26/vrrJUl+v18ZGRnKysoKK5ubmyu/3++U+cuw6tzfua8r1dXVcrvdzpKfn9/bagMALNXrwKqoqNDBgwe1bt26aNanS1VVVQoEAs5y4sSJfv9MAEBiSevNi+bNm6eNGzdq165duuqqq5ztHo9HLS0tam5uDutlNTY2yuPxOGX27NkT9n6dswg7y1wsMzNTmZmZvakqACBJRNTDMsZo3rx52rBhg7Zv365x48aF7Z88ebLS09O1bds2Z1t9fb0aGhrk9XolSV6vVwcOHFBTU5NTpqamRi6XS4WFhX05FgBAEouoh1VRUaEXX3xRv/71rzVixAjnnJPb7daQIUPkdrs1e/ZsVVZWKjs7Wy6XS4888oi8Xq+mTZsmSZoxY4YKCwv14IMPatmyZfL7/Xr88cdVUVFBLwoA8LlSjDGmx4VTUrrcvnr1an3nO9+R9OmFw48++qheeuklhUIhlZSU6Lnnngsb7nv//fc1d+5cvfbaaxo2bJjKy8u1dOlSpaX1LD+DwaDcbrcCgYBcLldPqw8ASDCRfJ9HFFiJgsACgOQQyfc59xIEAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYgcACAFiBwAIAWIHAAgBYIeLA2rVrl+6++27l5eUpJSVFL7/8cth+Y4wWL16s0aNHa8iQISouLtbRo0fDypw+fVozZ86Uy+VSVlaWZs+erbNnz/bpQAAAyS3iwDp37pxuuOEGPfvss13uX7ZsmVasWKFVq1aptrZWw4YNU0lJic6fP++UmTlzpg4dOqSamhpt3LhRu3bt0pw5c3p/FACA5Gf6QJLZsGGDs97R0WE8Ho/5yU9+4mxrbm42mZmZ5qWXXjLGGHP48GEjyezdu9cps3nzZpOSkmI+/PDDHn1uIBAwkkwgEOhL9QEAcRbJ93lUz2EdP35cfr9fxcXFzja3262ioiL5fD5Jks/nU1ZWlqZMmeKUKS4uVmpqqmpra7t831AopGAwGLYAAAaWqAaW3++XJOXm5oZtz83Ndfb5/X7l5OSE7U9LS1N2drZT5mLV1dVyu93Okp+fH81qAwAsYMUswaqqKgUCAWc5ceJEvKsEAIixqAaWx+ORJDU2NoZtb2xsdPZ5PB41NTWF7W9ra9Pp06edMhfLzMyUy+UKWwAAA0tUA2vcuHHyeDzatm2bsy0YDKq2tlZer1eS5PV61dzcrLq6OqfM9u3b1dHRoaKiomhWBwCQRNIifcHZs2d17NgxZ/348ePav3+/srOzVVBQoAULFujHP/6xxo8fr3HjxumJJ55QXl6e7rnnHknSddddpzvuuEMPPfSQVq1apdbWVs2bN0/33Xef8vLyonZgAIDkEnFg7du3T7fddpuzXllZKUkqLy/XmjVr9IMf/EDnzp3TnDlz1NzcrFtvvVVbtmzR4MGDnde88MILmjdvnqZPn67U1FSVlZVpxYoVUTgcAECySjHGmHhXIlLBYFBut1uBQIDzWQBgsUi+z62YJQgAAIEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsAKBBQCwAoEFALACgQUAsELcAuvZZ5/V2LFjNXjwYBUVFWnPnj3xqgoAwAJxCax///d/V2VlpZ588km99dZbuuGGG1RSUqKmpqZ4VAcAYIG4BNZPf/pTPfTQQ5o1a5YKCwu1atUqDR06VL/85S/jUR0AgAXSYv2BLS0tqqurU1VVlbMtNTVVxcXF8vl8Xb4mFAopFAo564FAQJIUDAb7t7IAgH7V+T1ujOm2bMwD66OPPlJ7e7tyc3PDtufm5up//ud/unxNdXW1fvSjH12yPT8/v1/qCACIrTNnzsjtdl+2TMwDqzeqqqpUWVnprDc3N2vMmDFqaGjo9gDxmWAwqPz8fJ04cUIulyve1bECbdY7tFvkBmqbGWN05swZ5eXldVs25oF15ZVXatCgQWpsbAzb3tjYKI/H0+VrMjMzlZmZecl2t9s9oP5ho8XlctFuEaLNeod2i9xAbLOedjxiPukiIyNDkydP1rZt25xtHR0d2rZtm7xeb6yrAwCwRFyGBCsrK1VeXq4pU6bo5ptv1jPPPKNz585p1qxZ8agOAMACcQmsb33rW/rf//1fLV68WH6/XzfeeKO2bNlyyUSMz5OZmaknn3yyy2FCfD7aLXK0We/QbpGjzbqXYnoylxAAgDjjXoIAACsQWAAAKxBYAAArEFgAACsQWAAAK1gZWDxL6zO7du3S3Xffrby8PKWkpOjll18O22+M0eLFizV69GgNGTJExcXFOnr0aFiZ06dPa+bMmXK5XMrKytLs2bN19uzZGB5FbFVXV2vq1KkaMWKEcnJydM8996i+vj6szPnz51VRUaGRI0dq+PDhKisru+TuLA0NDSotLdXQoUOVk5OjRYsWqa2tLZaHElMrV67UpEmTnDsxeL1ebd682dlPm3Vv6dKlSklJ0YIFC5xttFsEjGXWrVtnMjIyzC9/+Utz6NAh89BDD5msrCzT2NgY76rFxaZNm8w//dM/mf/6r/8yksyGDRvC9i9dutS43W7z8ssvm//+7/82f/3Xf23GjRtnPvnkE6fMHXfcYW644Qaze/du8/vf/95ce+215v7774/xkcROSUmJWb16tTl48KDZv3+/ueuuu0xBQYE5e/asU+bhhx82+fn5Ztu2bWbfvn1m2rRp5itf+Yqzv62tzVx//fWmuLjYvP3222bTpk3myiuvNFVVVfE4pJj4zW9+Y37729+ad955x9TX15t//Md/NOnp6ebgwYPGGNqsO3v27DFjx441kyZNMvPnz3e20249Z11g3XzzzaaiosJZb29vN3l5eaa6ujqOtUoMFwdWR0eH8Xg85ic/+Ymzrbm52WRmZpqXXnrJGGPM4cOHjSSzd+9ep8zmzZtNSkqK+fDDD2NW93hqamoykszOnTuNMZ+2UXp6ulm/fr1T5siRI0aS8fl8xphPfyikpqYav9/vlFm5cqVxuVwmFArF9gDi6IorrjDPP/88bdaNM2fOmPHjx5uamhrz1a9+1Qks2i0yVg0Jdj5Lq7i42NnW3bO0BrLjx4/L7/eHtZfb7VZRUZHTXj6fT1lZWZoyZYpTpri4WKmpqaqtrY15neOh8/lq2dnZkqS6ujq1traGtduECRNUUFAQ1m4TJ04MuztLSUmJgsGgDh06FMPax0d7e7vWrVunc+fOyev10mbdqKioUGlpaVj7SPy3FikrHi/SqTfP0hrI/H6/JHXZXp37/H6/cnJywvanpaUpOzvbKZPMOjo6tGDBAt1yyy26/vrrJX3aJhkZGcrKygore3G7ddWunfuS1YEDB+T1enX+/HkNHz5cGzZsUGFhofbv30+bfY5169bprbfe0t69ey/Zx39rkbEqsIBoq6io0MGDB/X666/HuypW+OIXv6j9+/crEAjoP//zP1VeXq6dO3fGu1oJ68SJE5o/f75qamo0ePDgeFfHelYNCfbmWVoDWWebXK69PB6Pmpqawva3tbXp9OnTSd+m8+bN08aNG7Vjxw5dddVVznaPx6OWlhY1NzeHlb+43bpq1859ySojI0PXXnutJk+erOrqat1www1avnw5bfY56urq1NTUpC9/+ctKS0tTWlqadu7cqRUrVigtLU25ubm0WwSsCiyepRWZcePGyePxhLVXMBhUbW2t015er1fNzc2qq6tzymzfvl0dHR0qKiqKeZ1jwRijefPmacOGDdq+fbvGjRsXtn/y5MlKT08Pa7f6+no1NDSEtduBAwfCwr6mpkYul0uFhYWxOZAE0NHRoVAoRJt9junTp+vAgQPav3+/s0yZMkUzZ850/qbdIhDvWR+RWrduncnMzDRr1qwxhw8fNnPmzDFZWVlhM2gGkjNnzpi3337bvP3220aS+elPf2refvtt8/777xtjPp3WnpWVZX7961+bP/zhD+Yb3/hGl9Pab7rpJlNbW2tef/11M378+KSe1j537lzjdrvNa6+9Zk6dOuUsf/7zn50yDz/8sCkoKDDbt283+/btM16v13i9Xmd/51TjGTNmmP3795stW7aYUaNGJfVU48cee8zs3LnTHD9+3PzhD38wjz32mElJSTG/+93vjDG0WU/95SxBY2i3SFgXWMYY87Of/cwUFBSYjIwMc/PNN5vdu3fHu0pxs2PHDiPpkqW8vNwY8+nU9ieeeMLk5uaazMxMM336dFNfXx/2Hh9//LG5//77zfDhw43L5TKzZs0yZ86cicPRxEZX7SXJrF692inzySefmL//+783V1xxhRk6dKj55je/aU6dOhX2Pn/84x/NnXfeaYYMGWKuvPJK8+ijj5rW1tYYH03s/N3f/Z0ZM2aMycjIMKNGjTLTp093wsoY2qynLg4s2q3neB4WAMAKVp3DAgAMXAQWAMAKBBYAwAoEFgDACgQWAMAKBBYAwAoEFgDACgQWAMAKBBYAwAoEFgDACgQWAMAK/x844WWCPeOMRQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 480x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(target_pos_list[:, 0], target_pos_list[:, 1], s = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch = np.load('/home/mig5/Desktop/TR_DATA_RL/minibatch.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[421, 328]\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "from DQ_Learning import DQNet, environment, mask_detect, top_detection\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('../target_pos_list.npy', 'rb') as f:\n",
    "    target_pos_list = np.load(f)\n",
    "    \n",
    "target_idx = np.random.randint(0, len(target_pos_list))\n",
    "target_pos = [target_pos_list[target_idx][0], target_pos_list[target_idx][1]]\n",
    "print(target_pos)\n",
    "\n",
    "checkpoint_path = \"/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model\"\n",
    "checkpoint_dir  = os.path.dirname(checkpoint_path)\n",
    "model = DQNet()\n",
    "envir = environment()\n",
    "model.load_weights(checkpoint_path)\n",
    "model.compile(  optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "                loss = tf.keras.losses.MeanSquaredError(),\n",
    "                metrics = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value -1062.2699\n",
      "1\n",
      "value -1065.3967\n",
      "9\n",
      "value -1065.4636\n",
      "1\n",
      "value -1065.4636\n",
      "1\n",
      "value -1065.4636\n",
      "1\n",
      "value -1065.4636\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    a = model.get_best(   state_current = [i*100, 320],\n",
    "                            target_pos = [421, 328],\n",
    "                            get_action = True)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.call(inputs = tf.constant([[420, 320, 420, 524, 1]])).numpy()[0][0] == model.call(inputs = tf.constant([[420, 320, 420, 524, 2]])).numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n",
      "-1063.1056\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    print(model.call(inputs = tf.constant([[3000, 320, 100, 603, i+1]])).numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ac1aa0e324239271716ea4bc0f1972974f6d8d50c2a2c3470023e155096e31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
