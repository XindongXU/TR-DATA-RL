{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyjoystick.sdl2 import Key, Joystick, run_event_loop\n",
    "from pprint import pprint\n",
    "from threading import Thread\n",
    "import time\n",
    "import serial\n",
    "from sklearn import linear_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# set blue thresh\n",
    "lower_green = np.array([35,70,60])\n",
    "upper_green = np.array([120,255,255])\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx = 1, fy = 1, interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    # edges = cv2.Canny(mask, 100, 200)\n",
    "    cv2.imshow('green edges', mask)\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenpos0 = []\n",
    "greenpos1 = []\n",
    "for (index0,liste) in enumerate(edges):\n",
    "    for (index1,value) in enumerate(liste):\n",
    "        if value == 255:\n",
    "            greenpos0.append(index0)\n",
    "            greenpos1.append(index1)\n",
    "            # print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor()\n",
    "ransac.fit(np.array(greenpos0).reshape(-1, 1), np.array(greenpos1).reshape(-1, 1))\n",
    "\n",
    "line_X = np.arange(min(greenpos0), max(greenpos0) + 1)[:, np.newaxis]\n",
    "line_y = ransac.predict(line_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (4.8, 6.4))\n",
    "# plt.xlim((0, 480))\n",
    "# plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4.8, 6.4))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(greenpos0, greenpos1, s = 1, marker = 'x')\n",
    "plt.plot(line_X, line_y, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_mask = ransac.inlier_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (2.4, 3.2))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(np.array(greenpos0).reshape(-1, 1)[inlier_mask], np.array(greenpos1).reshape(-1, 1)[inlier_mask], s = 1, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][-1,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][-1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((np.array(greenpos0).reshape(-1, 1)[inlier_mask][0,0], np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(greenpos1).reshape(-1, 1)[inlier_mask][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Servo_t = [0, 29.85799098, 87.28123918, 49.99237628, 23.27381264], [54.25188891, 14.62139926, 51.21600907, 64.9204633, 113.30784031]\n",
    "\n",
    "A_t = [[-0.96566657, 0.49763318, 0.95705414, -0.62148105, -0.44530939], [0.90419815, -0.66050816, 0.60991016, 0.22840757, 0.80645628]]\n",
    "\n",
    "s_t = [[391, 402, 363, 365, 325], [360, 320, 441, 434, 471]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, 180))\n",
    "plt.ylim((0, 180))\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "print(ret)\n",
    "if ret :\n",
    "    print(ret)\n",
    "    cv2.imwrite('./first_frame.jpg', frame)\n",
    "    # cv2.imshow('test', frame)\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.npy', 'rb') as f:\n",
    "    Servo_t = np.load(f)\n",
    "    A_t = np.load(f)\n",
    "    s_t = np.load(f)\n",
    "    \n",
    "print(np.shape(Servo_t), np.shape(A_t), np.shape(s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[0, 0], s_t[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6, 8))\n",
    "plt.xlim((0, 480))\n",
    "plt.ylim((0, 640))\n",
    "plt.title('green point position')\n",
    "# plt.plot(s_t[0], s_t[1])\n",
    "plt.scatter(s_t[0], s_t[1], s = 20, marker = 'x')\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((-0.1, 180.1))\n",
    "plt.ylim((-0.1, 180.1))\n",
    "# plt.plot(Servo_t[0], Servo_t[1])\n",
    "plt.title('Servo angle inputs')\n",
    "plt.scatter(Servo_t[0], Servo_t[1], s = 20, marker = 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(s_pos, target_pos):\n",
    "    # reward(s_t[:, 0], s_t[:, 1])\n",
    "    reward = np.linalg.norm(s_pos - target_pos)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(s_t[0, :]), max(s_t[0, :]), min(s_t[1, :]), max(s_t[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reward figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lis)\n",
    "episode = 10\n",
    "file_name = './img' + str(episode) + '.png'\n",
    "plt.savefig(file_name)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "x_train = datasets.load_iris().data\n",
    "y_train = datasets.load_iris().target\n",
    "\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(120)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "tf.random.set_seed(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(x_train), tf.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #第三步，models.Sequential()\n",
    "# model = tf.keras.models.Sequential([ #使用models.Sequential()来搭建神经网络\n",
    "#     tf.keras.layers.Dense(3, activation = \"softmax\", kernel_regularizer = tf.keras.regularizers.l2()) #全连接层，三个神经元，激活函数为softmax,使用l2正则化\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class irisModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(irisModel, self).__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(3, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) #搭建网络块，这一层命名为d1\n",
    " \n",
    "    def call(self, x):\n",
    "        y = self.d1(x)\n",
    "        return  y\n",
    "\n",
    "model = irisModel()\n",
    "\n",
    "#第四步，model.compile()\n",
    "model.compile(  #使用model.compile()方法来配置训练方法\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1), #使用SGD优化器，学习率为0.1\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), #配置损失函数\n",
    "    metrics = ['sparse_categorical_accuracy'] #标注网络评价指标\n",
    ")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#第五步，model.fit()\n",
    "model.fit(  #使用model.fit()方法来执行训练过程，\n",
    "    x_train, y_train, #告知训练集的输入以及标签，\n",
    "    batch_size = 32, #每一批batch的大小为32，\n",
    "    epochs = 500, #迭代次数epochs为500\n",
    "    validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "    validation_freq = 20 #测试的间隔次数为20,每迭代20次测试一次准确率\n",
    ")\n",
    "\n",
    "#第六步，model.summary()\n",
    "model.summary() #打印神经网络结构，统计参数数目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from DQ_Learning import DQNet\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with open('/home/mig5/Desktop/TR_DATA_RL/minibatch.npy', 'rb') as f:\n",
    "    minibatch = np.load(f, allow_pickle=True)\n",
    "    # experience = np.load(f, allow_pickle=True)\n",
    "\n",
    "print(np.shape(minibatch))\n",
    "DQL = DQNet()\n",
    "\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for (i, mini) in enumerate(minibatch):\n",
    "    value_ = DQL.get_best(mini[4], mini[1], get_action = False)\n",
    "    y_train.append(mini[3] + 0.99*value_)\n",
    "    x_train.append([mini[0][0], mini[0][1], mini[1][0], mini[1][1], mini[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"cp.ckpt\"\n",
    "\n",
    "# # Create a callback that saves the model's weights\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                                                  save_weights_only=True,\n",
    "#                                                  verbose=1)\n",
    "DQL.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.0001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(),\n",
    "            metrics = 'mae')\n",
    "# Train the model with the new callback\n",
    "DQL.fit(np.array(x_train),\n",
    "        np.array(y_train),\n",
    "        epochs=500)\n",
    "# DQL.save_weights('/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQL.get_best(mini[4], mini[1], get_action = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from DQ_Learning import DQNet\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_path = \"/home/mig5/Desktop/TR_DATA_RL/project_RL/deepqlearning_model\"\n",
    "model = DQNet()\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1),\n",
    "            loss = tf.keras.losses.MeanAbsoluteError(),\n",
    "            metrics = 'mae')\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(np.array(x_train), np.array(y_train), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQL.fit(np.array(x_train), np.array(y_train),\n",
    "        batch_size = 64, #每一批batch的大小为32，\n",
    "        epochs = 200, #迭代次数epochs为500\n",
    "        validation_split = 0.2, #从数据集中划分20%给测试集\n",
    "        validation_freq = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01-02-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "servo_0_target = 0\n",
    "servo_1_target = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../target_pos_list.npy', 'rb') as f:\n",
    "#     target_pos_list = np.load(f)\n",
    "# print(np.shape(target_pos_list))\n",
    "# plt.figure(figsize = (6, 8))\n",
    "# plt.xlim((0, 480))\n",
    "# plt.ylim((0, 640))\n",
    "# plt.title('green point position')\n",
    "# # plt.plot(s_t[0], s_t[1])\n",
    "# plt.scatter(target_pos_list[:, 0], target_pos_list[:, 1], s = 20, marker = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1919, 8)\n"
     ]
    }
   ],
   "source": [
    "replay_memory = np.load('../replay_memory.npy', allow_pickle=True)\n",
    "print(np.shape(replay_memory))\n",
    "replay_memory = np.ndarray.tolist(replay_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.63935817272331, -38.63935817272331)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 2\n",
    "np.linalg.norm([replay_memory[index][6] - replay_memory[index][2], replay_memory[index][7] - replay_memory[index][3]]), replay_memory[index][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([367.0, 268.0, 307.0, 307.0, 1.0, -38.63935817272331, 314.0, 269.0],\n",
       " [311.0, 296.0, 201.0, 520.0, 2.0, -254.82543044209697, 351.0, 314.0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_memory[2], replay_memory[18]\n",
    "# state_current[0], state_current[1], target_pos[0], target_pos[1], \n",
    "# action_current, reward_current, state_next[0], state_next[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQ_Learning import environment, GetMinibatch, DQNet, LearningRateReducerCb\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 13ms/step - loss: 35954.5041 - mae: 163.1885\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35423.6452 - mae: 162.2898\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35287.4743 - mae: 162.7778\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 36125.9770 - mae: 164.4831\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 35405.5786 - mae: 163.2321\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 36135.8139 - mae: 163.4598\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 33594.7892 - mae: 157.7788\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35530.3690 - mae: 160.9954\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35784.6785 - mae: 163.3618\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35861.3575 - mae: 162.7713\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35834.5784 - mae: 162.5389\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 37357.9134 - mae: 167.3879\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35089.5974 - mae: 160.5139\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35444.6594 - mae: 163.4933\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 36014.5926 - mae: 163.8846\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35624.4867 - mae: 163.0585\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35574.0554 - mae: 161.0822\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34627.2796 - mae: 160.2919\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33395.2695 - mae: 156.7753\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 33339.3057 - mae: 156.6669\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32838.6342 - mae: 156.3407\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35067.7224 - mae: 162.7624\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 35021.5055 - mae: 162.0428\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 34582.5965 - mae: 160.8395\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 36747.6707 - mae: 165.0653\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35244.1052 - mae: 163.1676\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33840.7502 - mae: 158.9186\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34402.3208 - mae: 160.9417\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 33198.1039 - mae: 156.9671\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 33691.4434 - mae: 159.3880\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 32325.5316 - mae: 156.6031\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33571.2283 - mae: 159.8679\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33927.0006 - mae: 160.9829\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 32588.0046 - mae: 155.9077\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33299.3766 - mae: 159.3867\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 32447.0593 - mae: 157.3189\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32607.5798 - mae: 157.3430\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 31931.4009 - mae: 154.8916\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33068.5912 - mae: 159.3789\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32042.0864 - mae: 156.5342\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 31615.9704 - mae: 155.1037\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 33404.1170 - mae: 160.6034\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33560.6106 - mae: 159.8015\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 31599.5171 - mae: 155.9212\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 32574.0563 - mae: 158.3778\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32070.3392 - mae: 156.6419\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32120.8255 - mae: 157.1531\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 31769.8678 - mae: 156.8331\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33229.2150 - mae: 160.0309\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 32254.6467 - mae: 158.4612\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 33214.2201 - mae: 160.1681\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30332.1538 - mae: 152.4210\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30554.3990 - mae: 153.2253\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30775.7379 - mae: 154.9499\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 31353.9026 - mae: 157.0394\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29573.8774 - mae: 150.3786\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 28567.3676 - mae: 148.2538\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30924.2515 - mae: 155.2598\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28854.6131 - mae: 148.4006\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29190.6658 - mae: 150.0217\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30276.7762 - mae: 153.8387\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30204.7266 - mae: 153.2072\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28699.5394 - mae: 151.1860\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29033.8483 - mae: 150.6858\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28510.9547 - mae: 149.5868\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28535.7957 - mae: 148.9465\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 28311.8447 - mae: 149.1031\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29290.5427 - mae: 151.2774\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29613.9315 - mae: 153.0894\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29144.6343 - mae: 151.4752\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27864.8552 - mae: 149.2613\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26742.9022 - mae: 145.4927\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28023.6490 - mae: 149.4597\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25813.7443 - mae: 142.4331\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27472.6986 - mae: 147.8890\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27005.6665 - mae: 145.5155\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27645.9455 - mae: 149.0332\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27576.9370 - mae: 149.3022\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27267.3273 - mae: 146.6842\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27421.0508 - mae: 147.5483\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 27215.8876 - mae: 147.7902\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 26134.1845 - mae: 143.9726\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26823.0873 - mae: 146.0525\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27307.9297 - mae: 148.1427\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 26697.2154 - mae: 146.0726\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25031.2291 - mae: 140.6074\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27002.6643 - mae: 147.7761\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24166.1403 - mae: 139.0714\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24974.6171 - mae: 141.2063\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24332.9543 - mae: 139.7498\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25104.9378 - mae: 141.4401\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23660.6272 - mae: 137.2791\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25781.2492 - mae: 144.1606\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24271.4521 - mae: 139.2630\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23293.6652 - mae: 137.4160\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24394.4122 - mae: 140.4113\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 23528.1206 - mae: 138.9798\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24179.1089 - mae: 140.6790\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23315.7384 - mae: 137.3372\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23113.2804 - mae: 136.4514\n",
      "0\n",
      "___________target network update___________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 36473.6562 - mae: 164.2127\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 36134.4414 - mae: 163.7209\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 35795.9688 - mae: 163.2066\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 35656.3320 - mae: 162.6961\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 35288.9492 - mae: 162.1772\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 35087.3320 - mae: 161.6630\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 34747.2461 - mae: 161.1392\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 34408.6406 - mae: 160.6176\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 34180.2070 - mae: 160.0987\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 33918.9648 - mae: 159.5801\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 33623.9492 - mae: 159.0557\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 33490.0273 - mae: 158.5323\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 33051.2969 - mae: 158.0101\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 32810.3711 - mae: 157.4872\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 32608.6758 - mae: 156.9610\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 32328.4902 - mae: 156.4377\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 31924.9414 - mae: 155.9140\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 31775.3906 - mae: 155.3846\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 31455.9844 - mae: 154.8537\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 31231.9570 - mae: 154.3260\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 31011.2676 - mae: 153.7944\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30719.5039 - mae: 153.2580\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30675.6055 - mae: 152.7297\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30315.8145 - mae: 152.2042\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30052.9746 - mae: 151.6725\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29759.8984 - mae: 151.1358\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29451.0391 - mae: 150.5974\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29408.9062 - mae: 150.0610\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29030.8555 - mae: 149.5216\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28780.7773 - mae: 148.9836\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28551.1465 - mae: 148.4463\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28232.3242 - mae: 147.9077\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27872.5938 - mae: 147.3659\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27761.1074 - mae: 146.8201\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27622.4648 - mae: 146.2806\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27472.1523 - mae: 145.7897\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27014.9336 - mae: 145.1923\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26835.2812 - mae: 144.6530\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26735.6367 - mae: 144.1030\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 26308.1816 - mae: 143.5574\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 26101.9727 - mae: 143.0125\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25845.1309 - mae: 142.4622\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25752.7148 - mae: 141.9090\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25431.6367 - mae: 141.3554\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25259.0566 - mae: 140.8170\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25303.0957 - mae: 140.3392\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24600.9043 - mae: 139.7002\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24557.3789 - mae: 139.1466\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24192.0293 - mae: 138.5880\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23927.3047 - mae: 138.0314\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23955.6895 - mae: 137.4795\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23516.6406 - mae: 136.9180\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23403.0352 - mae: 136.3539\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23218.6426 - mae: 135.7924\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23013.2949 - mae: 135.2289\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22766.3652 - mae: 134.6714\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 22685.2480 - mae: 134.1440\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 22417.7793 - mae: 133.5524\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22103.8809 - mae: 132.9943\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 22007.2246 - mae: 132.4303\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 21554.1016 - mae: 131.8679\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 21452.4395 - mae: 131.3476\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20993.8965 - mae: 130.7361\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 20945.1484 - mae: 130.1659\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20902.6191 - mae: 129.6063\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20729.7070 - mae: 129.0266\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20612.6543 - mae: 128.4634\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20268.8730 - mae: 127.8991\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20116.0801 - mae: 127.3250\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19898.8281 - mae: 126.7565\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19596.5938 - mae: 126.2017\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 19161.2363 - mae: 125.6166\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 19284.5762 - mae: 125.0522\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19017.2324 - mae: 124.4655\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18926.6094 - mae: 123.8950\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 18556.8926 - mae: 123.3212\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18358.4355 - mae: 122.7502\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18200.0430 - mae: 122.2070\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18132.3242 - mae: 121.6048\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 17618.9531 - mae: 121.0161\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 17697.9043 - mae: 120.4439\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 17440.8965 - mae: 119.8658\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17416.0977 - mae: 119.2875\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 16915.1426 - mae: 118.7164\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 16913.9805 - mae: 118.1390\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 16734.0957 - mae: 117.5617\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16430.3262 - mae: 117.0077\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16587.3477 - mae: 116.4312\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16195.0830 - mae: 115.8355\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15886.0391 - mae: 115.2479\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15899.5723 - mae: 114.6657\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 15450.6943 - mae: 114.0883\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15490.0547 - mae: 113.5303\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15127.4121 - mae: 112.9192\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15288.2090 - mae: 112.3433\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 14857.3916 - mae: 111.7623\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 14617.8750 - mae: 111.1822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 14741.6963 - mae: 110.6363\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14430.3369 - mae: 110.0524\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 14438.7412 - mae: 109.4668\n",
      "1\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 13891.5332 - mae: 106.0122\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 13712.0596 - mae: 105.4348\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13618.7324 - mae: 104.9273\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13435.5752 - mae: 104.3307\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13472.6797 - mae: 103.8293\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13336.4277 - mae: 103.2090\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13021.7910 - mae: 102.5794\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12808.0059 - mae: 101.9941\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12688.1953 - mae: 101.4220\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12582.8281 - mae: 100.9283\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12202.7412 - mae: 100.2812\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12254.4355 - mae: 99.6932\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12120.5547 - mae: 99.1556\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11970.0391 - mae: 98.6097\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11768.6787 - mae: 97.9820\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11598.9629 - mae: 97.3979\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11272.1592 - mae: 96.8548\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11335.5752 - mae: 96.3041\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 11318.4629 - mae: 95.8103\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 11010.5820 - mae: 95.1422\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10884.2900 - mae: 94.6270\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10685.1104 - mae: 94.1198\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 10586.9688 - mae: 93.4723\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10786.0674 - mae: 93.0353\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10516.5869 - mae: 92.2978\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 10038.5527 - mae: 91.7004\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10306.9902 - mae: 91.2089\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10553.9961 - mae: 91.6669\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10140.2012 - mae: 90.0891\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 10133.0225 - mae: 89.6773\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9981.5195 - mae: 89.0302\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9253.4014 - mae: 88.3012\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9750.5439 - mae: 88.5260\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9317.0488 - mae: 87.2173\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8964.7383 - mae: 86.6943\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9143.3770 - mae: 86.1618\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8954.4033 - mae: 85.5569\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8877.8662 - mae: 85.0157\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8555.3652 - mae: 84.3589\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8650.3281 - mae: 84.1580\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 9006.0801 - mae: 84.2916\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8337.8770 - mae: 82.7261\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8338.7383 - mae: 82.2344\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8080.3940 - mae: 81.8441\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8221.5166 - mae: 81.5890\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8369.9551 - mae: 80.6016\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7685.6953 - mae: 80.3227\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8227.3643 - mae: 79.8980\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 7855.4277 - mae: 79.7092\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7681.2729 - mae: 78.5156\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7491.3311 - mae: 78.0082\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7786.0723 - mae: 78.1732\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7391.1245 - mae: 77.4160\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7135.9834 - mae: 76.0429\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7052.6377 - mae: 75.7313\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6922.1538 - mae: 75.1058\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7106.3550 - mae: 75.1230\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6896.4355 - mae: 74.5402\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6877.5200 - mae: 73.7714\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6578.6450 - mae: 72.8369\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6960.4424 - mae: 73.2211\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6739.1323 - mae: 72.3899\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6717.1665 - mae: 72.7162\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6628.4297 - mae: 71.7090\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6219.4580 - mae: 70.2925\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6312.2080 - mae: 70.5197\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6710.5596 - mae: 70.8347\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6140.5581 - mae: 69.3933\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6051.6045 - mae: 69.1296\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6201.3159 - mae: 68.3144\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5577.0244 - mae: 67.2031\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5959.3501 - mae: 67.5376\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5837.7290 - mae: 67.3260\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5710.2148 - mae: 65.7794\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5451.5835 - mae: 65.1894\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5413.9448 - mae: 65.2714\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5571.9507 - mae: 64.7025\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5463.2510 - mae: 65.0315\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5219.6553 - mae: 63.8187\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5460.4263 - mae: 63.2525\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5154.1499 - mae: 62.3522\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5484.4595 - mae: 62.9880\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5084.6763 - mae: 61.8667\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5045.1953 - mae: 61.5826\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5387.6006 - mae: 63.0982\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5331.1348 - mae: 61.8434\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4802.3862 - mae: 61.1190\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4453.4448 - mae: 58.5588\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4599.2378 - mae: 58.5294\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4798.8354 - mae: 58.8388\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4806.6221 - mae: 59.7114\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4678.4360 - mae: 58.6558\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4817.6899 - mae: 59.0383\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4397.6084 - mae: 56.7044\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4419.1636 - mae: 57.2990\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4248.3633 - mae: 55.9044\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4136.1235 - mae: 55.8236\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4046.8125 - mae: 54.3156\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3943.0671 - mae: 54.4715\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4240.5601 - mae: 55.4109\n",
      "2\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3424.9773 - mae: 50.5510\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3777.4521 - mae: 52.3635\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3724.4692 - mae: 51.5325\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3786.7698 - mae: 51.8260\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3718.5679 - mae: 50.3746\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3624.9590 - mae: 51.9320\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3403.4319 - mae: 49.1267\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3574.9243 - mae: 50.3956\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3266.5264 - mae: 48.5619\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3519.4041 - mae: 49.3695\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3213.9866 - mae: 48.7765\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3343.9355 - mae: 48.1556\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3359.1257 - mae: 49.0224\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3163.8538 - mae: 47.5663\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3520.9165 - mae: 48.7476\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3220.1279 - mae: 47.2935\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3212.8362 - mae: 47.0820\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3007.5447 - mae: 46.8563\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3072.9470 - mae: 46.4299\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2770.8940 - mae: 43.8650\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2894.2783 - mae: 45.4442\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2771.1047 - mae: 44.2374\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 2996.9666 - mae: 46.1752\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2939.1721 - mae: 45.0214\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3233.2600 - mae: 44.9938\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2638.5332 - mae: 42.3956\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2596.1030 - mae: 42.5352\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2933.3740 - mae: 44.6510\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2751.7317 - mae: 41.9802\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2783.6233 - mae: 44.7179\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2951.8008 - mae: 43.1078\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2660.4614 - mae: 40.6157\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2707.4229 - mae: 40.8434\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2317.0796 - mae: 39.1650\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2620.7454 - mae: 41.4224\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2500.8857 - mae: 40.0188\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2333.9985 - mae: 40.1236\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2588.3823 - mae: 40.8315\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2291.8311 - mae: 39.0444\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2135.4304 - mae: 37.1889\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2086.0522 - mae: 37.2035\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2338.6262 - mae: 38.9123\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1961.1942 - mae: 35.6292\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2553.3784 - mae: 40.8659\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2203.1296 - mae: 39.0788\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2130.3303 - mae: 37.1472\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2264.7483 - mae: 38.3353\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2326.5754 - mae: 39.2914\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1964.6073 - mae: 35.6541\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1925.9462 - mae: 35.5717\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2080.0737 - mae: 36.4143\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2503.3613 - mae: 40.4531\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1902.4810 - mae: 33.9370\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2276.6743 - mae: 37.6747\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1940.1992 - mae: 35.0172\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2025.3074 - mae: 36.1166\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1945.6283 - mae: 34.3535\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1773.9205 - mae: 33.9175\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1777.0587 - mae: 33.4436\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1965.9171 - mae: 35.6580\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1965.8450 - mae: 36.1296\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2017.4437 - mae: 36.7554\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1398.5562 - mae: 30.3889\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1495.4108 - mae: 31.6841\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1620.6365 - mae: 32.0891\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1615.4376 - mae: 31.6856\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1808.5504 - mae: 33.2699\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1559.3630 - mae: 31.8166\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1930.3802 - mae: 34.2638\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1327.9532 - mae: 29.5466\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1481.6249 - mae: 31.5181\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1663.2815 - mae: 32.2680\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1736.5845 - mae: 32.6488\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1801.6907 - mae: 33.5633\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1585.8646 - mae: 32.0915\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1614.2687 - mae: 31.9502\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1608.4608 - mae: 32.4174\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1619.9303 - mae: 31.7031\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1308.7034 - mae: 29.0395\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1648.3674 - mae: 33.0635\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1593.9402 - mae: 32.7633\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1490.7886 - mae: 31.0194\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1520.8096 - mae: 30.7349\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1508.3701 - mae: 31.4831\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1323.3328 - mae: 29.4178\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1282.8733 - mae: 28.2130\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1472.6228 - mae: 30.8589\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1388.4019 - mae: 29.4358\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1171.4056 - mae: 27.2487\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1586.1907 - mae: 31.9532\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1510.6642 - mae: 30.0765\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1213.2898 - mae: 27.9877\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1524.4204 - mae: 31.1570\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2119.8811 - mae: 37.5563\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1492.2394 - mae: 31.1587\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1425.3986 - mae: 30.0646\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1501.3378 - mae: 31.0693\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1264.1310 - mae: 28.7911\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1611.8029 - mae: 31.8395\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1456.3147 - mae: 31.1003\n",
      "3\n",
      "___________target network update___________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 33671.8945 - mae: 151.9872\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 30839.2480 - mae: 148.7887\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29317.1426 - mae: 145.9754\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 27995.1953 - mae: 143.5230\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 26346.8574 - mae: 140.7140\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 26791.5469 - mae: 138.8623\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 24617.7578 - mae: 136.0265\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23701.0977 - mae: 133.8712\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23543.4238 - mae: 132.1748\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22750.2188 - mae: 130.4232\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 22032.2871 - mae: 128.2919\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 21253.9121 - mae: 126.2253\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20760.5703 - mae: 124.6440\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19797.9199 - mae: 123.0115\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20021.7656 - mae: 121.3456\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 19090.5293 - mae: 119.7061\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18765.7617 - mae: 118.4652\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 18227.3535 - mae: 116.7609\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 17679.2734 - mae: 115.1348\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 16990.5020 - mae: 113.7974\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 17091.9805 - mae: 112.2329\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16653.1406 - mae: 111.5995\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16362.7949 - mae: 109.4121\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 15828.8047 - mae: 108.9389\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14907.4922 - mae: 107.0149\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 15319.2793 - mae: 106.3272\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14625.4551 - mae: 104.4146\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14268.9180 - mae: 102.9673\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 14096.9062 - mae: 101.8916\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14860.5000 - mae: 102.1790\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13933.2725 - mae: 100.3417\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13249.0576 - mae: 98.3857\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12838.5576 - mae: 98.0430\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 13175.4658 - mae: 97.1520\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13194.7637 - mae: 96.8172\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 13909.1094 - mae: 98.9898\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12364.5732 - mae: 96.0352\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 11186.0254 - mae: 92.5498\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 11318.7041 - mae: 90.9144\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11327.3594 - mae: 90.3844\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10872.1895 - mae: 89.5522\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10812.9404 - mae: 88.1126\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11238.3340 - mae: 90.6189\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11086.0479 - mae: 88.4707\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9662.8164 - mae: 84.9907\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10398.1982 - mae: 85.8189\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9595.8604 - mae: 84.2975\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10091.4609 - mae: 84.0145\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10370.9258 - mae: 86.1297\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10063.8555 - mae: 84.1807\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9074.0977 - mae: 80.4212\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9159.2529 - mae: 80.1927\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9623.2832 - mae: 81.8914\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8766.7725 - mae: 78.6203\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8006.7510 - mae: 75.6903\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8814.5059 - mae: 78.0589\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8761.2852 - mae: 78.0909\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7568.1748 - mae: 73.7518\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8100.9648 - mae: 75.4234\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8573.2549 - mae: 75.0993\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8317.5039 - mae: 74.1543\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7715.1465 - mae: 73.8610\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8182.0957 - mae: 74.4053\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7879.3540 - mae: 73.7303\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6853.9824 - mae: 69.2343\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7624.8774 - mae: 68.8152\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7526.7417 - mae: 70.2459\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7434.3936 - mae: 71.9029\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8044.2676 - mae: 72.5991\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6685.4844 - mae: 68.4653\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7526.6890 - mae: 70.5500\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7794.1660 - mae: 71.1899\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7419.9932 - mae: 70.4908\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7208.7632 - mae: 69.2201\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6977.6831 - mae: 69.4657\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6294.5449 - mae: 66.8301\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7556.3765 - mae: 69.6362\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6783.5703 - mae: 66.7806\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6644.4380 - mae: 65.4987\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5639.9917 - mae: 62.9820\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5646.4810 - mae: 62.0784\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5765.6382 - mae: 61.9698\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6102.0425 - mae: 62.8788\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6531.7026 - mae: 65.3609\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 5801.7158 - mae: 62.0262\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5822.0444 - mae: 62.4908\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5407.5566 - mae: 59.8222\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5402.5742 - mae: 60.5029\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5304.9619 - mae: 57.7978\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5631.6577 - mae: 61.4592\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5098.4375 - mae: 57.8120\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5080.7979 - mae: 55.9355\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4584.0225 - mae: 55.0068\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5448.9194 - mae: 57.5042\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5108.4180 - mae: 57.2004\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6812.8779 - mae: 65.3889\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5789.3599 - mae: 60.1024\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4666.5952 - mae: 56.1484\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4538.0996 - mae: 54.3154\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5154.5859 - mae: 56.4620\n",
      "4\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5782.0376 - mae: 58.6762\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5327.3247 - mae: 57.6833\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5235.0688 - mae: 55.7857\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5038.2578 - mae: 56.0793\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4316.4995 - mae: 51.3301\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4921.4727 - mae: 55.7859\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4685.1440 - mae: 51.6465\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4694.6050 - mae: 53.0238\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4484.7476 - mae: 50.3253\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4479.6421 - mae: 52.8678\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4783.1738 - mae: 55.3001\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4891.5796 - mae: 54.3085\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4638.7207 - mae: 52.3116\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3737.6460 - mae: 46.0493\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4017.8179 - mae: 50.8328\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4540.4302 - mae: 52.8880\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4281.9902 - mae: 50.7577\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3649.9250 - mae: 48.0897\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4109.4614 - mae: 50.6576\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4985.3857 - mae: 53.5032\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4575.6807 - mae: 52.9494\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4678.2832 - mae: 54.3703\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3785.4817 - mae: 47.6099\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3854.2712 - mae: 49.2157\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3998.3901 - mae: 48.7612\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4455.6328 - mae: 50.2700\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3938.0796 - mae: 47.9003\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4085.0898 - mae: 48.8620\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4036.3738 - mae: 49.1722\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3849.1099 - mae: 47.6369\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4447.6445 - mae: 52.4660\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3359.4529 - mae: 44.9876\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4100.0742 - mae: 50.3446\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4658.2856 - mae: 54.0349\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4562.7979 - mae: 53.1507\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4359.8169 - mae: 52.7921\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3783.8762 - mae: 49.1446\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3932.0317 - mae: 47.9789\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3545.5049 - mae: 46.5460\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3200.9199 - mae: 43.5928\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3849.5635 - mae: 49.0726\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2894.8093 - mae: 41.2083\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3570.2842 - mae: 46.2801\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2946.4995 - mae: 42.8923\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3838.3279 - mae: 47.9567\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3871.3420 - mae: 48.7744\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3988.8152 - mae: 47.7283\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3528.4026 - mae: 47.5792\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3493.9194 - mae: 46.0241\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4308.8911 - mae: 50.0948\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3290.5686 - mae: 45.2032\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2862.4590 - mae: 40.9867\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4080.3721 - mae: 50.6562\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3901.8562 - mae: 48.6431\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3651.6230 - mae: 46.7348\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4614.7891 - mae: 53.3342\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2912.7537 - mae: 42.0941\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3419.0955 - mae: 46.1973\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2712.5879 - mae: 40.0970\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3070.2532 - mae: 42.8696\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3884.4883 - mae: 48.1291\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3283.6504 - mae: 43.6807\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2561.6523 - mae: 39.4649\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3679.6003 - mae: 47.1299\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3904.9695 - mae: 48.1777\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3656.8513 - mae: 46.6434\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 3368.0940 - mae: 45.5475\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3222.4031 - mae: 44.9648\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3419.8430 - mae: 46.0361\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4106.2969 - mae: 49.5769\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3754.1709 - mae: 48.4355\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2539.5718 - mae: 38.6220\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2974.1550 - mae: 42.6700\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3942.6626 - mae: 48.9712\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3126.8740 - mae: 43.3784\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3223.2273 - mae: 43.6593\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2758.8145 - mae: 41.2685\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2928.2925 - mae: 42.5171\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2606.8384 - mae: 39.5933\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3224.6987 - mae: 44.3822\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4246.2471 - mae: 50.2803\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4266.5474 - mae: 49.6616\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3956.9045 - mae: 48.7513\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2783.0374 - mae: 42.2002\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4214.7920 - mae: 49.7624\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3463.8052 - mae: 45.6571\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3427.7595 - mae: 45.6111\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2691.2183 - mae: 40.2035\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2881.0984 - mae: 41.1134\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2976.2051 - mae: 42.4361\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2949.4133 - mae: 42.5472\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2756.5901 - mae: 39.9980\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3329.1013 - mae: 45.3925\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2903.5022 - mae: 42.4113\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3166.3643 - mae: 44.2253\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3587.2002 - mae: 47.3323\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3803.8540 - mae: 47.1873\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3294.3491 - mae: 44.6081\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4563.9521 - mae: 53.3687\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3471.2112 - mae: 44.2262\n",
      "5\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3660.7056 - mae: 47.5555\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3291.2673 - mae: 44.6750\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4454.6260 - mae: 51.6206\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4867.8462 - mae: 54.8657\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3017.7334 - mae: 42.8653\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3288.1143 - mae: 44.4810\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2917.2319 - mae: 41.6725\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3323.1941 - mae: 44.2530\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2697.6287 - mae: 40.3371\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3345.2917 - mae: 45.4362\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3601.5579 - mae: 47.0822\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3926.7771 - mae: 49.4417\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2925.0786 - mae: 42.5801\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3594.3440 - mae: 46.6984\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3657.9041 - mae: 46.4648\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3529.4641 - mae: 46.1249\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2908.7869 - mae: 42.4699\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3748.4214 - mae: 47.0945\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3862.5071 - mae: 48.6185\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2775.9456 - mae: 41.0218\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3511.4141 - mae: 45.9806\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3544.1775 - mae: 47.1743\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3620.8208 - mae: 48.2971\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3037.7119 - mae: 42.9801\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4384.9043 - mae: 53.2081\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3176.8572 - mae: 44.3214\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3779.7866 - mae: 48.5491\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4938.9922 - mae: 55.3056\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3968.9680 - mae: 49.0853\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3469.3430 - mae: 45.8459\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2862.2546 - mae: 40.7719: 0s - loss: 2619.3364 - mae: 39.0\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3023.9209 - mae: 42.7938\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4664.7051 - mae: 54.1893\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3579.4507 - mae: 46.1792\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3571.7625 - mae: 46.9168\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2765.5647 - mae: 41.5082\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3438.1069 - mae: 45.7308\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3363.0525 - mae: 46.5894\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3113.6675 - mae: 43.9088\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3749.0420 - mae: 48.4280\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2550.2415 - mae: 39.6788\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3444.2800 - mae: 44.8119\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2831.8577 - mae: 41.6495\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4350.7959 - mae: 52.4820\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2797.7710 - mae: 42.6315\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3225.9783 - mae: 44.2095\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3130.6638 - mae: 45.1065\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 3819.2664 - mae: 46.5772\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2814.1025 - mae: 41.5566\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4381.2075 - mae: 51.1584\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3651.5662 - mae: 46.7673\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2991.9541 - mae: 42.3543\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3319.1118 - mae: 44.7608\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3421.0632 - mae: 45.6025\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3314.4485 - mae: 43.7071\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3375.6868 - mae: 46.2663\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3271.0605 - mae: 45.1386\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3588.6536 - mae: 47.5347\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3387.0042 - mae: 46.0607\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3524.6345 - mae: 47.1844\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2699.1294 - mae: 40.5781\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3476.3423 - mae: 47.7102\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3340.4119 - mae: 44.9404\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2784.9629 - mae: 41.1217\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3603.7576 - mae: 47.7577\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3164.1477 - mae: 43.3785\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3536.2537 - mae: 46.7705\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3071.9971 - mae: 41.9710\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3818.1958 - mae: 48.7878\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3188.1160 - mae: 44.1237\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1879.1782 - mae: 33.9566\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3428.9250 - mae: 46.0728\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3485.5520 - mae: 44.9993\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2763.6340 - mae: 41.2626\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2931.6162 - mae: 41.6006\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4241.8281 - mae: 51.3456\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3314.8218 - mae: 44.9753\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3505.8359 - mae: 46.5826\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2824.2737 - mae: 42.3545\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3226.2834 - mae: 45.1748\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2825.1929 - mae: 41.4391\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3924.7180 - mae: 50.4241\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2636.2346 - mae: 40.4826\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3548.3972 - mae: 46.5947\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4386.5918 - mae: 51.5760\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3250.7915 - mae: 45.6366\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4360.9321 - mae: 52.8590\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3289.1230 - mae: 44.2696\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2959.0515 - mae: 42.6560\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3352.6804 - mae: 46.0960\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3367.7686 - mae: 45.9261\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2787.8196 - mae: 41.8801\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2653.1855 - mae: 41.5740\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4518.1704 - mae: 53.5630\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3682.9028 - mae: 47.3433\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 4448.6128 - mae: 51.8615\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3331.9585 - mae: 44.7929\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3298.4751 - mae: 45.4220\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2597.0815 - mae: 39.9818\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3239.3616 - mae: 45.2856\n",
      "6\n",
      "___________target network update___________\n"
     ]
    }
   ],
   "source": [
    "model = DQNet()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "model.save_weights(\"./predict_model_weekend\")\n",
    "\n",
    "model_ = DQNet()\n",
    "model_.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "model_.load_weights(\"./predict_model_weekend\")\n",
    "# model_.load_weights(\"./target_model_weekend\")\n",
    "model_.save_weights(\"./target_model_weekend\")\n",
    "\n",
    "for step in range(7):    \n",
    "    x_train, y_train = [], []\n",
    "    minibatch = GetMinibatch(1000, replay_memory)\n",
    "    for (i, mini) in enumerate(minibatch):\n",
    "        if mini[5] >= -10:\n",
    "            y_train.append(mini[5])\n",
    "        else:\n",
    "            value_ = model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False, is_training = True)\n",
    "            y_train.append(mini[5] + 0.99*value_)\n",
    "            \n",
    "        action_0 = 0.1 * (-1 + (mini[4] - 1)//3)\n",
    "        action_1 = 0.1 * (-1 + (mini[4] - 1) %3)\n",
    "        x_train.append([mini[0], mini[1], mini[2], mini[3], action_0, action_1])\n",
    "        \n",
    "    history = model.fit(np.array(x_train), np.array(y_train), batch_size = 64, epochs = 100)\n",
    "#     model.fit(np.array(x_train), np.array(y_train), callbacks=[LearningRateReducerCb(step)], epochs = 100)\n",
    "    model.save_weights(\"./predict_model_weekend\")\n",
    "    \n",
    "    print(step)\n",
    "    if (step%3 == 0):\n",
    "        print(\"___________target network update___________\")\n",
    "        model_.load_weights(\"./predict_model_weekend\")\n",
    "        model_.save_weights(\"./target_model_weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 11ms/step - loss: 306290.3640 - mae: 455.1629\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 315740.0772 - mae: 464.0955\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 320503.4430 - mae: 470.3063\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 291243.4136 - mae: 445.5439\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 303264.9835 - mae: 457.0868\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 318365.0221 - mae: 466.3696\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 315517.7224 - mae: 463.6247\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 303218.9393 - mae: 458.3009\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 304774.8015 - mae: 453.7527\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 313824.4577 - mae: 462.3740\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 324133.4926 - mae: 473.9419\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 316854.2555 - mae: 469.2944\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 315172.8199 - mae: 464.7156\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 311129.2463 - mae: 460.5354\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 324161.2629 - mae: 471.4767\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 324306.7849 - mae: 472.3823\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 316118.6801 - mae: 465.8156\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 316208.3842 - mae: 463.6218\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 327686.7243 - mae: 473.5313\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 316402.5974 - mae: 468.2300\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 320425.1085 - mae: 468.5866\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 304537.2665 - mae: 452.8505\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 303109.2849 - mae: 455.9808\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 296749.5864 - mae: 450.1206\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 320971.8658 - mae: 467.4653\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 301568.1930 - mae: 455.1945\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 303061.8603 - mae: 451.4742\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 307945.0377 - mae: 457.6668\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 308919.9154 - mae: 460.9369\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 295096.1434 - mae: 448.8364\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 304213.8768 - mae: 456.6715\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 314476.3860 - mae: 465.7633\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 321648.6379 - mae: 470.4991\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 320733.0478 - mae: 469.0396\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 301299.7849 - mae: 457.9321\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 302672.4945 - mae: 456.4837\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 301723.4706 - mae: 457.1833\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 299509.2978 - mae: 451.3522\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 316831.9504 - mae: 469.4997\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 290676.5404 - mae: 446.7680\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 309861.9522 - mae: 465.4176\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 303950.6397 - mae: 456.1685\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 308104.0974 - mae: 461.5712\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 303328.7169 - mae: 456.1698\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 296880.6581 - mae: 454.8457\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 312252.7390 - mae: 461.7577\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 294332.7243 - mae: 452.9460\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 305940.0478 - mae: 463.7599\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 306626.2886 - mae: 458.0270\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 306685.1857 - mae: 460.3883\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 289768.9770 - mae: 447.2859\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 306197.5846 - mae: 462.6875\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 317593.3658 - mae: 472.7478\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 309787.6324 - mae: 462.0613\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 298698.7886 - mae: 456.6782\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 15ms/step - loss: 312089.7518 - mae: 465.5635\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 311066.7721 - mae: 466.3242\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 296649.6875 - mae: 456.4056\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 306477.7757 - mae: 462.9607\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 307619.3934 - mae: 466.8560\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 295747.8640 - mae: 454.9871\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 300984.1305 - mae: 462.1516\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 285846.4963 - mae: 445.8600\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 286605.2298 - mae: 447.4401\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 293022.2831 - mae: 450.5944\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 285551.5138 - mae: 443.3705\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 295192.2371 - mae: 457.0806\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 312234.6618 - mae: 469.3225\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 297250.6305 - mae: 458.7061\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 288491.9963 - mae: 450.2959\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 278601.2656 - mae: 443.0347\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 294040.7592 - mae: 453.6312\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 287412.8364 - mae: 448.4494\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 285425.9816 - mae: 447.8969\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 286020.5037 - mae: 442.9964\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 273310.4752 - mae: 436.6330\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 289785.4559 - mae: 451.6978\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 286826.9963 - mae: 446.8432\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 285665.0092 - mae: 447.0007\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 285073.6875 - mae: 446.3776\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 282054.2307 - mae: 440.7699\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 286756.0055 - mae: 449.0718\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 282649.9283 - mae: 446.3626\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 272943.4963 - mae: 434.8264\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 277272.6351 - mae: 443.0776\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 280665.4301 - mae: 441.7022\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 285264.5018 - mae: 446.4935\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 282519.8695 - mae: 447.5266\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 273613.0754 - mae: 441.0485\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 275954.1011 - mae: 442.7957\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 273807.2675 - mae: 435.3981\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 265092.6544 - mae: 430.9040\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 279909.2408 - mae: 443.2745\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 275108.5450 - mae: 441.2429\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 287690.9871 - mae: 453.2376\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 264590.8713 - mae: 435.6941\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 263388.9403 - mae: 430.2054\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 266659.9081 - mae: 433.6994\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 278675.8860 - mae: 448.3241\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 271931.6691 - mae: 438.3442\n",
      "0\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 272035.4688 - mae: 437.8973\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 271601.8750 - mae: 437.4442\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 270921.6875 - mae: 436.9882\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 270077.1562 - mae: 436.5280\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 269368.9688 - mae: 436.0665\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 268703.4688 - mae: 435.6037\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 268209.9688 - mae: 435.1353\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 267235.4375 - mae: 434.6657\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 266563.5000 - mae: 434.1941\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 265976.9688 - mae: 433.7148\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 265455.0938 - mae: 433.2346\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 264605.7188 - mae: 432.7566\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 263851.5312 - mae: 432.2727\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 263055.5000 - mae: 431.7841\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 262595.7500 - mae: 431.2915\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 261715.0312 - mae: 430.7993\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 261321.3438 - mae: 430.3043\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 260412.1562 - mae: 429.8045\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 259512.0781 - mae: 429.3064\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 258610.4531 - mae: 428.8032\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 257802.3438 - mae: 428.2975\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 257079.7969 - mae: 427.7863\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 256340.2031 - mae: 427.2701\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 255911.0781 - mae: 426.7543\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 254964.9688 - mae: 426.2338\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 254235.0469 - mae: 425.7105\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 253397.2031 - mae: 425.1848\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 253080.5781 - mae: 424.6602\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 251937.2500 - mae: 424.1313\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 251161.2500 - mae: 423.5984\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 250392.1250 - mae: 423.0634\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 249514.0781 - mae: 422.5261\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 249009.1875 - mae: 422.0029\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 248442.8125 - mae: 421.4438\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 247579.5156 - mae: 420.9006\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 247088.7656 - mae: 420.3556\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 246134.0781 - mae: 419.8094\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 244756.1562 - mae: 419.2519\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 244152.4688 - mae: 418.6968\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 243588.6406 - mae: 418.1401\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 242597.8750 - mae: 417.5799\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 242287.4375 - mae: 417.0135\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 241209.8906 - mae: 416.4463\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 240402.3438 - mae: 415.8791\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 239696.7500 - mae: 415.3386\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 238817.7656 - mae: 414.7361\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 237948.9688 - mae: 414.1639\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 237318.1406 - mae: 413.5869\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 236383.3906 - mae: 413.0052\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 235620.2188 - mae: 412.4236\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 235626.2812 - mae: 411.8394\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 234105.1719 - mae: 411.2517\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 234629.7656 - mae: 410.6756\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 233012.6875 - mae: 410.0671\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 231532.0000 - mae: 409.4743\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 231246.6875 - mae: 408.8759\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 230267.9219 - mae: 408.2761\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 229909.8906 - mae: 407.6785\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 228214.8125 - mae: 407.0764\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 228191.0938 - mae: 406.4717\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 226897.8906 - mae: 405.8645\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 226218.0156 - mae: 405.2556\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 225749.5469 - mae: 404.6404\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 224354.6719 - mae: 404.0198\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 223798.4688 - mae: 403.4021\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 223180.0312 - mae: 402.7826\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 222492.1719 - mae: 402.1674\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 221186.7031 - mae: 401.5472\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 220579.5312 - mae: 400.9190\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 220101.0625 - mae: 400.2879\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 218475.3281 - mae: 399.6549\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 218102.6094 - mae: 399.0206\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 217253.5469 - mae: 398.3859\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 216576.5000 - mae: 397.7492\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 215382.7969 - mae: 397.1155\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 215258.3594 - mae: 396.4764\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 214190.1719 - mae: 395.8317\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 213050.9062 - mae: 395.1850\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 212371.5469 - mae: 394.5336\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 211920.7500 - mae: 393.8839\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 211534.9375 - mae: 393.2327\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 210169.3438 - mae: 392.5820\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 208644.8906 - mae: 391.9308\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 207813.7344 - mae: 391.2747\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 207334.0156 - mae: 390.6086\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 206798.4688 - mae: 389.9479\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 205696.0781 - mae: 389.2878\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 205447.0156 - mae: 388.6253\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 204695.2969 - mae: 387.9581\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 203241.5781 - mae: 387.2904\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 202809.0625 - mae: 386.6296\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 202113.5938 - mae: 385.9563\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 200436.1875 - mae: 385.2766\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 200055.8750 - mae: 384.5974\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 199021.7812 - mae: 383.9110\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 198278.2188 - mae: 383.2492\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 198065.9062 - mae: 382.5449\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 196386.8438 - mae: 381.8609\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 196325.1719 - mae: 381.1704\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 196100.5000 - mae: 380.4879\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-21a2159a3817>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mvalue_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvalue_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MinesParis - 2A\\TR - DATA\\TR_DATA_ReinforcementLearning\\project_RL\\DQ_Learning.py\u001b[0m in \u001b[0;36mget_best\u001b[1;34m(self, state_current, target_pos, get_action, is_training)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0maction_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_current\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_current\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_pos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[0mvalue_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mvalue_new\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MinesParis - 2A\\TR - DATA\\TR_DATA_ReinforcementLearning\\project_RL\\DQ_Learning.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# x = self.dense1(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m     outputs = nn.batch_normalization(inputs, _broadcast(mean),\n\u001b[0m\u001b[0;32m    892\u001b[0m                                      \u001b[0m_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                                      self.epsilon)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[1;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[0;32m   1556\u001b[0m   \"\"\"\n\u001b[0;32m   1557\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"batchnorm\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1558\u001b[1;33m     \u001b[0minv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvariance_epsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m       \u001b[0minv\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mrsqrt\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   5004\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5005\u001b[0m   \"\"\"\n\u001b[1;32m-> 5006\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mrsqrt\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   8005\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8006\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8007\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   8008\u001b[0m         _ctx, \"Rsqrt\", name, x)\n\u001b[0;32m   8009\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 运行两次\n",
    "# from DQ_Learning import environment, GetMinibatch, DQNet, LearningRateReducerCb\n",
    "\n",
    "model = DQNet()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "model.save_weights(\"./predict_model_weekend\")\n",
    "\n",
    "model_ = DQNet()\n",
    "model_.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "model_.load_weights(\"./target_model_weekend\")\n",
    "\n",
    "for step in range(6):\n",
    "    x_train, y_train = [], []\n",
    "    minibatch = GetMinibatch(1000, replay_memory)\n",
    "    for (i, mini) in enumerate(minibatch):\n",
    "        if mini[5] >= -10:\n",
    "            y_train.append(mini[5])\n",
    "        else:\n",
    "            value_ = model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False, is_training = True)\n",
    "            y_train.append(mini[5] + 0.99*value_)\n",
    "            \n",
    "        action_0 = 0.1 * (-1 + (mini[4] - 1)//3)\n",
    "        action_1 = 0.1 * (-1 + (mini[4] - 1) %3)\n",
    "        x_train.append([mini[0], mini[1], mini[2], mini[3], action_0, action_1])\n",
    "        \n",
    "    history = model.fit(np.array(x_train), np.array(y_train), batch_size = 64, epochs = 100)\n",
    "    model.save_weights(\"./predict_model_weekend\")\n",
    "    \n",
    "    print(step)\n",
    "    if (step%3 == 2):\n",
    "        print(\"___________target network update___________\")\n",
    "        model_.load_weights(\"./predict_model_weekend\")\n",
    "        model_.save_weights(\"./target_model_weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x29416adfe80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQNet()\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "model.load_weights(\"./target_model_weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[367.0, 254.0, 60.0, 559.0, 7.0, -422.1717659910478, 355.0, 257.0]\n"
     ]
    }
   ],
   "source": [
    "mini = replay_memory[0]\n",
    "print(mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-870.51697\n",
      "-867.181\n",
      "-863.752\n",
      "-869.6375\n",
      "-866.2603\n",
      "-862.7889\n",
      "-868.73047\n",
      "-865.312\n",
      "-861.7981\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for at in range(1, 10):\n",
    "    action_0 = 0.1 * (-1 + (at - 1)//3)\n",
    "    action_1 = 0.1 * (-1 + (at - 1) %3)\n",
    "    print(model.call(inputs = tf.constant([[mini[0], mini[1], mini[2], mini[3], action_0, action_1]])).numpy()[0][0])\n",
    "print(model.get_best([mini[0], mini[1]], [mini[2], mini[3]], get_action = True, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1266.7430983885088"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini[5] + 0.99*(model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-384.74942, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.get_best([20.0, 510.0], [203.0, 495.0], get_action = False, is_training = True), \n",
    " model.get_best([20.0, 510.0], [203.0, 495.0], get_action = True, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-68.47254\n",
      "-65.66455\n",
      "-62.99671\n",
      "-66.46234\n",
      "-63.883064\n",
      "-61.45076\n",
      "-65.24979\n",
      "-62.91429\n",
      "-60.732983\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for at in range(1, 10):\n",
    "    action_0 = 0.1 * (-1 + (at - 1)//3)\n",
    "    action_1 = 0.1 * (-1 + (at - 1) %3)\n",
    "    print(model.call(inputs = tf.constant([[291.0, 367.0, 291.0, 367.0, action_0, action_1]])).numpy()[0][0])\n",
    "print(model.get_best([291.0, 367.0], [291.0, 367.0], get_action = True, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[367.0, 254.0, 60.0, 559.0, 7.0, -422.1717659910478, 355.0, 257.0],\n",
       " [355.0, 257.0, 287.0, 342.0, 5.0, -108.97706180660222, 367.0, 268.0],\n",
       " [367.0, 268.0, 307.0, 307.0, 1.0, -38.63935817272331, 314.0, 269.0],\n",
       " [314.0, 269.0, 275.0, 368.0, 4.0, -143.22360140703069, 363.0, 255.0],\n",
       " [363.0, 255.0, 44.0, 540.0, 6.0, -421.2279667828336, 356.0, 257.0],\n",
       " [356.0, 257.0, 357.0, 289.0, 8.0, -46.647615158762406, 317.0, 265.0],\n",
       " [317.0, 265.0, 60.0, 559.0, 1.0, -408.72973955903916, 352.0, 273.0],\n",
       " [352.0, 273.0, 302.0, 317.0, 3.0, -75.92759709091287, 351.0, 259.0],\n",
       " [351.0, 259.0, 175.0, 531.0, 4.0, -327.365239449762, 363.0, 263.0],\n",
       " [363.0, 263.0, 275.0, 368.0, 1.0, -144.1700384962146, 367.0, 257.0],\n",
       " [367.0, 257.0, 10.0, 542.0, 9.0, -413.359407779719, 315.0, 263.0],\n",
       " [315.0, 263.0, 87.0, 558.0, 6.0, -389.6678072409883, 367.0, 287.0],\n",
       " [367.0, 287.0, 147.0, 545.0, 6.0, -306.2025473440742, 315.0, 289.0],\n",
       " [315.0, 289.0, 147.0, 545.0, 2.0, -317.80497164141406, 353.0, 303.0],\n",
       " [353.0, 303.0, 275.0, 368.0, 2.0, -111.94641575325224, 359.0, 294.0],\n",
       " [359.0, 294.0, 34.0, 545.0, 5.0, -411.86648321998723, 359.0, 292.0],\n",
       " [359.0, 292.0, 227.0, 470.0, 3.0, -202.20039564748632, 313.0, 287.0],\n",
       " [313.0, 287.0, 367.0, 264.0, 3.0, -64.4980619863884, 311.0, 296.0],\n",
       " [311.0, 296.0, 201.0, 520.0, 2.0, -254.82543044209697, 351.0, 314.0],\n",
       " [351.0, 314.0, 124.0, 479.0, 7.0, -280.04463929880893, 351.0, 315.0],\n",
       " [351.0, 315.0, 295.0, 332.0, 1.0, -31.304951684997057, 309.0, 304.0],\n",
       " [309.0, 304.0, 339.0, 308.0, 1.0, -22.47220505424423, 351.0, 289.0],\n",
       " [351.0, 289.0, 203.0, 495.0, 3.0, -257.6198750096739, 355.0, 287.0],\n",
       " [355.0, 287.0, 222.0, 513.0, 8.0, -256.2225595063791, 355.0, 294.0],\n",
       " [355.0, 294.0, 295.0, 332.0, 1.0, -42.37924020083418, 309.0, 292.0],\n",
       " [309.0, 292.0, 291.0, 337.0, 9.0, -81.21576201698781, 355.0, 287.0],\n",
       " [355.0, 287.0, 14.0, 531.0, 2.0, -410.7614879708174, 357.0, 305.0],\n",
       " [357.0, 305.0, 297.0, 440.0, 8.0, -154.05518491761322, 315.0, 287.0],\n",
       " [315.0, 287.0, 305.0, 312.0, 4.0, -58.42088667591412, 363.0, 305.0],\n",
       " [363.0, 305.0, 107.0, 559.0, 3.0, -358.0223456713282, 351.0, 297.0],\n",
       " [351.0, 297.0, 275.0, 368.0, 1.0, -113.89907813498755, 358.0, 290.0],\n",
       " [358.0, 290.0, 307.0, 307.0, 3.0, -28.160255680657446, 315.0, 280.0],\n",
       " [315.0, 280.0, 203.0, 495.0, 5.0, -256.0175775215444, 359.0, 292.0],\n",
       " [359.0, 292.0, 52.0, 559.0, 8.0, -403.1935019317648, 355.0, 293.0],\n",
       " [355.0, 293.0, 96.0, 489.0, 4.0, -315.62794553081005, 351.0, 303.0],\n",
       " [351.0, 303.0, 309.0, 398.0, 2.0, -109.16501271011697, 315.0, 289.0],\n",
       " [315.0, 289.0, 217.0, 483.0, 5.0, -245.63590942694026, 361.0, 284.0],\n",
       " [361.0, 284.0, 145.0, 542.0, 5.0, -334.8447401408599, 356.0, 282.0],\n",
       " [356.0, 282.0, 79.0, 536.0, 4.0, -386.66264365723254, 367.0, 278.0],\n",
       " [367.0, 278.0, 367.0, 254.0, 9.0, -53.48831648126533, 317.0, 273.0],\n",
       " [317.0, 273.0, 367.0, 264.0, 2.0, -27.730849247724095, 355.0, 289.0],\n",
       " [355.0, 289.0, 301.0, 325.0, 3.0, -66.03029607687671, 355.0, 287.0],\n",
       " [355.0, 287.0, 247.0, 481.0, 2.0, -217.81643647805828, 357.0, 293.0],\n",
       " [357.0, 293.0, 247.0, 481.0, 9.0, -203.9730374338726, 313.0, 288.0],\n",
       " [313.0, 288.0, 367.0, 298.0, 2.0, -23.323807579381203, 355.0, 318.0],\n",
       " [355.0, 318.0, 175.0, 531.0, 7.0, -292.6977963702494, 361.0, 305.0],\n",
       " [361.0, 305.0, 151.0, 529.0, 2.0, -300.29319006597535, 351.0, 305.0],\n",
       " [351.0, 305.0, 47.0, 495.0, 2.0, -368.4562389212591, 359.0, 299.0],\n",
       " [359.0, 299.0, 259.0, 382.0, 9.0, -104.95713410721541, 313.0, 292.0],\n",
       " [313.0, 292.0, 14.0, 537.0, 7.0, -397.6053319562, 351.0, 326.0],\n",
       " [351.0, 326.0, 247.0, 481.0, 1.0, -180.89223311131963, 306.0, 310.0],\n",
       " [306.0, 310.0, 307.0, 307.0, 5.0, -60.03332407921454, 367.0, 305.0],\n",
       " [367.0, 305.0, 87.0, 558.0, 3.0, -354.91970923012997, 315.0, 286.0],\n",
       " [315.0, 286.0, 59.0, 548.0, 3.0, -386.80356771881, 355.0, 299.0],\n",
       " [355.0, 299.0, 139.0, 485.0, 9.0, -252.65985039178662, 310.0, 299.0],\n",
       " [310.0, 299.0, 260.0, 417.0, 2.0, -128.03515142334936, 353.0, 329.0],\n",
       " [353.0, 329.0, 175.0, 531.0, 2.0, -279.4065138825507, 357.0, 319.0],\n",
       " [357.0, 319.0, 297.0, 440.0, 9.0, -130.6789960169575, 351.0, 321.0],\n",
       " [351.0, 321.0, 295.0, 332.0, 6.0, -57.723478758647246, 351.0, 346.0],\n",
       " [351.0, 346.0, 361.0, 321.0, 2.0, -58.42088667591412, 303.0, 328.0],\n",
       " [303.0, 328.0, 302.0, 317.0, 1.0, -48.46648326421054, 347.0, 335.0],\n",
       " [347.0, 335.0, 289.0, 355.0, 7.0, -57.62811813689564, 334.0, 319.0],\n",
       " [334.0, 319.0, 347.0, 366.0, 1.0, -63.60031446463138, 309.0, 315.0],\n",
       " [309.0, 315.0, 44.0, 540.0, 8.0, -384.2004685057008, 351.0, 309.0],\n",
       " [351.0, 309.0, 44.0, 540.0, 6.0, -374.79861259081525, 351.0, 325.0],\n",
       " [351.0, 325.0, 44.0, 540.0, 2.0, -372.5184559186296, 351.0, 329.0],\n",
       " [351.0, 329.0, 10.0, 542.0, 5.0, -412.47787819469784, 357.0, 319.0],\n",
       " [357.0, 319.0, 201.0, 520.0, 7.0, -252.00198411917316, 353.0, 319.0],\n",
       " [353.0, 319.0, 307.0, 307.0, 7.0, -47.53945729601885, 351.0, 325.0],\n",
       " [351.0, 325.0, 361.0, 321.0, 9.0, -59.21148537234985, 302.0, 326.0],\n",
       " [302.0, 326.0, 295.0, 332.0, 4.0, -33.83784863137726, 323.0, 351.0],\n",
       " [323.0, 351.0, 114.0, 554.0, 5.0, -310.75713990188547, 351.0, 353.0],\n",
       " [351.0, 353.0, 252.0, 439.0, 3.0, -115.83177456984762, 303.0, 335.0],\n",
       " [303.0, 335.0, 14.0, 538.0, 9.0, -352.59750424527965, 303.0, 336.0],\n",
       " [303.0, 336.0, 27.0, 543.0, 4.0, -333.1816321467917, 300.0, 352.0],\n",
       " [300.0, 352.0, 355.0, 302.0, 1.0, -62.68173577685928, 303.0, 337.0],\n",
       " [303.0, 337.0, 337.0, 385.0, 6.0, -50.59644256269407, 353.0, 337.0],\n",
       " [353.0, 337.0, 247.0, 481.0, 7.0, -172.10461934532728, 355.0, 347.0],\n",
       " [355.0, 347.0, 145.0, 542.0, 7.0, -276.87722911066555, 351.0, 357.0],\n",
       " [351.0, 357.0, 165.0, 527.0, 8.0, -216.11339616044165, 289.0, 350.0],\n",
       " [289.0, 350.0, 60.0, 559.0, 2.0, -310.65414853177157, 305.0, 368.0],\n",
       " [305.0, 368.0, 227.0, 470.0, 4.0, -138.43771162512041, 301.0, 353.0],\n",
       " [301.0, 353.0, 47.0, 495.0, 9.0, -291.9794513317675, 301.0, 351.0],\n",
       " [301.0, 351.0, 305.0, 312.0, 6.0, -57.14017850864661, 309.0, 369.0],\n",
       " [309.0, 369.0, 287.0, 342.0, 3.0, -31.575306807693888, 293.0, 373.0],\n",
       " [293.0, 373.0, 151.0, 529.0, 6.0, -209.60916010518244, 291.0, 373.0],\n",
       " [291.0, 373.0, 309.0, 398.0, 9.0, -24.839484696748443, 293.0, 379.0],\n",
       " [293.0, 379.0, 287.0, 342.0, 6.0, -65.49045732013177, 295.0, 407.0],\n",
       " [295.0, 407.0, 111.0, 500.0, 1.0, -201.6953147695801, 291.0, 409.0],\n",
       " [291.0, 409.0, 60.0, 559.0, 7.0, -288.00173610587836, 291.0, 387.0],\n",
       " [291.0, 387.0, 111.0, 500.0, 3.0, -210.11663427725088, 293.0, 395.0],\n",
       " [293.0, 395.0, 201.0, 520.0, 1.0, -172.40939649566667, 286.0, 370.0],\n",
       " [286.0, 370.0, 367.0, 264.0, 8.0, -120.42009799032718, 293.0, 359.0],\n",
       " [293.0, 359.0, 297.0, 417.0, 8.0, -37.48332962798263, 291.0, 380.0],\n",
       " [291.0, 380.0, 151.0, 529.0, 6.0, -196.5807722031837, 291.0, 391.0],\n",
       " [291.0, 391.0, 227.0, 470.0, 3.0, -92.84934033152847, 297.0, 409.0],\n",
       " [297.0, 409.0, 247.0, 481.0, 1.0, -107.42439201596628, 291.0, 383.0],\n",
       " [291.0, 383.0, 97.0, 558.0, 9.0, -272.28110474287416, 293.0, 369.0],\n",
       " [293.0, 369.0, 14.0, 537.0, 4.0, -317.71842880135233, 293.0, 385.0],\n",
       " [293.0, 385.0, 34.0, 545.0, 1.0, -308.1379561170613, 291.0, 375.0],\n",
       " [291.0, 375.0, 367.0, 257.0, 7.0, -122.41323457861898, 295.0, 356.0],\n",
       " [339.0, 379.0, 14.0, 537.0, 2.0, -330.94561486745823, 293.0, 359.0],\n",
       " [293.0, 359.0, 107.0, 559.0, 1.0, -287.50652166516153, 299.0, 345.0],\n",
       " [299.0, 345.0, 283.0, 410.0, 6.0, -102.53292154230269, 355.0, 337.0],\n",
       " [355.0, 337.0, 301.0, 325.0, 8.0, -58.137767414994535, 353.0, 351.0],\n",
       " [353.0, 351.0, 261.0, 423.0, 2.0, -104.80458005259122, 339.0, 353.0],\n",
       " [339.0, 353.0, 339.0, 308.0, 8.0, -45.221676218380054, 353.0, 351.0],\n",
       " [353.0, 351.0, 367.0, 298.0, 9.0, -89.20201791439474, 296.0, 352.0],\n",
       " [296.0, 352.0, 60.0, 559.0, 5.0, -308.00162337234525, 307.0, 375.0],\n",
       " [307.0, 375.0, 305.0, 312.0, 7.0, -66.49060083951716, 291.0, 377.0],\n",
       " [291.0, 377.0, 357.0, 289.0, 2.0, -114.85643212288984, 291.0, 383.0],\n",
       " [291.0, 383.0, 26.0, 542.0, 7.0, -320.3700984798675, 295.0, 368.0],\n",
       " [295.0, 368.0, 27.0, 543.0, 4.0, -316.76489704511135, 293.0, 371.0],\n",
       " [293.0, 371.0, 10.0, 542.0, 5.0, -363.5849281804734, 335.0, 379.0],\n",
       " [335.0, 379.0, 107.0, 559.0, 9.0, -260.2152954766495, 291.0, 375.0],\n",
       " [291.0, 375.0, 309.0, 398.0, 7.0, -16.64331697709324, 295.0, 407.0],\n",
       " [295.0, 407.0, 14.0, 537.0, 4.0, -306.843608374038, 291.0, 405.0],\n",
       " [291.0, 405.0, 52.0, 559.0, 1.0, -298.28342226815084, 305.0, 401.0],\n",
       " [305.0, 401.0, 139.0, 485.0, 1.0, -192.4266093865399, 291.0, 367.0],\n",
       " [291.0, 367.0, 289.0, 355.0, 6.0, -57.723478758647246, 345.0, 369.0],\n",
       " [345.0, 369.0, 10.0, 542.0, 1.0, -341.7206461424302, 292.0, 349.0],\n",
       " [292.0, 349.0, 114.0, 554.0, 4.0, -317.6948221170751, 355.0, 347.0],\n",
       " [355.0, 347.0, 302.0, 317.0, 5.0, -60.90155991434045, 355.0, 347.0],\n",
       " [355.0, 347.0, 289.0, 355.0, 4.0, -66.61080993352356, 355.0, 346.0],\n",
       " [355.0, 346.0, 69.0, 557.0, 8.0, -354.81826334054455, 355.0, 347.0],\n",
       " [355.0, 347.0, 367.0, 257.0, 1.0, -101.27191120937731, 351.0, 357.0],\n",
       " [351.0, 357.0, 139.0, 485.0, 5.0, -256.8598839834668, 355.0, 346.0],\n",
       " [355.0, 346.0, 151.0, 529.0, 1.0, -252.80031645549812, 303.0, 327.0],\n",
       " [303.0, 327.0, 305.0, 312.0, 6.0, -52.773099207835045, 357.0, 321.0],\n",
       " [357.0, 321.0, 302.0, 317.0, 7.0, -8.602325267042627, 307.0, 324.0],\n",
       " [307.0, 324.0, 34.0, 545.0, 7.0, -339.0722636843067, 301.0, 336.0],\n",
       " [301.0, 336.0, 79.0, 536.0, 7.0, -280.28021692584724, 293.0, 355.0],\n",
       " [293.0, 355.0, 247.0, 481.0, 1.0, -138.70832707519762, 341.0, 379.0],\n",
       " [341.0, 379.0, 271.0, 471.0, 8.0, -126.01587201618692, 345.0, 369.0],\n",
       " [345.0, 369.0, 243.0, 455.0, 8.0, -96.04165762834376, 293.0, 373.0],\n",
       " [293.0, 373.0, 357.0, 289.0, 2.0, -113.50770898930169, 329.0, 399.0],\n",
       " [329.0, 399.0, 14.0, 537.0, 7.0, -325.70692347569155, 301.0, 383.0],\n",
       " [301.0, 383.0, 14.0, 531.0, 7.0, -308.65028754238995, 293.0, 399.0],\n",
       " [293.0, 399.0, 14.0, 537.0, 8.0, -305.5503231875234, 295.0, 417.0],\n",
       " [295.0, 417.0, 27.0, 543.0, 9.0, -283.0194339616981, 291.0, 441.0],\n",
       " [291.0, 441.0, 367.0, 279.0, 3.0, -198.6454127333425, 261.0, 447.0],\n",
       " [261.0, 447.0, 14.0, 531.0, 7.0, -282.3349075123372, 287.0, 459.0],\n",
       " [287.0, 459.0, 151.0, 529.0, 4.0, -152.95751043999115, 287.0, 459.0],\n",
       " [287.0, 459.0, 301.0, 325.0, 7.0, -127.57742747053649, 271.0, 449.0],\n",
       " [271.0, 449.0, 17.0, 544.0, 1.0, -277.4833328328028, 283.0, 465.0],\n",
       " [283.0, 465.0, 17.0, 544.0, 3.0, -285.5748588373984, 289.0, 457.0],\n",
       " [289.0, 457.0, 252.0, 439.0, 9.0, -36.68787265568828, 287.0, 450.0],\n",
       " [287.0, 450.0, 10.0, 542.0, 7.0, -277.8812696098821, 277.0, 465.0],\n",
       " [277.0, 465.0, 14.0, 537.0, 3.0, -268.972117514065, 275.0, 472.0],\n",
       " [275.0, 472.0, 252.0, 439.0, 9.0, -44.28317965096906, 271.0, 479.0],\n",
       " [271.0, 479.0, 295.0, 332.0, 7.0, -167.37084572887835, 257.0, 495.0],\n",
       " [257.0, 495.0, 14.0, 531.0, 1.0, -230.0630348404541, 239.0, 483.0],\n",
       " [239.0, 483.0, 59.0, 548.0, 3.0, -220.42912693199145, 269.0, 481.0],\n",
       " [269.0, 481.0, 145.0, 542.0, 4.0, -144.46106741956464, 275.0, 479.0],\n",
       " [275.0, 479.0, 150.0, 542.0, 5.0, -143.26548781894402, 275.0, 472.0],\n",
       " [275.0, 472.0, 301.0, 325.0, 5.0, -147.95945390545344, 277.0, 471.0],\n",
       " [277.0, 471.0, 217.0, 483.0, 6.0, -61.0, 277.0, 472.0],\n",
       " [277.0, 472.0, 97.0, 558.0, 8.0, -194.74342094150447, 275.0, 479.0],\n",
       " [275.0, 479.0, 150.0, 542.0, 1.0, -137.35355838128112, 271.0, 477.0],\n",
       " [271.0, 477.0, 295.0, 332.0, 4.0, -136.7186892857008, 281.0, 468.0],\n",
       " [281.0, 468.0, 297.0, 440.0, 9.0, -31.064449134018133, 271.0, 457.0],\n",
       " [271.0, 457.0, 247.0, 481.0, 5.0, -32.31098884280702, 277.0, 469.0],\n",
       " [277.0, 469.0, 201.0, 520.0, 5.0, -91.52595260361949, 277.0, 469.0],\n",
       " [277.0, 469.0, 297.0, 440.0, 3.0, -38.8329756778952, 275.0, 472.0],\n",
       " [275.0, 472.0, 79.0, 536.0, 3.0, -205.8761763779384, 275.0, 473.0],\n",
       " [275.0, 473.0, 14.0, 538.0, 2.0, -286.6810073932349, 289.0, 457.0],\n",
       " [289.0, 457.0, 14.0, 537.0, 8.0, -294.45712760943655, 295.0, 449.0],\n",
       " [295.0, 449.0, 243.0, 455.0, 4.0, -40.19950248448356, 283.0, 451.0],\n",
       " [283.0, 451.0, 367.0, 279.0, 4.0, -184.09236811991963, 294.0, 448.0],\n",
       " [294.0, 448.0, 301.0, 325.0, 5.0, -117.15374513859982, 295.0, 442.0],\n",
       " [295.0, 442.0, 147.0, 545.0, 9.0, -164.01524319403975, 273.0, 440.0],\n",
       " [273.0, 440.0, 260.0, 417.0, 5.0, -55.072679252057455, 287.0, 465.0],\n",
       " [287.0, 465.0, 14.0, 538.0, 5.0, -282.591578076913, 287.0, 465.0],\n",
       " [287.0, 465.0, 59.0, 548.0, 1.0, -243.32899539512343, 287.0, 463.0],\n",
       " [287.0, 463.0, 10.0, 542.0, 1.0, -298.6000669792289, 291.0, 441.0],\n",
       " [291.0, 441.0, 367.0, 264.0, 1.0, -161.01242188104618, 293.0, 407.0],\n",
       " [293.0, 407.0, 44.0, 540.0, 8.0, -299.2423766781704, 309.0, 401.0],\n",
       " [309.0, 401.0, 367.0, 276.0, 5.0, -147.05441169852742, 319.0, 415.0],\n",
       " [319.0, 415.0, 367.0, 298.0, 3.0, -126.46343345014795, 319.0, 415.0],\n",
       " [319.0, 415.0, 252.0, 439.0, 6.0, -52.009614495783374, 293.0, 407.0],\n",
       " [293.0, 407.0, 361.0, 321.0, 1.0, -103.71113729971339, 295.0, 401.0],\n",
       " [295.0, 401.0, 361.0, 321.0, 8.0, -82.46211251235322, 309.0, 385.0],\n",
       " [309.0, 385.0, 180.0, 512.0, 6.0, -171.14321488157222, 303.0, 393.0],\n",
       " [303.0, 393.0, 201.0, 520.0, 2.0, -160.70158679988197, 309.0, 401.0],\n",
       " [309.0, 401.0, 361.0, 321.0, 2.0, -94.03190947758107, 282.0, 372.0],\n",
       " [282.0, 372.0, 47.0, 495.0, 1.0, -280.60826787534256, 293.0, 360.0],\n",
       " [293.0, 360.0, 339.0, 308.0, 5.0, -46.57252408878007, 351.0, 353.0],\n",
       " [351.0, 353.0, 180.0, 512.0, 6.0, -230.79428069170172, 351.0, 357.0],\n",
       " [351.0, 357.0, 287.0, 342.0, 3.0, -14.035668847618199, 301.0, 343.0],\n",
       " [301.0, 343.0, 289.0, 372.0, 4.0, -69.57010852370435, 355.0, 350.0],\n",
       " [355.0, 350.0, 111.0, 500.0, 6.0, -290.7593506664919, 357.0, 345.0],\n",
       " [357.0, 345.0, 87.0, 558.0, 4.0, -339.24622326563934, 355.0, 350.0],\n",
       " [355.0, 350.0, 367.0, 254.0, 8.0, -92.07062506576133, 353.0, 345.0],\n",
       " [353.0, 345.0, 14.0, 537.0, 6.0, -375.2132726863483, 341.0, 353.0],\n",
       " [341.0, 353.0, 287.0, 342.0, 6.0, -68.35202996254024, 351.0, 366.0],\n",
       " [351.0, 366.0, 107.0, 559.0, 6.0, -274.4886154287642, 295.0, 359.0],\n",
       " [295.0, 359.0, 287.0, 342.0, 4.0, -67.47592163134935, 339.0, 385.0],\n",
       " [339.0, 385.0, 60.0, 559.0, 3.0, -319.6075718752608, 317.0, 369.0],\n",
       " [317.0, 369.0, 139.0, 485.0, 4.0, -203.9730374338726, 297.0, 356.0],\n",
       " [297.0, 356.0, 10.0, 542.0, 7.0, -351.9573837838894, 303.0, 347.0],\n",
       " [303.0, 347.0, 301.0, 325.0, 9.0, -35.17101079013795, 292.0, 359.0],\n",
       " [292.0, 359.0, 261.0, 423.0, 5.0, -59.665735560705194, 307.0, 385.0],\n",
       " [309.0, 385.0, 165.0, 527.0, 1.0, -195.8979326077741, 291.0, 377.0],\n",
       " [291.0, 377.0, 10.0, 542.0, 4.0, -337.61812747540677, 295.0, 361.0],\n",
       " [295.0, 361.0, 287.0, 342.0, 6.0, -18.867962264113206, 297.0, 358.0],\n",
       " [297.0, 358.0, 79.0, 536.0, 3.0, -284.6278271708513, 297.0, 353.0],\n",
       " [297.0, 353.0, 271.0, 471.0, 5.0, -132.00378782444085, 351.0, 366.0],\n",
       " [351.0, 366.0, 10.0, 542.0, 3.0, -386.059580893934, 351.0, 361.0],\n",
       " [351.0, 361.0, 97.0, 558.0, 1.0, -331.48906467634794, 351.0, 345.0],\n",
       " [351.0, 345.0, 147.0, 545.0, 4.0, -301.3104711091203, 355.0, 327.0],\n",
       " [355.0, 327.0, 150.0, 542.0, 7.0, -315.48375552474965, 367.0, 313.0],\n",
       " [367.0, 313.0, 180.0, 512.0, 5.0, -270.1740179958095, 367.0, 317.0],\n",
       " [367.0, 317.0, 302.0, 317.0, 6.0, -61.032778078668514, 363.0, 319.0],\n",
       " [363.0, 319.0, 111.0, 500.0, 4.0, -305.8512710452582, 359.0, 321.0],\n",
       " [359.0, 321.0, 151.0, 529.0, 4.0, -305.47012947258855, 367.0, 313.0],\n",
       " [367.0, 313.0, 222.0, 513.0, 5.0, -251.34040662018512, 366.0, 307.0],\n",
       " [366.0, 307.0, 201.0, 520.0, 2.0, -248.65236777477105, 313.0, 298.0],\n",
       " [313.0, 298.0, 222.0, 513.0, 6.0, -258.11818998280614, 357.0, 293.0],\n",
       " [357.0, 293.0, 307.0, 307.0, 4.0, -56.88585061331157, 363.0, 297.0],\n",
       " [363.0, 297.0, 10.0, 542.0, 7.0, -428.7213547282197, 359.0, 293.0],\n",
       " [359.0, 293.0, 96.0, 489.0, 8.0, -281.27744310555727, 307.0, 303.0],\n",
       " [307.0, 303.0, 309.0, 398.0, 2.0, -87.02298546935747, 311.0, 311.0],\n",
       " [311.0, 311.0, 355.0, 302.0, 9.0, -42.0, 313.0, 302.0],\n",
       " [313.0, 302.0, 17.0, 544.0, 9.0, -354.80276210875246, 300.0, 330.0],\n",
       " [300.0, 330.0, 60.0, 559.0, 7.0, -313.8295715830489, 295.0, 351.0],\n",
       " [295.0, 351.0, 97.0, 558.0, 8.0, -274.37201023428025, 293.0, 366.0],\n",
       " [293.0, 366.0, 201.0, 520.0, 7.0, -165.0242406436097, 293.0, 383.0],\n",
       " [293.0, 383.0, 337.0, 385.0, 9.0, -47.80167361086848, 291.0, 398.0],\n",
       " [291.0, 398.0, 261.0, 423.0, 7.0, -32.0624390837628, 293.0, 425.0],\n",
       " [293.0, 425.0, 367.0, 279.0, 3.0, -169.162643630324, 297.0, 433.0],\n",
       " [297.0, 433.0, 203.0, 495.0, 7.0, -116.81181447096864, 302.0, 433.0],\n",
       " [302.0, 433.0, 165.0, 527.0, 9.0, -152.55163060419906, 291.0, 441.0],\n",
       " [291.0, 441.0, 227.0, 494.0, 4.0, -69.31810730249349, 289.0, 463.0],\n",
       " [289.0, 463.0, 10.0, 542.0, 3.0, -291.56474409640134, 287.0, 451.0],\n",
       " [287.0, 451.0, 44.0, 540.0, 4.0, -265.0018867857359, 295.0, 455.0],\n",
       " [295.0, 455.0, 291.0, 337.0, 1.0, -96.08329719571451, 295.0, 433.0],\n",
       " [295.0, 433.0, 297.0, 440.0, 6.0, -17.46424919657298, 293.0, 423.0],\n",
       " [293.0, 423.0, 165.0, 527.0, 5.0, -168.6297719858507, 305.0, 433.0],\n",
       " [305.0, 433.0, 203.0, 495.0, 1.0, -117.5925167687128, 291.0, 417.0],\n",
       " [291.0, 417.0, 288.0, 457.0, 8.0, -59.135437767890075, 307.0, 401.0],\n",
       " [307.0, 401.0, 247.0, 481.0, 9.0, -72.80109889280519, 291.0, 423.0],\n",
       " [291.0, 423.0, 307.0, 307.0, 5.0, -133.24038426843418, 299.0, 440.0],\n",
       " [299.0, 440.0, 347.0, 366.0, 2.0, -89.04493247793498, 299.0, 441.0],\n",
       " [299.0, 441.0, 87.0, 558.0, 3.0, -247.39644298170498, 293.0, 421.0],\n",
       " [293.0, 421.0, 289.0, 372.0, 1.0, -27.073972741361768, 291.0, 399.0],\n",
       " [291.0, 399.0, 175.0, 531.0, 9.0, -187.72320048411703, 293.0, 385.0],\n",
       " [293.0, 385.0, 201.0, 520.0, 7.0, -142.90206436577463, 291.0, 409.0],\n",
       " [291.0, 409.0, 275.0, 368.0, 3.0, -76.27581530209953, 318.0, 431.0],\n",
       " [318.0, 431.0, 261.0, 423.0, 1.0, -38.8329756778952, 293.0, 401.0],\n",
       " [293.0, 401.0, 34.0, 545.0, 3.0, -310.35785796399614, 293.0, 374.0],\n",
       " [293.0, 374.0, 337.0, 385.0, 8.0, -4.47213595499958, 341.0, 383.0],\n",
       " [341.0, 383.0, 180.0, 512.0, 8.0, -166.06625183943908, 287.0, 385.0],\n",
       " [287.0, 385.0, 297.0, 417.0, 6.0, -12.165525060596439, 299.0, 405.0],\n",
       " [299.0, 405.0, 243.0, 455.0, 3.0, -66.60330322138685, 293.0, 411.0],\n",
       " [293.0, 411.0, 227.0, 470.0, 3.0, -95.90099061010788, 288.0, 396.0],\n",
       " [288.0, 396.0, 147.0, 545.0, 7.0, -208.60728654579637, 293.0, 396.0],\n",
       " [293.0, 396.0, 203.0, 495.0, 8.0, -119.60351165413162, 291.0, 414.0],\n",
       " [291.0, 414.0, 217.0, 483.0, 6.0, -94.40338976964757, 293.0, 427.0],\n",
       " [293.0, 427.0, 10.0, 542.0, 1.0, -306.64800667866734, 297.0, 434.0],\n",
       " [297.0, 434.0, 357.0, 289.0, 5.0, -143.17821063276352, 297.0, 419.0],\n",
       " [297.0, 419.0, 271.0, 471.0, 6.0, -58.180752831155424, 295.0, 418.0],\n",
       " [295.0, 418.0, 14.0, 537.0, 1.0, -303.3298534598927, 289.0, 409.0],\n",
       " [289.0, 409.0, 367.0, 264.0, 6.0, -148.71785366928881, 293.0, 393.0],\n",
       " [293.0, 393.0, 165.0, 527.0, 6.0, -179.61069010501575, 293.0, 401.0],\n",
       " [293.0, 401.0, 150.0, 542.0, 8.0, -194.60986614249546, 293.0, 410.0],\n",
       " [293.0, 410.0, 227.0, 494.0, 7.0, -91.35097153287424, 295.0, 433.0],\n",
       " [295.0, 433.0, 193.0, 507.0, 8.0, -107.5174404457249, 271.0, 433.0],\n",
       " [271.0, 433.0, 151.0, 529.0, 6.0, -151.28780519261954, 289.0, 467.0],\n",
       " [289.0, 467.0, 14.0, 531.0, 4.0, -263.1387466717891, 265.0, 452.0],\n",
       " [265.0, 452.0, 87.0, 558.0, 5.0, -221.472345903501, 288.0, 465.0],\n",
       " [288.0, 465.0, 14.0, 538.0, 1.0, -271.97426348829407, 271.0, 449.0],\n",
       " [271.0, 449.0, 309.0, 398.0, 5.0, -50.44799302251776, 297.0, 447.0],\n",
       " [297.0, 447.0, 295.0, 332.0, 7.0, -109.01834707974616, 293.0, 441.0],\n",
       " [293.0, 441.0, 307.0, 307.0, 9.0, -138.15932831336434, 255.0, 435.0],\n",
       " [255.0, 435.0, 357.0, 289.0, 3.0, -201.357890334598, 273.0, 472.0],\n",
       " [273.0, 472.0, 175.0, 531.0, 6.0, -114.61239025515522, 275.0, 475.0],\n",
       " [275.0, 475.0, 275.0, 368.0, 3.0, -105.01904589168576, 273.0, 473.0],\n",
       " [273.0, 473.0, 96.0, 489.0, 1.0, -199.27117202445515, 293.0, 459.0],\n",
       " [293.0, 459.0, 355.0, 302.0, 7.0, -143.26548781894402, 297.0, 433.0],\n",
       " [297.0, 433.0, 261.0, 423.0, 2.0, -34.17601498127012, 293.0, 435.0],\n",
       " [293.0, 435.0, 302.0, 317.0, 7.0, -107.22872749408155, 295.0, 424.0],\n",
       " [295.0, 424.0, 339.0, 308.0, 5.0, -125.7179382586272, 293.0, 425.0],\n",
       " [293.0, 425.0, 295.0, 332.0, 2.0, -93.02150289046077, 293.0, 425.0],\n",
       " [293.0, 425.0, 10.0, 542.0, 1.0, -318.05974281571696, 291.0, 393.0],\n",
       " [291.0, 393.0, 124.0, 479.0, 8.0, -196.88067452139634, 293.0, 378.0],\n",
       " [293.0, 378.0, 193.0, 507.0, 2.0, -154.67385040788247, 293.0, 389.0],\n",
       " [293.0, 389.0, 52.0, 559.0, 4.0, -301.40006635699336, 293.0, 378.0],\n",
       " [293.0, 378.0, 297.0, 440.0, 7.0, -71.7007670809734, 343.0, 385.0],\n",
       " [343.0, 385.0, 26.0, 542.0, 2.0, -345.69639859275367, 335.0, 387.0],\n",
       " [335.0, 387.0, 34.0, 545.0, 7.0, -333.91765451979325, 319.0, 371.0],\n",
       " [319.0, 371.0, 287.0, 342.0, 1.0, -63.51377803280167, 340.0, 377.0],\n",
       " [340.0, 377.0, 243.0, 455.0, 4.0, -132.6536844569347, 344.0, 369.0],\n",
       " [344.0, 369.0, 295.0, 332.0, 2.0, -16.0312195418814, 296.0, 348.0],\n",
       " [296.0, 348.0, 79.0, 536.0, 7.0, -333.68548065506235, 354.0, 347.0],\n",
       " [354.0, 347.0, 247.0, 481.0, 3.0, -161.83942659315127, 351.0, 357.0],\n",
       " [351.0, 357.0, 111.0, 500.0, 4.0, -282.11522468665174, 353.0, 355.0],\n",
       " [353.0, 355.0, 96.0, 489.0, 9.0, -291.70704482408377, 353.0, 351.0],\n",
       " [353.0, 351.0, 193.0, 507.0, 1.0, -187.48866632412745, 297.0, 351.0],\n",
       " [297.0, 351.0, 227.0, 470.0, 7.0, -178.2133552795637, 355.0, 346.0],\n",
       " [355.0, 346.0, 289.0, 355.0, 4.0, -62.03224967708329, 351.0, 357.0],\n",
       " [351.0, 357.0, 227.0, 470.0, 2.0, -167.7647161950331, 351.0, 357.0],\n",
       " [351.0, 357.0, 252.0, 439.0, 5.0, -135.28118864054971, 353.0, 349.0],\n",
       " [353.0, 349.0, 260.0, 417.0, 7.0, -114.80853626799707, 351.0, 347.0],\n",
       " [351.0, 357.0, 14.0, 538.0, 7.0, -332.27699288394916, 292.0, 356.0],\n",
       " [292.0, 356.0, 145.0, 542.0, 7.0, -220.16584657934573, 293.0, 379.0],\n",
       " [293.0, 379.0, 355.0, 347.0, 8.0, -78.40918313565064, 293.0, 395.0],\n",
       " [293.0, 395.0, 283.0, 410.0, 5.0, -35.6931365951495, 318.0, 417.0],\n",
       " [318.0, 417.0, 291.0, 337.0, 8.0, -84.02380615040002, 293.0, 421.0],\n",
       " [293.0, 421.0, 52.0, 559.0, 3.0, -276.3783638420345, 299.0, 435.0],\n",
       " [299.0, 435.0, 69.0, 557.0, 6.0, -262.9752840097335, 303.0, 437.0],\n",
       " [303.0, 437.0, 175.0, 531.0, 4.0, -153.21879780235844, 299.0, 441.0],\n",
       " [299.0, 441.0, 59.0, 548.0, 2.0, -268.1734513332742, 293.0, 417.0],\n",
       " [293.0, 417.0, 361.0, 321.0, 6.0, -109.63576058932597, 293.0, 407.0],\n",
       " [293.0, 407.0, 355.0, 347.0, 4.0, -88.09086218218096, 299.0, 415.0],\n",
       " [299.0, 415.0, 297.0, 417.0, 4.0, -22.090722034374522, 319.0, 415.0],\n",
       " [319.0, 415.0, 227.0, 494.0, 6.0, -118.3427226321923, 305.0, 405.0],\n",
       " [305.0, 405.0, 107.0, 559.0, 3.0, -245.34873140083687, 293.0, 399.0],\n",
       " [293.0, 399.0, 367.0, 276.0, 1.0, -125.09996003196804, 288.0, 373.0],\n",
       " [288.0, 373.0, 14.0, 538.0, 2.0, -335.0462654619508, 294.0, 354.0],\n",
       " [294.0, 354.0, 337.0, 385.0, 2.0, -61.29437168288782, 303.0, 334.0],\n",
       " [303.0, 334.0, 307.0, 307.0, 3.0, -49.47726750741192, 355.0, 319.0],\n",
       " [355.0, 319.0, 297.0, 440.0, 3.0, -141.52384958020326, 367.0, 317.0],\n",
       " [367.0, 317.0, 151.0, 529.0, 6.0, -292.04280508172087, 356.0, 321.0],\n",
       " [356.0, 321.0, 297.0, 440.0, 8.0, -125.57467897629681, 309.0, 315.0],\n",
       " [309.0, 315.0, 287.0, 342.0, 3.0, -64.03124237432849, 351.0, 340.0],\n",
       " [351.0, 340.0, 247.0, 481.0, 7.0, -176.81628884240274, 355.0, 341.0],\n",
       " [355.0, 341.0, 291.0, 337.0, 7.0, -13.416407864998739, 303.0, 331.0],\n",
       " [303.0, 331.0, 355.0, 302.0, 4.0, -49.040799340956916, 353.0, 351.0],\n",
       " [353.0, 351.0, 10.0, 542.0, 5.0, -400.0124998046936, 357.0, 343.0],\n",
       " [357.0, 343.0, 260.0, 417.0, 5.0, -122.00409829181969, 357.0, 343.0],\n",
       " [357.0, 343.0, 145.0, 542.0, 5.0, -290.766229125736, 357.0, 343.0],\n",
       " [357.0, 343.0, 287.0, 342.0, 6.0, -66.03029607687671, 353.0, 344.0],\n",
       " [353.0, 344.0, 14.0, 531.0, 8.0, -342.0014619851792, 301.0, 345.0],\n",
       " [301.0, 345.0, 297.0, 440.0, 8.0, -82.29823813423954, 290.0, 358.0],\n",
       " [290.0, 358.0, 14.0, 531.0, 9.0, -312.65636088203934, 291.0, 386.0],\n",
       " [291.0, 386.0, 139.0, 485.0, 1.0, -176.2980430974774, 294.0, 401.0],\n",
       " [294.0, 401.0, 367.0, 257.0, 2.0, -142.04224723651762, 291.0, 377.0],\n",
       " [291.0, 377.0, 52.0, 559.0, 9.0, -335.393798392278, 335.0, 379.0],\n",
       " [335.0, 379.0, 59.0, 548.0, 9.0, -276.34217919094436, 293.0, 401.0],\n",
       " [293.0, 401.0, 17.0, 544.0, 5.0, -303.67910695337605, 287.0, 405.0],\n",
       " [287.0, 405.0, 271.0, 471.0, 2.0, -63.50590523722971, 299.0, 414.0],\n",
       " [299.0, 414.0, 203.0, 495.0, 6.0, -121.16517651536682, 294.0, 415.0],\n",
       " [294.0, 415.0, 289.0, 372.0, 9.0, -47.095647357266465, 292.0, 419.0],\n",
       " [292.0, 419.0, 10.0, 542.0, 8.0, -297.40544715926103, 295.0, 457.0],\n",
       " [295.0, 457.0, 297.0, 440.0, 1.0, -26.076809620810597, 271.0, 442.0],\n",
       " [271.0, 442.0, 295.0, 332.0, 2.0, -99.0, 295.0, 431.0],\n",
       " [295.0, 431.0, 289.0, 355.0, 4.0, -55.036351623268054, 287.0, 410.0],\n",
       " [287.0, 410.0, 347.0, 366.0, 5.0, -61.29437168288782, 313.0, 417.0],\n",
       " [313.0, 417.0, 10.0, 542.0, 2.0, -316.36213427020624, 288.0, 391.0],\n",
       " [288.0, 391.0, 339.0, 308.0, 4.0, -84.59905436823747, 293.0, 379.0],\n",
       " [293.0, 379.0, 79.0, 536.0, 1.0, -284.1918366174511, 293.0, 349.0],\n",
       " [293.0, 349.0, 337.0, 385.0, 9.0, -30.4138126514911, 351.0, 358.0],\n",
       " [351.0, 358.0, 59.0, 548.0, 1.0, -305.16389039334257, 297.0, 357.0],\n",
       " [297.0, 357.0, 367.0, 264.0, 8.0, -96.33794683301072, 351.0, 359.0],\n",
       " [351.0, 359.0, 17.0, 544.0, 8.0, -330.6070174693816, 291.0, 359.0],\n",
       " [291.0, 359.0, 347.0, 366.0, 4.0, -54.147945482723536, 293.0, 370.0],\n",
       " [293.0, 370.0, 175.0, 531.0, 6.0, -222.39604313026794, 341.0, 383.0],\n",
       " [341.0, 383.0, 52.0, 559.0, 7.0, -300.8005984036601, 293.0, 379.0],\n",
       " [293.0, 379.0, 337.0, 385.0, 2.0, -34.0, 303.0, 385.0],\n",
       " [303.0, 385.0, 309.0, 398.0, 2.0, -47.01063709417264, 290.0, 355.0],\n",
       " [290.0, 355.0, 217.0, 483.0, 1.0, -169.44615663980107, 303.0, 337.0],\n",
       " [303.0, 337.0, 295.0, 332.0, 9.0, -16.97056274847714, 307.0, 320.0],\n",
       " [307.0, 320.0, 307.0, 307.0, 3.0, -31.25699921617557, 303.0, 338.0],\n",
       " [303.0, 338.0, 14.0, 538.0, 7.0, -387.15629918677547, 353.0, 351.0],\n",
       " [353.0, 351.0, 17.0, 544.0, 2.0, -385.75251133336775, 351.0, 351.0],\n",
       " [351.0, 351.0, 201.0, 520.0, 4.0, -243.28789530101986, 359.0, 335.0],\n",
       " [359.0, 335.0, 79.0, 559.0, 9.0, -329.587621126765, 307.0, 321.0],\n",
       " [307.0, 321.0, 289.0, 355.0, 5.0, -65.19202405202648, 354.0, 350.0],\n",
       " [354.0, 350.0, 60.0, 559.0, 5.0, -360.95567594927775, 355.0, 351.0],\n",
       " [355.0, 351.0, 283.0, 410.0, 4.0, -76.24303246854758, 305.0, 337.0],\n",
       " [305.0, 337.0, 259.0, 382.0, 9.0, -57.28001396647874, 299.0, 341.0],\n",
       " [299.0, 341.0, 367.0, 254.0, 9.0, -140.13208055259867, 293.0, 373.0],\n",
       " [293.0, 373.0, 301.0, 325.0, 6.0, -66.12110101926616, 297.0, 391.0],\n",
       " [297.0, 391.0, 222.0, 513.0, 5.0, -139.84634424968, 303.0, 399.0],\n",
       " [303.0, 399.0, 203.0, 495.0, 8.0, -121.62236636408618, 289.0, 409.0],\n",
       " [289.0, 409.0, 47.0, 495.0, 6.0, -256.632032295269, 295.0, 429.0],\n",
       " [295.0, 429.0, 367.0, 257.0, 7.0, -205.7668583615933, 293.0, 449.0],\n",
       " [293.0, 449.0, 287.0, 342.0, 4.0, -105.17128885774862, 281.0, 447.0],\n",
       " [281.0, 447.0, 180.0, 512.0, 4.0, -132.09844813622905, 295.0, 447.0],\n",
       " [295.0, 447.0, 79.0, 536.0, 4.0, -241.96900627972997, 297.0, 431.0],\n",
       " [297.0, 431.0, 60.0, 559.0, 8.0, -265.84393918237066, 293.0, 431.0],\n",
       " [293.0, 431.0, 307.0, 307.0, 4.0, -136.7186892857008, 293.0, 443.0],\n",
       " [293.0, 443.0, 297.0, 417.0, 7.0, -24.73863375370596, 291.0, 441.0],\n",
       " [291.0, 441.0, 347.0, 366.0, 9.0, -111.07204868912791, 271.0, 447.0],\n",
       " [271.0, 447.0, 260.0, 417.0, 9.0, -62.20128616033595, 265.0, 479.0],\n",
       " [265.0, 479.0, 96.0, 489.0, 6.0, -153.16004700965587, 249.0, 496.0],\n",
       " [249.0, 496.0, 367.0, 257.0, 8.0, -284.42925306655786, 239.0, 511.0],\n",
       " [239.0, 511.0, 271.0, 471.0, 4.0, -60.14149981501958, 227.0, 512.0],\n",
       " [227.0, 512.0, 193.0, 507.0, 1.0, -31.04834939252005, 223.0, 499.0],\n",
       " [223.0, 499.0, 14.0, 531.0, 9.0, -230.70543990118657, 243.0, 503.0],\n",
       " [243.0, 503.0, 367.0, 276.0, 3.0, -268.66335812685736, 235.0, 510.0],\n",
       " [235.0, 510.0, 14.0, 537.0, 4.0, -204.56050449683585, 215.0, 499.0],\n",
       " [215.0, 499.0, 355.0, 302.0, 6.0, -236.30488780387088, 223.0, 498.0],\n",
       " [223.0, 498.0, 283.0, 410.0, 3.0, -112.69871339105873, 233.0, 511.0],\n",
       " [233.0, 511.0, 145.0, 542.0, 8.0, -101.01980003939822, 239.0, 505.0],\n",
       " [239.0, 505.0, 309.0, 398.0, 9.0, -142.56226709757388, 191.0, 478.0],\n",
       " [191.0, 478.0, 60.0, 559.0, 5.0, -154.35349040433132, 211.0, 527.0],\n",
       " [211.0, 527.0, 283.0, 410.0, 9.0, -138.68309197591464, 175.0, 497.0],\n",
       " [175.0, 497.0, 309.0, 398.0, 3.0, -194.74342094150447, 179.0, 543.0],\n",
       " [179.0, 543.0, 367.0, 279.0, 8.0, -325.6270873253636, 175.0, 542.0],\n",
       " [175.0, 542.0, 96.0, 489.0, 5.0, -98.00510190801293, 175.0, 547.0],\n",
       " [175.0, 547.0, 59.0, 548.0, 6.0, -110.07270324653611, 169.0, 544.0],\n",
       " [169.0, 544.0, 79.0, 559.0, 5.0, -85.0, 163.0, 546.0],\n",
       " [163.0, 546.0, 44.0, 540.0, 3.0, -115.35163631262454, 159.0, 549.0],\n",
       " [153.0, 547.0, 139.0, 485.0, 1.0, -67.05221845696084, 159.0, 549.0],\n",
       " [159.0, 549.0, 355.0, 347.0, 2.0, -250.50349298961882, 159.0, 503.0],\n",
       " [159.0, 503.0, 87.0, 558.0, 1.0, -117.0, 195.0, 513.0],\n",
       " [195.0, 513.0, 27.0, 543.0, 4.0, -198.75864761061342, 223.0, 510.0],\n",
       " [223.0, 510.0, 44.0, 540.0, 7.0, -183.63550854886427, 223.0, 499.0],\n",
       " [223.0, 499.0, 367.0, 276.0, 6.0, -267.5985799663369, 239.0, 511.0],\n",
       " [239.0, 511.0, 180.0, 512.0, 8.0, -53.009433122794285, 233.0, 513.0],\n",
       " [233.0, 513.0, 175.0, 531.0, 7.0, -37.36308338453881, 211.0, 521.0],\n",
       " [211.0, 521.0, 87.0, 558.0, 8.0, -104.84750831564858, 175.0, 501.0],\n",
       " [175.0, 501.0, 17.0, 544.0, 4.0, -162.5207679036744, 179.0, 531.0],\n",
       " [179.0, 531.0, 222.0, 513.0, 8.0, -44.94441010848846, 184.0, 537.0],\n",
       " [184.0, 537.0, 107.0, 559.0, 6.0, -63.56099432828282, 169.0, 545.0],\n",
       " [169.0, 545.0, 203.0, 495.0, 7.0, -68.26419266350405, 145.0, 531.0],\n",
       " [145.0, 531.0, 302.0, 317.0, 7.0, -279.60865508778517, 143.0, 547.0],\n",
       " [143.0, 547.0, 217.0, 483.0, 6.0, -99.24716620639605, 142.0, 548.0],\n",
       " [142.0, 548.0, 34.0, 545.0, 6.0, -101.17806086301516, 135.0, 551.0],\n",
       " [135.0, 551.0, 165.0, 527.0, 1.0, -42.941821107167776, 127.0, 547.0],\n",
       " [127.0, 547.0, 180.0, 512.0, 1.0, -55.65968020030299, 127.0, 529.0],\n",
       " [127.0, 529.0, 355.0, 347.0, 4.0, -275.0872588834314, 163.0, 544.0],\n",
       " [163.0, 544.0, 291.0, 337.0, 2.0, -222.61176967986216, 175.0, 527.0],\n",
       " [175.0, 527.0, 227.0, 470.0, 3.0, -63.631753079732135, 195.0, 525.0],\n",
       " [195.0, 525.0, 361.0, 321.0, 2.0, -248.4028985338134, 211.0, 519.0],\n",
       " [211.0, 519.0, 59.0, 548.0, 5.0, -167.28717822953436, 223.0, 515.0],\n",
       " [223.0, 515.0, 291.0, 337.0, 5.0, -190.5465822312224, 223.0, 515.0],\n",
       " [223.0, 515.0, 34.0, 545.0, 7.0, -190.87430418995638, 222.0, 512.0],\n",
       " [222.0, 512.0, 145.0, 542.0, 4.0, -93.30058949438637, 233.0, 511.0],\n",
       " [233.0, 511.0, 355.0, 347.0, 5.0, -198.40362899906847, 235.0, 505.0],\n",
       " [235.0, 505.0, 357.0, 289.0, 8.0, -245.22642598219304, 207.0, 483.0],\n",
       " [207.0, 483.0, 87.0, 558.0, 9.0, -128.87590930814028, 207.0, 511.0],\n",
       " [207.0, 511.0, 107.0, 559.0, 9.0, -80.44874144447506, 153.0, 493.0],\n",
       " [153.0, 493.0, 243.0, 455.0, 9.0, -125.8729518204765, 155.0, 545.0],\n",
       " [155.0, 545.0, 222.0, 513.0, 3.0, -94.93682109698007, 135.0, 551.0],\n",
       " [135.0, 551.0, 339.0, 308.0, 9.0, -323.9891973507759, 127.0, 553.0],\n",
       " [127.0, 553.0, 367.0, 276.0, 7.0, -373.9545426920229, 118.0, 555.0],\n",
       " [118.0, 555.0, 44.0, 540.0, 3.0, -61.68468205316454, 103.0, 558.0],\n",
       " [103.0, 558.0, 60.0, 559.0, 1.0, -39.0, 99.0, 559.0],\n",
       " [99.0, 559.0, 355.0, 302.0, 5.0, -351.55227207344285, 113.0, 557.0],\n",
       " [113.0, 557.0, 301.0, 325.0, 2.0, -267.73867856549975, 101.0, 503.0],\n",
       " [101.0, 503.0, 17.0, 544.0, 5.0, -117.10678887237921, 134.0, 549.0],\n",
       " [134.0, 549.0, 367.0, 298.0, 1.0, -316.9369022376536, 127.0, 505.0],\n",
       " [127.0, 505.0, 114.0, 554.0, 5.0, -57.0087712549569, 169.0, 539.0],\n",
       " [169.0, 539.0, 27.0, 543.0, 6.0, -142.00352108310554, 169.0, 542.0],\n",
       " [169.0, 542.0, 367.0, 279.0, 4.0, -330.4073243740217, 167.0, 542.0],\n",
       " [167.0, 542.0, 150.0, 542.0, 7.0, -23.0, 173.0, 542.0],\n",
       " [173.0, 542.0, 291.0, 337.0, 2.0, -229.71504086585188, 178.0, 537.0],\n",
       " [178.0, 537.0, 367.0, 276.0, 8.0, -319.2303243741108, 179.0, 534.0],\n",
       " [179.0, 534.0, 52.0, 559.0, 5.0, -127.283148923964, 177.0, 535.0],\n",
       " [177.0, 535.0, 44.0, 540.0, 3.0, -135.05924625881784, 179.0, 536.0],\n",
       " [179.0, 536.0, 259.0, 382.0, 4.0, -176.2980430974774, 175.0, 537.0],\n",
       " [175.0, 537.0, 301.0, 325.0, 3.0, -235.6692597688549, 183.0, 529.0],\n",
       " [183.0, 529.0, 243.0, 455.0, 1.0, -80.62257748298549, 185.0, 511.0],\n",
       " [185.0, 511.0, 107.0, 559.0, 5.0, -118.10588469674151, 217.0, 516.0],\n",
       " [217.0, 516.0, 367.0, 264.0, 8.0, -289.3734611190183, 223.0, 515.0],\n",
       " [223.0, 515.0, 60.0, 559.0, 7.0, -168.8342382338369, 223.0, 515.0],\n",
       " [223.0, 515.0, 111.0, 500.0, 2.0, -108.06016842481785, 217.0, 521.0],\n",
       " [217.0, 521.0, 27.0, 543.0, 7.0, -186.76188047886004, 211.0, 511.0],\n",
       " [211.0, 511.0, 291.0, 337.0, 9.0, -192.76929216034384, 217.0, 515.0],\n",
       " [217.0, 515.0, 26.0, 542.0, 9.0, -150.20652449211386, 175.0, 523.0],\n",
       " [175.0, 523.0, 10.0, 542.0, 2.0, -160.00312496948303, 170.0, 543.0],\n",
       " [170.0, 543.0, 301.0, 325.0, 3.0, -254.8489748851268, 169.0, 543.0],\n",
       " [169.0, 543.0, 288.0, 457.0, 1.0, -131.88252348207476, 175.0, 525.0],\n",
       " [175.0, 525.0, 243.0, 455.0, 3.0, -77.82030583337487, 209.0, 525.0],\n",
       " [209.0, 525.0, 79.0, 559.0, 2.0, -142.9405470816451, 215.0, 515.0],\n",
       " [215.0, 515.0, 243.0, 455.0, 1.0, -35.38361202590826, 217.0, 479.0],\n",
       " [217.0, 479.0, 339.0, 308.0, 9.0, -206.8260138377182, 255.0, 497.0],\n",
       " [255.0, 497.0, 291.0, 337.0, 8.0, -165.42067585401773, 249.0, 497.0],\n",
       " [249.0, 497.0, 339.0, 308.0, 1.0, -214.9534833400008, 233.0, 495.0],\n",
       " [233.0, 495.0, 145.0, 542.0, 3.0, -109.20164833920778, 247.0, 503.0],\n",
       " [247.0, 503.0, 252.0, 439.0, 1.0, -37.12142238654117, 219.0, 456.0],\n",
       " [219.0, 456.0, 347.0, 366.0, 2.0, -120.65239326262865, 281.0, 467.0],\n",
       " [281.0, 467.0, 203.0, 495.0, 8.0, -86.53323061113575, 275.0, 447.0],\n",
       " [275.0, 447.0, 26.0, 542.0, 3.0, -274.8981629622141, 289.0, 462.0],\n",
       " [289.0, 462.0, 52.0, 559.0, 7.0, -250.68905041904003, 281.0, 457.0],\n",
       " [281.0, 457.0, 367.0, 279.0, 6.0, -200.63897926375125, 287.0, 463.0],\n",
       " [287.0, 463.0, 44.0, 540.0, 7.0, -245.72545655670274, 278.0, 465.0],\n",
       " [278.0, 465.0, 175.0, 531.0, 8.0, -108.24047302187847, 271.0, 481.0],\n",
       " [271.0, 481.0, 114.0, 554.0, 6.0, -158.90248582070703, 259.0, 489.0],\n",
       " [259.0, 489.0, 260.0, 417.0, 8.0, -72.53275122315436, 241.0, 487.0],\n",
       " [241.0, 487.0, 34.0, 545.0, 7.0, -195.143536915779, 225.0, 505.0],\n",
       " [225.0, 505.0, 165.0, 527.0, 8.0, -43.86342439892262, 195.0, 495.0],\n",
       " [195.0, 495.0, 17.0, 544.0, 2.0, -190.67249408344142, 207.0, 528.0],\n",
       " [207.0, 528.0, 355.0, 302.0, 3.0, -269.3120866207085, 207.0, 527.0],\n",
       " [207.0, 527.0, 347.0, 366.0, 1.0, -193.80660463462024, 191.0, 481.0],\n",
       " [191.0, 481.0, 261.0, 423.0, 2.0, -72.99315036357864, 249.0, 495.0],\n",
       " [249.0, 495.0, 367.0, 276.0, 9.0, -237.95167576632025, 257.0, 487.0],\n",
       " [257.0, 487.0, 10.0, 542.0, 1.0, -251.24689052802225, 257.0, 496.0],\n",
       " [257.0, 496.0, 339.0, 308.0, 9.0, -197.7978766316767, 257.0, 488.0],\n",
       " [257.0, 488.0, 52.0, 559.0, 8.0, -208.4346420343797, 251.0, 497.0],\n",
       " [251.0, 497.0, 193.0, 507.0, 4.0, -46.04345773288535, 239.0, 505.0],\n",
       " [239.0, 505.0, 367.0, 279.0, 3.0, -257.78285435614214, 243.0, 505.0],\n",
       " [243.0, 505.0, 69.0, 557.0, 4.0, -178.04493814764857, 241.0, 511.0],\n",
       " [241.0, 511.0, 247.0, 481.0, 4.0, -18.0, 247.0, 499.0],\n",
       " [247.0, 499.0, 180.0, 512.0, 2.0, -73.824115301167, 247.0, 481.0],\n",
       " [247.0, 481.0, 283.0, 410.0, 3.0, -63.28506932918696, 277.0, 473.0],\n",
       " [277.0, 473.0, 288.0, 457.0, 4.0, -13.45362404707371, 279.0, 467.0],\n",
       " [279.0, 467.0, 291.0, 337.0, 1.0, -98.35141076771599, 259.0, 430.0],\n",
       " [259.0, 430.0, 14.0, 538.0, 8.0, -302.5524747874325, 297.0, 431.0],\n",
       " [297.0, 431.0, 355.0, 347.0, 5.0, -109.41663493271945, 299.0, 441.0],\n",
       " [299.0, 441.0, 151.0, 529.0, 4.0, -170.88007490635061, 295.0, 437.0],\n",
       " [295.0, 437.0, 307.0, 307.0, 4.0, -124.4025723206719, 297.0, 431.0],\n",
       " [297.0, 431.0, 47.0, 495.0, 4.0, -258.0620080523284, 297.0, 431.0],\n",
       " [297.0, 431.0, 127.0, 553.0, 5.0, -209.24626639440905, 297.0, 431.0],\n",
       " [297.0, 431.0, 222.0, 513.0, 6.0, -112.80514172678478, 295.0, 427.0],\n",
       " [295.0, 427.0, 26.0, 542.0, 2.0, -291.35888522576414, 297.0, 435.0],\n",
       " [297.0, 435.0, 297.0, 417.0, 8.0, -7.0, 297.0, 424.0],\n",
       " [297.0, 424.0, 193.0, 507.0, 8.0, -120.9297316626478, 293.0, 439.0],\n",
       " [293.0, 439.0, 175.0, 531.0, 1.0, -139.26952286842948, 289.0, 451.0],\n",
       " [289.0, 451.0, 243.0, 455.0, 9.0, -55.78530272392541, 297.0, 441.0],\n",
       " [297.0, 441.0, 111.0, 500.0, 1.0, -190.93716243832682, 295.0, 449.0],\n",
       " [295.0, 449.0, 367.0, 257.0, 9.0, -191.03926298015284, 303.0, 437.0],\n",
       " [303.0, 437.0, 60.0, 559.0, 1.0, -255.8378392654222, 287.0, 441.0],\n",
       " [287.0, 441.0, 367.0, 254.0, 8.0, -190.43634106966033, 302.0, 433.0],\n",
       " [302.0, 433.0, 107.0, 559.0, 5.0, -229.8173187555716, 303.0, 439.0],\n",
       " [303.0, 439.0, 14.0, 537.0, 2.0, -302.03476621077914, 299.0, 437.0],\n",
       " [299.0, 437.0, 355.0, 347.0, 3.0, -98.08159868191383, 293.0, 423.0],\n",
       " [293.0, 423.0, 307.0, 307.0, 1.0, -97.32420048477151, 291.0, 403.0],\n",
       " [291.0, 403.0, 287.0, 342.0, 3.0, -40.44749683231337, 293.0, 382.0],\n",
       " [293.0, 382.0, 309.0, 398.0, 6.0, -18.027756377319946, 319.0, 383.0],\n",
       " [319.0, 383.0, 96.0, 489.0, 7.0, -224.18296099391677, 293.0, 382.0],\n",
       " [293.0, 382.0, 291.0, 337.0, 9.0, -62.0, 291.0, 399.0],\n",
       " [291.0, 399.0, 10.0, 542.0, 2.0, -328.3321488980328, 319.0, 431.0],\n",
       " [319.0, 431.0, 111.0, 500.0, 6.0, -206.3225629929989, 299.0, 415.0],\n",
       " [299.0, 415.0, 367.0, 264.0, 7.0, -169.09464805250343, 295.0, 417.0],\n",
       " [295.0, 417.0, 275.0, 368.0, 9.0, -68.8839603971781, 291.0, 435.0],\n",
       " [291.0, 435.0, 79.0, 536.0, 9.0, -207.6174366473105, 271.0, 457.0],\n",
       " [271.0, 457.0, 302.0, 317.0, 9.0, -164.9151296879701, 243.0, 471.0],\n",
       " [243.0, 471.0, 355.0, 302.0, 3.0, -228.12277396174193, 249.0, 504.0],\n",
       " [249.0, 504.0, 337.0, 385.0, 8.0, -146.21901381147393, 243.0, 497.0],\n",
       " [243.0, 497.0, 347.0, 366.0, 5.0, -174.01149387324966, 241.0, 504.0],\n",
       " [241.0, 504.0, 150.0, 542.0, 4.0, -100.08995953640904, 243.0, 505.0],\n",
       " [243.0, 505.0, 139.0, 485.0, 6.0, -102.95630140987001, 241.0, 499.0],\n",
       " [241.0, 499.0, 367.0, 279.0, 2.0, -254.52701231892854, 239.0, 499.0],\n",
       " [239.0, 499.0, 260.0, 417.0, 4.0, -86.97700845625813, 247.0, 503.0],\n",
       " [247.0, 503.0, 301.0, 325.0, 1.0, -152.2005256232711, 239.0, 464.0],\n",
       " [239.0, 464.0, 47.0, 495.0, 9.0, -219.10727965998757, 265.0, 473.0],\n",
       " [265.0, 473.0, 287.0, 342.0, 2.0, -138.85243966167826, 259.0, 478.0],\n",
       " [259.0, 478.0, 10.0, 542.0, 3.0, -274.33191575170395, 277.0, 479.0],\n",
       " [277.0, 479.0, 180.0, 512.0, 3.0, -116.86744627996283, 287.0, 465.0],\n",
       " [287.0, 465.0, 367.0, 276.0, 1.0, -195.54283418218117, 293.0, 457.0],\n",
       " [293.0, 457.0, 307.0, 307.0, 2.0, -118.4229707446997, 297.0, 425.0],\n",
       " [297.0, 425.0, 26.0, 542.0, 5.0, -296.08275870100914, 289.0, 406.0],\n",
       " [289.0, 406.0, 367.0, 298.0, 7.0, -131.51805959639154, 311.0, 417.0],\n",
       " [311.0, 417.0, 289.0, 372.0, 8.0, -47.042533945356304, 291.0, 419.0],\n",
       " [291.0, 419.0, 222.0, 513.0, 6.0, -105.3612832116238, 297.0, 439.0],\n",
       " [297.0, 439.0, 288.0, 457.0, 1.0, -16.76305461424021, 293.0, 441.0],\n",
       " [293.0, 441.0, 17.0, 544.0, 3.0, -308.28720375649715, 297.0, 415.0],\n",
       " [297.0, 415.0, 175.0, 531.0, 2.0, -180.27756377319946, 291.0, 393.0],\n",
       " [291.0, 393.0, 243.0, 455.0, 8.0, -86.02325267042627, 293.0, 385.0],\n",
       " [293.0, 385.0, 227.0, 470.0, 2.0, -98.29038610159185, 297.0, 401.0],\n",
       " [297.0, 401.0, 201.0, 520.0, 1.0, -174.07182425654074, 291.0, 371.0],\n",
       " [291.0, 371.0, 347.0, 366.0, 9.0, -52.46903848937962, 295.0, 359.0],\n",
       " [295.0, 359.0, 60.0, 559.0, 3.0, -300.04166377354994, 303.0, 383.0],\n",
       " [303.0, 383.0, 217.0, 483.0, 8.0, -132.87964479181903, 293.0, 374.0],\n",
       " [293.0, 374.0, 150.0, 542.0, 2.0, -213.71476317746513, 295.0, 385.0],\n",
       " [295.0, 385.0, 79.0, 559.0, 8.0, -283.3513719747974, 291.0, 371.0],\n",
       " [291.0, 371.0, 79.0, 559.0, 5.0, -276.1756687327832, 291.0, 382.0],\n",
       " [291.0, 382.0, 260.0, 417.0, 1.0, -47.50789408087881, 291.0, 381.0],\n",
       " [291.0, 381.0, 295.0, 332.0, 8.0, -35.05709628591621, 293.0, 367.0],\n",
       " [293.0, 367.0, 288.0, 457.0, 4.0, -80.30566605165541, 295.0, 377.0],\n",
       " [295.0, 377.0, 260.0, 417.0, 1.0, -61.85466837676846, 295.0, 366.0],\n",
       " [295.0, 366.0, 339.0, 308.0, 9.0, -60.108235708594876, 297.0, 351.0],\n",
       " [297.0, 351.0, 135.0, 547.0, 1.0, -240.26027553467927, 293.0, 366.0],\n",
       " [293.0, 366.0, 217.0, 483.0, 4.0, -179.8777362543792, 351.0, 363.0],\n",
       " [351.0, 363.0, 261.0, 423.0, 1.0, -109.2520022699813, 305.0, 323.0],\n",
       " [305.0, 323.0, 135.0, 547.0, 6.0, -315.39816105995294, 355.0, 321.0],\n",
       " [355.0, 321.0, 165.0, 527.0, 2.0, -261.5434954266689, 311.0, 310.0],\n",
       " [311.0, 310.0, 69.0, 557.0, 7.0, -377.89548819746443, 355.0, 310.0],\n",
       " [355.0, 310.0, 79.0, 559.0, 4.0, -375.3664875824692, 359.0, 309.0],\n",
       " [359.0, 309.0, 227.0, 470.0, 2.0, -196.3517252279694, 312.0, 293.0],\n",
       " [312.0, 293.0, 260.0, 417.0, 5.0, -168.12197952677099, 369.0, 289.0],\n",
       " [369.0, 289.0, 227.0, 470.0, 8.0, -222.84748147555987, 357.0, 289.0],\n",
       " [357.0, 289.0, 297.0, 417.0, 4.0, -133.29666162361306, 359.0, 299.0],\n",
       " [359.0, 299.0, 367.0, 298.0, 9.0, -56.00892785976178, 311.0, 299.0],\n",
       " [311.0, 299.0, 339.0, 308.0, 8.0, -36.71511950137164, 307.0, 326.0],\n",
       " [307.0, 326.0, 355.0, 302.0, 7.0, -68.81860213634101, 299.0, 342.0],\n",
       " [299.0, 342.0, 287.0, 342.0, 2.0, -8.06225774829855, 294.0, 346.0],\n",
       " [294.0, 346.0, 14.0, 537.0, 3.0, -360.62445840513925, 305.0, 324.0],\n",
       " [305.0, 324.0, 147.0, 545.0, 9.0, -271.22131184698594, 307.0, 326.0],\n",
       " [307.0, 326.0, 247.0, 481.0, 2.0, -153.57408635573907, 303.0, 338.0],\n",
       " [303.0, 338.0, 139.0, 485.0, 8.0, -227.72790781983662, 303.0, 327.0],\n",
       " [303.0, 327.0, 361.0, 321.0, 3.0, -61.35144660071187, 303.0, 341.0],\n",
       " [303.0, 341.0, 124.0, 479.0, 8.0, -229.10696191953662, 303.0, 336.0],\n",
       " [303.0, 336.0, 97.0, 558.0, 5.0, -320.22023671217283, 351.0, 363.0],\n",
       " [351.0, 363.0, 243.0, 455.0, 5.0, -141.8731828077456, 351.0, 363.0],\n",
       " [351.0, 363.0, 275.0, 368.0, 3.0, -31.240998703626616, 299.0, 348.0],\n",
       " [299.0, 348.0, 97.0, 558.0, 7.0, -320.22023671217283, 351.0, 363.0],\n",
       " [351.0, 363.0, 175.0, 531.0, 9.0, -212.19095173922943, 295.0, 356.0],\n",
       " [295.0, 356.0, 203.0, 495.0, 8.0, -146.81961721786362, 293.0, 379.0],\n",
       " [293.0, 379.0, 339.0, 308.0, 9.0, -112.69871339105873, 289.0, 409.0],\n",
       " [289.0, 409.0, 10.0, 542.0, 1.0, -308.0795351853154, 297.0, 430.0],\n",
       " [297.0, 430.0, 10.0, 542.0, 2.0, -313.5889028648814, 287.0, 395.0],\n",
       " [287.0, 395.0, 60.0, 559.0, 1.0, -301.9155511065967, 293.0, 367.0],\n",
       " [293.0, 367.0, 79.0, 559.0, 8.0, -299.24738929521175, 297.0, 354.0],\n",
       " [297.0, 354.0, 287.0, 342.0, 3.0, -24.73863375370596, 293.0, 366.0],\n",
       " [293.0, 366.0, 367.0, 254.0, 5.0, -126.19429464123962, 325.0, 373.0],\n",
       " [325.0, 373.0, 96.0, 489.0, 4.0, -237.69938998659632, 295.0, 359.0],\n",
       " [295.0, 359.0, 367.0, 276.0, 1.0, -90.02777349240623, 299.0, 335.0],\n",
       " [299.0, 335.0, 47.0, 495.0, 2.0, -314.5854414940399, 305.0, 315.0],\n",
       " [305.0, 315.0, 14.0, 531.0, 5.0, -411.76813864115326, 367.0, 319.0],\n",
       " [367.0, 319.0, 339.0, 308.0, 4.0, -28.0178514522438, 367.0, 309.0],\n",
       " [367.0, 309.0, 217.0, 483.0, 9.0, -203.06649157357302, 311.0, 303.0],\n",
       " [311.0, 303.0, 367.0, 276.0, 5.0, -53.33854141237835, 361.0, 329.0],\n",
       " [361.0, 329.0, 222.0, 513.0, 5.0, -230.6013876801265, 361.0, 329.0],\n",
       " [361.0, 329.0, 227.0, 494.0, 7.0, -202.5660386145713, 355.0, 337.0],\n",
       " [355.0, 337.0, 203.0, 495.0, 7.0, -209.3800372528384, 355.0, 351.0],\n",
       " [355.0, 351.0, 97.0, 558.0, 3.0, -327.96493715029965, 353.0, 353.0],\n",
       " [353.0, 353.0, 201.0, 520.0, 5.0, -233.11156127485398, 355.0, 345.0],\n",
       " [355.0, 345.0, 227.0, 470.0, 5.0, -176.08236708995025, 353.0, 347.0],\n",
       " [353.0, 347.0, 367.0, 298.0, 4.0, -46.486557196677836, 352.0, 342.0],\n",
       " [352.0, 342.0, 14.0, 531.0, 5.0, -393.8591118661596, 359.0, 341.0],\n",
       " [359.0, 341.0, 107.0, 559.0, 6.0, -331.60518693168837, 356.0, 340.0],\n",
       " [356.0, 340.0, 297.0, 417.0, 5.0, -92.45539465060976, 355.0, 345.0],\n",
       " [355.0, 345.0, 355.0, 347.0, 3.0, -12.0, 355.0, 335.0],\n",
       " [355.0, 335.0, 283.0, 410.0, 3.0, -111.39569111954016, 355.0, 325.0],\n",
       " [355.0, 325.0, 305.0, 312.0, 3.0, -5.0990195135927845, 310.0, 311.0],\n",
       " [310.0, 311.0, 297.0, 440.0, 3.0, -136.1653406708183, 351.0, 315.0],\n",
       " [351.0, 315.0, 135.0, 547.0, 5.0, -322.6391172812125, 355.0, 311.0],\n",
       " [355.0, 311.0, 150.0, 542.0, 6.0, -291.23358322830836, 309.0, 298.0],\n",
       " [309.0, 298.0, 145.0, 542.0, 3.0, -285.4277491765648, 307.0, 307.0],\n",
       " [307.0, 307.0, 260.0, 417.0, 9.0, -113.46365056704283, 303.0, 312.0],\n",
       " [303.0, 312.0, 14.0, 537.0, 7.0, -348.1738071710737, 299.0, 337.0],\n",
       " [299.0, 337.0, 297.0, 417.0, 6.0, -72.0, 297.0, 345.0],\n",
       " [297.0, 345.0, 44.0, 540.0, 2.0, -316.62280397975127, 295.0, 347.0],\n",
       " [295.0, 347.0, 147.0, 545.0, 6.0, -254.82543044209697, 297.0, 339.0],\n",
       " [297.0, 339.0, 291.0, 337.0, 9.0, -14.142135623730951, 293.0, 351.0],\n",
       " [293.0, 351.0, 79.0, 536.0, 8.0, -261.6027522790997, 289.0, 380.0],\n",
       " [289.0, 380.0, 289.0, 355.0, 2.0, -34.058772731852805, 291.0, 389.0],\n",
       " [291.0, 389.0, 367.0, 264.0, 1.0, -120.10412149464314, 291.0, 357.0],\n",
       " [291.0, 357.0, 175.0, 531.0, 7.0, -222.44100341438852, 297.0, 345.0],\n",
       " [297.0, 345.0, 60.0, 559.0, 2.0, -319.3195891266303, 297.0, 345.0],\n",
       " [297.0, 345.0, 367.0, 257.0, 9.0, -113.70136322841516, 295.0, 345.0],\n",
       " [295.0, 345.0, 69.0, 557.0, 3.0, -298.80428377116687, 291.0, 357.0],\n",
       " [291.0, 357.0, 301.0, 325.0, 2.0, -19.697715603592208, 293.0, 343.0],\n",
       " [293.0, 343.0, 150.0, 542.0, 3.0, -255.44079548889601, 291.0, 329.0],\n",
       " [291.0, 329.0, 301.0, 325.0, 3.0, -49.24428900898052, 321.0, 370.0],\n",
       " [321.0, 370.0, 96.0, 489.0, 9.0, -237.7414562082095, 291.0, 353.0],\n",
       " [291.0, 353.0, 289.0, 355.0, 5.0, -13.0, 277.0, 360.0],\n",
       " [277.0, 360.0, 355.0, 347.0, 2.0, -72.09022125087424, 289.0, 376.0],\n",
       " [289.0, 376.0, 69.0, 557.0, 7.0, -295.97972903562163, 289.0, 359.0],\n",
       " [289.0, 359.0, 227.0, 470.0, 3.0, -121.93850909372314, 289.0, 365.0],\n",
       " [289.0, 365.0, 175.0, 531.0, 3.0, -207.3475343475297, 283.0, 354.0],\n",
       " [283.0, 354.0, 69.0, 557.0, 1.0, -288.0902636327719, 289.0, 371.0],\n",
       " [289.0, 371.0, 367.0, 264.0, 7.0, -119.55333537798099, 285.0, 351.0],\n",
       " [285.0, 351.0, 203.0, 495.0, 1.0, -160.31219541881399, 291.0, 361.0],\n",
       " [291.0, 361.0, 111.0, 500.0, 3.0, -240.8318915758459, 291.0, 340.0],\n",
       " [291.0, 340.0, 259.0, 382.0, 4.0, -52.009614495783374, 291.0, 341.0],\n",
       " [291.0, 341.0, 367.0, 264.0, 2.0, -106.07544484940895, 293.0, 340.0],\n",
       " [293.0, 340.0, 355.0, 347.0, 5.0, -52.08646657242167, 303.0, 350.0],\n",
       " [303.0, 350.0, 203.0, 495.0, 3.0, -178.23860412379804, 291.0, 340.0],\n",
       " [291.0, 340.0, 69.0, 557.0, 7.0, -306.96579614022147, 291.0, 345.0],\n",
       " [291.0, 345.0, 180.0, 512.0, 8.0, -183.43936327844142, 287.0, 363.0],\n",
       " [287.0, 363.0, 271.0, 471.0, 3.0, -91.21403400793103, 295.0, 383.0],\n",
       " [295.0, 383.0, 87.0, 558.0, 3.0, -277.41665415039523, 291.0, 370.0],\n",
       " [291.0, 370.0, 14.0, 537.0, 8.0, -328.18439938546743, 291.0, 361.0],\n",
       " [291.0, 361.0, 367.0, 298.0, 3.0, -113.27841806805037, 291.0, 382.0],\n",
       " [291.0, 382.0, 97.0, 558.0, 7.0, -263.964012698701, 291.0, 379.0],\n",
       " [291.0, 379.0, 259.0, 382.0, 3.0, -32.0624390837628, 291.0, 384.0],\n",
       " [291.0, 384.0, 135.0, 547.0, 6.0, -223.44574285494903, 293.0, 389.0],\n",
       " [293.0, 389.0, 111.0, 500.0, 8.0, -207.93508602446101, 270.0, 366.0],\n",
       " [270.0, 366.0, 193.0, 507.0, 8.0, -119.97082978791136, 285.0, 430.0],\n",
       " [285.0, 430.0, 302.0, 317.0, 4.0, -119.85407794480753, 281.0, 435.0],\n",
       " [281.0, 435.0, 355.0, 347.0, 1.0, -99.6393496566492, 293.0, 425.0],\n",
       " [293.0, 425.0, 14.0, 537.0, 8.0, -308.65028754238995, 293.0, 405.0],\n",
       " [293.0, 405.0, 47.0, 495.0, 4.0, -268.2088738278434, 303.0, 415.0],\n",
       " [303.0, 415.0, 47.0, 495.0, 7.0, -264.4617174564213, 291.0, 393.0],\n",
       " [291.0, 393.0, 165.0, 527.0, 4.0, -179.61069010501575, 291.0, 399.0],\n",
       " [291.0, 399.0, 287.0, 342.0, 3.0, -61.68468205316454, 305.0, 401.0],\n",
       " [305.0, 401.0, 97.0, 558.0, 7.0, -261.2680615766114, 291.0, 383.0],\n",
       " [291.0, 383.0, 297.0, 440.0, 5.0, -41.0, 297.0, 399.0],\n",
       " [297.0, 399.0, 151.0, 529.0, 6.0, -194.0, 295.0, 399.0],\n",
       " [295.0, 399.0, 111.0, 500.0, 7.0, -200.8706051168264, 293.0, 415.0],\n",
       " [293.0, 415.0, 260.0, 417.0, 8.0, -38.48376280978771, 295.0, 433.0],\n",
       " [295.0, 433.0, 295.0, 332.0, 7.0, -120.14990636700472, 289.0, 452.0],\n",
       " [289.0, 452.0, 252.0, 439.0, 7.0, -26.92582403567252, 277.0, 449.0],\n",
       " [277.0, 449.0, 34.0, 545.0, 7.0, -257.11670501933554, 279.0, 467.0],\n",
       " [279.0, 467.0, 302.0, 317.0, 7.0, -166.37307474468338, 274.0, 481.0],\n",
       " [274.0, 481.0, 10.0, 542.0, 2.0, -267.58550035455954, 271.0, 483.0],\n",
       " [271.0, 483.0, 339.0, 308.0, 1.0, -155.65667348366404, 249.0, 435.0],\n",
       " [249.0, 435.0, 287.0, 342.0, 9.0, -107.16809226630845, 293.0, 449.0],\n",
       " [293.0, 449.0, 367.0, 279.0, 6.0, -202.23748416156684, 271.0, 457.0],\n",
       " [271.0, 457.0, 147.0, 545.0, 1.0, -148.8220413782851, 259.0, 447.0],\n",
       " [259.0, 447.0, 114.0, 554.0, 9.0, -200.8033864256278, 293.0, 463.0],\n",
       " [293.0, 463.0, 10.0, 542.0, 2.0, -274.4922585429323, 271.0, 457.0],\n",
       " [271.0, 457.0, 287.0, 342.0, 6.0, -123.0, 287.0, 465.0],\n",
       " [287.0, 465.0, 357.0, 289.0, 7.0, -191.70811146114815, 281.0, 465.0],\n",
       " [281.0, 465.0, 367.0, 254.0, 1.0, -221.16283593768642, 259.0, 447.0],\n",
       " [259.0, 447.0, 97.0, 558.0, 2.0, -228.26519664635694, 293.0, 441.0],\n",
       " [293.0, 441.0, 203.0, 495.0, 3.0, -120.41594578792295, 293.0, 415.0],\n",
       " [293.0, 415.0, 193.0, 507.0, 5.0, -138.85243966167826, 297.0, 415.0],\n",
       " [297.0, 415.0, 355.0, 347.0, 3.0, -84.8528137423857, 295.0, 407.0],\n",
       " [295.0, 407.0, 203.0, 495.0, 4.0, -132.93607486307093, 297.0, 401.0],\n",
       " [297.0, 401.0, 357.0, 289.0, 7.0, -120.06664815842908, 297.0, 393.0],\n",
       " [297.0, 393.0, 217.0, 483.0, 9.0, -104.65180361560904, 291.0, 409.0],\n",
       " [291.0, 409.0, 309.0, 398.0, 8.0, -45.880278987817846, 293.0, 441.0],\n",
       " [293.0, 441.0, 203.0, 495.0, 5.0, -96.60227740586657, 289.0, 451.0],\n",
       " [289.0, 451.0, 305.0, 312.0, 8.0, -152.0690632574555, 287.0, 463.0],\n",
       " [287.0, 463.0, 150.0, 542.0, 6.0, -144.25324953012324, 275.0, 470.0],\n",
       " [275.0, 470.0, 17.0, 544.0, 2.0, -266.30809225406574, 275.0, 478.0],\n",
       " [275.0, 478.0, 34.0, 545.0, 9.0, -249.8739682319869, 275.0, 479.0],\n",
       " [275.0, 479.0, 309.0, 398.0, 1.0, -93.49331526906082, 259.0, 477.0],\n",
       " [259.0, 477.0, 87.0, 558.0, 6.0, -206.15528128088303, 277.0, 478.0],\n",
       " [277.0, 478.0, 283.0, 410.0, 5.0, -70.03570517957252, 271.0, 479.0],\n",
       " [271.0, 479.0, 309.0, 398.0, 9.0, -92.64987857520376, 259.0, 476.0],\n",
       " [247.0, 481.0, 297.0, 440.0, 8.0, -77.07788269017254, 243.0, 495.0],\n",
       " [243.0, 495.0, 367.0, 264.0, 8.0, -270.11293934204633, 227.0, 495.0],\n",
       " [227.0, 495.0, 52.0, 559.0, 8.0, -176.08236708995025, 223.0, 517.0],\n",
       " [223.0, 517.0, 291.0, 337.0, 4.0, -206.15528128088303, 211.0, 527.0],\n",
       " [211.0, 527.0, 288.0, 457.0, 6.0, -101.23734488813898, 195.0, 497.0],\n",
       " [195.0, 497.0, 14.0, 538.0, 8.0, -168.5852899869974, 175.0, 488.0],\n",
       " [175.0, 488.0, 79.0, 559.0, 9.0, -101.24228365658294, 176.0, 530.0],\n",
       " [176.0, 530.0, 151.0, 529.0, 9.0, -32.57299494980466, 141.0, 498.0],\n",
       " [141.0, 498.0, 259.0, 382.0, 6.0, -210.41150158677164, 131.0, 549.0],\n",
       " [131.0, 549.0, 260.0, 417.0, 9.0, -172.53985046939155, 111.0, 504.0],\n",
       " [111.0, 504.0, 289.0, 372.0, 7.0, -263.86549603917524, 97.0, 553.0],\n",
       " [97.0, 553.0, 151.0, 529.0, 9.0, -83.93449827097318, 73.0, 498.0],\n",
       " [73.0, 498.0, 127.0, 553.0, 7.0, -94.64142856064674, 53.0, 494.0],\n",
       " [53.0, 494.0, 247.0, 481.0, 7.0, -217.55459085020476, 36.0, 534.0],\n",
       " [36.0, 534.0, 227.0, 494.0, 6.0, -192.57466084612483, 40.0, 540.0],\n",
       " [40.0, 540.0, 10.0, 542.0, 6.0, -26.076809620810597, 36.0, 544.0],\n",
       " [36.0, 544.0, 339.0, 308.0, 8.0, -376.80897016923575, 36.0, 532.0],\n",
       " [36.0, 532.0, 227.0, 494.0, 3.0, -194.74342094150447, 36.0, 532.0],\n",
       " [36.0, 532.0, 150.0, 542.0, 7.0, -113.01769772916099, 37.0, 544.0],\n",
       " [37.0, 544.0, 247.0, 481.0, 3.0, -217.59825366946308, 37.0, 538.0],\n",
       " [37.0, 538.0, 367.0, 264.0, 8.0, -436.58905162635494, 38.0, 551.0],\n",
       " [38.0, 551.0, 69.0, 557.0, 9.0, -35.4682957019364, 36.0, 544.0],\n",
       " [36.0, 544.0, 307.0, 307.0, 3.0, -354.3585754571208, 30.0, 528.0],\n",
       " [30.0, 528.0, 347.0, 366.0, 6.0, -370.95147930693037, 21.0, 543.0],\n",
       " [21.0, 543.0, 288.0, 457.0, 6.0, -281.18677067031444, 17.0, 532.0],\n",
       " [17.0, 532.0, 289.0, 355.0, 4.0, -328.105166067223, 16.0, 537.0],\n",
       " [16.0, 537.0, 69.0, 557.0, 1.0, -66.73080248281148, 36.0, 499.0],\n",
       " [36.0, 499.0, 227.0, 494.0, 3.0, -166.00301202086666, 61.0, 495.0],\n",
       " [61.0, 495.0, 355.0, 347.0, 6.0, -357.2296180329957, 57.0, 544.0],\n",
       " [57.0, 544.0, 47.0, 495.0, 9.0, -49.01020301937138, 48.0, 544.0],\n",
       " [48.0, 544.0, 275.0, 368.0, 4.0, -288.60006930006097, 44.0, 541.0],\n",
       " [44.0, 541.0, 339.0, 308.0, 4.0, -365.75948381415895, 53.0, 536.0],\n",
       " [53.0, 536.0, 114.0, 554.0, 6.0, -59.93329625508679, 60.0, 528.0],\n",
       " [60.0, 528.0, 227.0, 494.0, 4.0, -180.23595645708434, 53.0, 541.0],\n",
       " [53.0, 541.0, 367.0, 264.0, 3.0, -416.18505499356894, 60.0, 545.0],\n",
       " [60.0, 545.0, 127.0, 553.0, 8.0, -71.19691004531025, 57.0, 540.0],\n",
       " [57.0, 540.0, 305.0, 312.0, 7.0, -342.6601815209932, 51.0, 542.0],\n",
       " [51.0, 542.0, 337.0, 385.0, 6.0, -334.32020579079574, 44.0, 546.0],\n",
       " [44.0, 546.0, 139.0, 485.0, 7.0, -109.00458705944443, 38.0, 526.0],\n",
       " [38.0, 526.0, 287.0, 342.0, 6.0, -310.0774096899031, 29.0, 514.0],\n",
       " [29.0, 514.0, 44.0, 540.0, 3.0, -26.076809620810597, 18.0, 542.0],\n",
       " [18.0, 542.0, 201.0, 520.0, 1.0, -172.40939649566667, 30.0, 498.0],\n",
       " [30.0, 498.0, 301.0, 325.0, 5.0, -343.2855953866984, 35.0, 542.0],\n",
       " [35.0, 542.0, 287.0, 342.0, 4.0, -317.34523787194286, 39.0, 540.0],\n",
       " [39.0, 540.0, 14.0, 531.0, 6.0, -33.61547262794322, 45.0, 544.0],\n",
       " [45.0, 544.0, 337.0, 385.0, 9.0, -338.64730915806786, 38.0, 544.0],\n",
       " [38.0, 544.0, 135.0, 547.0, 5.0, -109.1146186356347, 26.0, 542.0],\n",
       " [26.0, 542.0, 260.0, 417.0, 8.0, -290.7593506664919, 281.0, 127.0],\n",
       " [281.0, 127.0, 291.0, 337.0, 3.0, -344.0930106817051, 11.0, 537.0],\n",
       " [11.0, 537.0, 114.0, 554.0, 6.0, -103.78824596263297, 20.0, 510.0],\n",
       " [20.0, 510.0, 203.0, 495.0, 7.0, -192.5876423865249, 14.0, 532.0],\n",
       " [14.0, 532.0, 47.0, 495.0, 3.0, -55.47071299343465, 16.0, 541.0],\n",
       " [16.0, 541.0, 247.0, 481.0, 8.0, -238.73206738936435, 14.0, 533.0],\n",
       " [14.0, 533.0, 259.0, 382.0, 6.0, -290.0224129270012, 12.0, 534.0],\n",
       " [12.0, 534.0, 357.0, 289.0, 2.0, -426.28277000132204, 11.0, 538.0],\n",
       " [11.0, 538.0, 217.0, 483.0, 7.0, -198.84164553734712, 20.0, 510.0],\n",
       " [20.0, 510.0, 34.0, 545.0, 1.0, -16.1245154965971, 18.0, 543.0],\n",
       " [18.0, 543.0, 87.0, 558.0, 9.0, -63.788713735268246, 25.0, 543.0],\n",
       " [25.0, 543.0, 259.0, 382.0, 7.0, -279.94642344563005, 22.0, 531.0],\n",
       " [22.0, 531.0, 79.0, 536.0, 8.0, -57.3149195236284, 22.0, 542.0],\n",
       " [22.0, 542.0, 347.0, 366.0, 2.0, -367.29416004069543, 23.0, 539.0],\n",
       " [23.0, 539.0, 60.0, 559.0, 3.0, -67.1863081289633, 43.0, 494.0],\n",
       " [43.0, 494.0, 96.0, 489.0, 6.0, -76.69419795525604, 37.0, 538.0],\n",
       " [37.0, 538.0, 287.0, 342.0, 3.0, -283.86792703650053, 46.0, 492.0],\n",
       " [46.0, 492.0, 201.0, 520.0, 9.0, -153.9415473483361, 48.0, 537.0],\n",
       " [48.0, 537.0, 124.0, 479.0, 7.0, -103.81233067415451, 40.0, 540.0],\n",
       " [40.0, 540.0, 52.0, 559.0, 5.0, -24.041630560342615, 35.0, 542.0],\n",
       " [35.0, 542.0, 26.0, 542.0, 4.0, -13.341664064126334, 39.0, 539.0],\n",
       " [39.0, 539.0, 271.0, 471.0, 4.0, -239.38462774372127, 44.0, 547.0],\n",
       " [44.0, 547.0, 297.0, 417.0, 5.0, -280.8629559055448, 47.0, 545.0],\n",
       " [47.0, 545.0, 79.0, 559.0, 7.0, -44.598206241955516, 46.0, 529.0],\n",
       " [46.0, 529.0, 14.0, 537.0, 5.0, -15.524174696260024, 29.0, 533.0],\n",
       " [29.0, 533.0, 283.0, 410.0, 5.0, -282.65172916506276, 29.0, 534.0],\n",
       " [29.0, 534.0, 151.0, 529.0, 4.0, -121.2023102090055, 30.0, 536.0],\n",
       " [30.0, 536.0, 193.0, 507.0, 7.0, -160.3277892319357, 37.0, 544.0],\n",
       " [37.0, 544.0, 357.0, 289.0, 7.0, -394.50728763864424, 47.0, 533.0],\n",
       " [47.0, 533.0, 367.0, 264.0, 2.0, -428.10863107393664, 53.0, 555.0],\n",
       " [53.0, 555.0, 47.0, 495.0, 1.0, -22.360679774997898, 69.0, 499.0],\n",
       " [69.0, 499.0, 26.0, 542.0, 3.0, -71.7007670809734, 97.0, 552.0],\n",
       " [97.0, 552.0, 227.0, 470.0, 8.0, -143.22011031974526, 111.0, 554.0],\n",
       " [111.0, 554.0, 243.0, 455.0, 9.0, -158.24032355881985, 91.0, 499.0],\n",
       " [91.0, 499.0, 127.0, 553.0, 5.0, -52.15361924162119, 75.0, 549.0],\n",
       " [75.0, 549.0, 367.0, 279.0, 3.0, -399.9062390110962, 72.0, 549.0],\n",
       " [72.0, 549.0, 367.0, 279.0, 4.0, -397.69837817119645, 75.0, 549.0],\n",
       " [75.0, 549.0, 10.0, 542.0, 1.0, -81.54140052758476, 78.0, 497.0],\n",
       " [78.0, 497.0, 203.0, 495.0, 5.0, -108.75660899458019, 111.0, 553.0],\n",
       " [111.0, 553.0, 217.0, 483.0, 2.0, -121.8031198286809, 111.0, 543.0],\n",
       " [111.0, 543.0, 367.0, 279.0, 6.0, -362.93250061133955, 129.0, 553.0],\n",
       " [129.0, 553.0, 227.0, 470.0, 4.0, -128.42507543311004, 129.0, 553.0],\n",
       " [129.0, 553.0, 107.0, 559.0, 4.0, -26.0, 131.0, 549.0],\n",
       " [131.0, 549.0, 289.0, 372.0, 9.0, -226.99118925632334, 127.0, 531.0],\n",
       " [127.0, 531.0, 96.0, 489.0, 1.0, -68.42514157822401, 127.0, 550.0],\n",
       " [127.0, 550.0, 367.0, 276.0, 8.0, -354.7012827718558, 129.0, 539.0],\n",
       " [129.0, 539.0, 291.0, 337.0, 3.0, -266.01691675530714, 129.0, 548.0],\n",
       " [129.0, 548.0, 367.0, 298.0, 1.0, -310.49798711102784, 127.0, 495.0],\n",
       " [127.0, 495.0, 135.0, 547.0, 9.0, -20.615528128088304, 155.0, 542.0],\n",
       " [155.0, 542.0, 150.0, 542.0, 8.0, -47.01063709417264, 127.0, 501.0],\n",
       " [127.0, 501.0, 165.0, 527.0, 2.0, -46.647615158762406, 125.0, 551.0],\n",
       " [125.0, 551.0, 79.0, 536.0, 5.0, -50.0, 127.0, 550.0],\n",
       " [127.0, 550.0, 222.0, 513.0, 9.0, -102.31813133555558, 127.0, 551.0],\n",
       " [127.0, 551.0, 150.0, 542.0, 2.0, -29.154759474226502, 123.0, 553.0],\n",
       " [125.0, 551.0, 227.0, 470.0, 7.0, -131.82184947875675, 123.0, 551.0],\n",
       " [123.0, 551.0, 60.0, 559.0, 2.0, -65.49045732013177, 125.0, 551.0],\n",
       " [125.0, 551.0, 124.0, 479.0, 3.0, -48.093658625644196, 127.0, 527.0],\n",
       " [127.0, 527.0, 283.0, 410.0, 1.0, -186.03494295427404, 155.0, 545.0],\n",
       " [155.0, 545.0, 69.0, 557.0, 5.0, -103.24727599312246, 171.0, 541.0],\n",
       " [171.0, 541.0, 150.0, 542.0, 5.0, -21.02379604162864, 169.0, 533.0],\n",
       " [169.0, 533.0, 367.0, 254.0, 6.0, -347.5413644445795, 171.0, 541.0],\n",
       " [171.0, 541.0, 361.0, 321.0, 7.0, -292.56964982718216, 167.0, 540.0],\n",
       " [167.0, 540.0, 367.0, 254.0, 6.0, -346.88326566728466, 165.0, 536.0],\n",
       " [165.0, 536.0, 52.0, 559.0, 2.0, -112.29425630903836, 163.0, 542.0],\n",
       " [163.0, 542.0, 361.0, 321.0, 2.0, -294.8219801846531, 167.0, 543.0],\n",
       " [167.0, 543.0, 79.0, 536.0, 3.0, -100.00499987500625, 179.0, 535.0],\n",
       " [179.0, 535.0, 151.0, 529.0, 9.0, -25.632011235952593, 175.0, 538.0],\n",
       " [175.0, 538.0, 287.0, 342.0, 4.0, -228.44255295369118, 168.0, 537.0],\n",
       " [168.0, 537.0, 347.0, 366.0, 1.0, -239.71024175032656, 178.0, 536.0],\n",
       " [178.0, 536.0, 14.0, 531.0, 9.0, -163.11039206623224, 177.0, 525.0],\n",
       " [177.0, 525.0, 203.0, 495.0, 6.0, -54.405882034941776, 171.0, 539.0],\n",
       " [171.0, 539.0, 355.0, 302.0, 5.0, -302.97854709533476, 165.0, 538.0],\n",
       " [165.0, 538.0, 27.0, 543.0, 8.0, -137.23337786413333, 164.0, 535.0],\n",
       " [164.0, 535.0, 222.0, 513.0, 4.0, -71.17583859709698, 157.0, 542.0],\n",
       " [157.0, 542.0, 260.0, 417.0, 5.0, -157.1146078504478, 161.0, 539.0],\n",
       " [161.0, 539.0, 60.0, 559.0, 1.0, -108.50345616615168, 167.0, 541.0],\n",
       " [167.0, 541.0, 201.0, 520.0, 8.0, -32.7566787083184, 173.0, 537.0],\n",
       " [173.0, 537.0, 165.0, 527.0, 6.0, -17.08800749063506, 171.0, 543.0],\n",
       " [171.0, 543.0, 309.0, 398.0, 5.0, -205.06584308460538, 163.0, 542.0],\n",
       " [163.0, 542.0, 301.0, 325.0, 6.0, -260.1691757299469, 159.0, 543.0],\n",
       " [159.0, 543.0, 165.0, 527.0, 4.0, -16.97056274847714, 153.0, 539.0],\n",
       " [153.0, 539.0, 26.0, 542.0, 6.0, -133.00375934536586, 159.0, 543.0],\n",
       " [159.0, 543.0, 247.0, 481.0, 5.0, -112.05802068571441, 153.0, 542.0],\n",
       " [153.0, 542.0, 124.0, 479.0, 6.0, -68.70953354520753, 149.0, 543.0],\n",
       " [149.0, 543.0, 34.0, 545.0, 2.0, -109.01834707974616, 143.0, 543.0],\n",
       " [143.0, 543.0, 289.0, 372.0, 5.0, -224.84883811129646, 143.0, 543.0],\n",
       " [143.0, 543.0, 111.0, 500.0, 2.0, -51.73973328110612, 145.0, 539.0],\n",
       " [145.0, 539.0, 17.0, 544.0, 4.0, -140.05713120009278, 157.0, 540.0],\n",
       " [157.0, 540.0, 14.0, 537.0, 4.0, -155.0129026887762, 169.0, 535.0],\n",
       " [169.0, 535.0, 175.0, 531.0, 2.0, -16.1245154965971, 191.0, 529.0],\n",
       " [191.0, 529.0, 339.0, 308.0, 7.0, -242.42112119202815, 191.0, 500.0],\n",
       " [191.0, 500.0, 243.0, 455.0, 8.0, -78.10249675906654, 193.0, 515.0],\n",
       " [193.0, 515.0, 47.0, 495.0, 1.0, -151.85519418182574, 195.0, 529.0],\n",
       " [195.0, 529.0, 44.0, 540.0, 3.0, -163.6001222493431, 207.0, 526.0],\n",
       " [207.0, 526.0, 180.0, 512.0, 7.0, -25.495097567963924, 199.0, 495.0],\n",
       " [199.0, 495.0, 357.0, 289.0, 2.0, -267.0973605260823, 207.0, 510.0],\n",
       " [207.0, 510.0, 14.0, 531.0, 4.0, -198.97989848223364, 211.0, 503.0],\n",
       " [211.0, 503.0, 34.0, 545.0, 6.0, -183.3930205869351, 211.0, 497.0],\n",
       " [211.0, 497.0, 297.0, 417.0, 7.0, -120.96693763173474, 209.0, 500.0],\n",
       " [209.0, 500.0, 52.0, 559.0, 1.0, -167.69317219254933, 207.0, 495.0],\n",
       " [207.0, 495.0, 165.0, 527.0, 6.0, -64.8459713474939, 223.0, 498.0],\n",
       " [223.0, 498.0, 14.0, 538.0, 7.0, -214.5809870421888, 227.0, 512.0],\n",
       " [227.0, 512.0, 291.0, 337.0, 1.0, -183.29484444468153, 225.0, 508.0],\n",
       " [225.0, 508.0, 111.0, 500.0, 4.0, -128.09761902549164, 239.0, 495.0],\n",
       " [239.0, 495.0, 361.0, 321.0, 6.0, -210.304541082688, 249.0, 499.0],\n",
       " [249.0, 499.0, 203.0, 495.0, 4.0, -40.19950248448356, 243.0, 499.0],\n",
       " [243.0, 499.0, 243.0, 455.0, 5.0, -46.389654018972806, 249.0, 501.0],\n",
       " [249.0, 501.0, 289.0, 372.0, 7.0, -129.5414991421668, 255.0, 497.0],\n",
       " [255.0, 497.0, 34.0, 545.0, 8.0, -219.06391761310215, 249.0, 503.0],\n",
       " [249.0, 503.0, 367.0, 279.0, 1.0, -254.52701231892854, 239.0, 499.0],\n",
       " [239.0, 499.0, 367.0, 264.0, 7.0, -259.42243542145695, 255.0, 498.0],\n",
       " [255.0, 498.0, 10.0, 542.0, 5.0, -249.65776575143823, 255.0, 494.0],\n",
       " [255.0, 494.0, 287.0, 342.0, 7.0, -156.31058825300352, 255.0, 495.0],\n",
       " [255.0, 495.0, 127.0, 553.0, 1.0, -134.23859355639868, 249.0, 497.0],\n",
       " [249.0, 497.0, 367.0, 254.0, 9.0, -264.09278672466615, 259.0, 495.0],\n",
       " [259.0, 495.0, 261.0, 423.0, 9.0, -80.49844718999243, 225.0, 495.0],\n",
       " [225.0, 495.0, 14.0, 537.0, 9.0, -171.09354166653983, 177.0, 485.0],\n",
       " [177.0, 485.0, 260.0, 417.0, 7.0, -137.56816492197603, 183.0, 531.0],\n",
       " [183.0, 531.0, 275.0, 368.0, 6.0, -200.57168294652163, 177.0, 543.0],\n",
       " [177.0, 543.0, 271.0, 471.0, 5.0, -119.4026800369238, 175.0, 542.0],\n",
       " [175.0, 542.0, 114.0, 554.0, 9.0, -50.44799302251776, 153.0, 522.0],\n",
       " [153.0, 522.0, 243.0, 455.0, 5.0, -135.88230201170424, 143.0, 547.0],\n",
       " [143.0, 547.0, 127.0, 553.0, 7.0, -48.662100242385755, 119.0, 505.0],\n",
       " [119.0, 505.0, 180.0, 512.0, 7.0, -61.40032573203501, 127.0, 543.0],\n",
       " [127.0, 543.0, 107.0, 559.0, 3.0, -14.317821063276353, 120.0, 553.0],\n",
       " [120.0, 553.0, 289.0, 372.0, 2.0, -238.47222060441337, 127.0, 547.0],\n",
       " [127.0, 547.0, 301.0, 325.0, 4.0, -276.4416755845616, 139.0, 549.0],\n",
       " [139.0, 549.0, 367.0, 279.0, 6.0, -346.7333269243094, 147.0, 547.0],\n",
       " [147.0, 547.0, 367.0, 298.0, 2.0, -325.5042242429428, 155.0, 545.0],\n",
       " [155.0, 545.0, 259.0, 382.0, 5.0, -184.56435192094924, 167.0, 542.0],\n",
       " [167.0, 542.0, 287.0, 342.0, 7.0, -232.72515979154468, 168.0, 542.0],\n",
       " [168.0, 542.0, 227.0, 494.0, 2.0, -76.00657866263946, 163.0, 535.0],\n",
       " [163.0, 535.0, 14.0, 538.0, 7.0, -161.02794788483146, 175.0, 541.0],\n",
       " [175.0, 541.0, 52.0, 559.0, 2.0, -127.09838708654017, 177.0, 536.0],\n",
       " [177.0, 536.0, 44.0, 540.0, 3.0, -149.40548852033515, 193.0, 529.0],\n",
       " [193.0, 529.0, 52.0, 559.0, 8.0, -146.32156368765337, 195.0, 528.0],\n",
       " [195.0, 528.0, 227.0, 494.0, 9.0, -53.33854141237835, 181.0, 521.0],\n",
       " [181.0, 521.0, 44.0, 540.0, 4.0, -125.01599897613104, 169.0, 542.0],\n",
       " [169.0, 542.0, 127.0, 553.0, 8.0, -43.174066289845804, 169.0, 543.0],\n",
       " [169.0, 543.0, 69.0, 557.0, 4.0, -92.77930803794561, 161.0, 545.0],\n",
       " [161.0, 545.0, 355.0, 302.0, 4.0, -305.6550343115585, 167.0, 543.0],\n",
       " [167.0, 543.0, 165.0, 527.0, 4.0, -16.401219466856727, 175.0, 540.0],\n",
       " [175.0, 540.0, 111.0, 500.0, 6.0, -80.05623023850174, 183.0, 535.0],\n",
       " [183.0, 535.0, 97.0, 558.0, 2.0, -83.24061508662703, 177.0, 535.0],\n",
       " [177.0, 535.0, 227.0, 494.0, 3.0, -57.3149195236284, 185.0, 533.0],\n",
       " [185.0, 533.0, 367.0, 279.0, 3.0, -302.88776799336085, 196.0, 529.0],\n",
       " [196.0, 529.0, 367.0, 279.0, 2.0, -293.21152774063984, 209.0, 526.0],\n",
       " [209.0, 526.0, 289.0, 372.0, 7.0, -161.13658802394943, 223.0, 519.0],\n",
       " [223.0, 519.0, 247.0, 481.0, 5.0, -40.80441152620633, 223.0, 514.0],\n",
       " [223.0, 514.0, 34.0, 545.0, 2.0, -192.03385118254542, 223.0, 511.0],\n",
       " [223.0, 511.0, 259.0, 382.0, 6.0, -132.90974381135493, 227.0, 511.0],\n",
       " [227.0, 511.0, 222.0, 513.0, 9.0, -7.280109889280518, 215.0, 515.0],\n",
       " [215.0, 515.0, 145.0, 542.0, 3.0, -55.90169943749474, 195.0, 517.0],\n",
       " [195.0, 517.0, 59.0, 548.0, 6.0, -135.63554106501732, 193.0, 527.0],\n",
       " [193.0, 527.0, 260.0, 417.0, 3.0, -137.55726080436466, 191.0, 536.0],\n",
       " [211.0, 516.0, 302.0, 317.0, 6.0, -221.55134844996994, 211.0, 519.0],\n",
       " [211.0, 519.0, 147.0, 545.0, 9.0, -60.03332407921454, 199.0, 515.0],\n",
       " [199.0, 515.0, 87.0, 558.0, 8.0, -101.13357503816425, 179.0, 516.0],\n",
       " [179.0, 516.0, 252.0, 439.0, 5.0, -124.2014492669067, 177.0, 538.0],\n",
       " [177.0, 538.0, 367.0, 298.0, 2.0, -309.2507073556987, 177.0, 542.0],\n",
       " [177.0, 542.0, 69.0, 557.0, 9.0, -111.01801655587259, 179.0, 542.0],\n",
       " [179.0, 542.0, 339.0, 308.0, 9.0, -277.2435752186153, 139.0, 500.0],\n",
       " [139.0, 500.0, 175.0, 531.0, 8.0, -50.15974481593781, 129.0, 551.0],\n",
       " [129.0, 551.0, 87.0, 558.0, 7.0, -58.69412236331676, 101.0, 501.0],\n",
       " [101.0, 501.0, 34.0, 545.0, 2.0, -61.61168720299745, 94.0, 559.0],\n",
       " [94.0, 559.0, 275.0, 368.0, 3.0, -255.54842985234717, 103.0, 557.0],\n",
       " [103.0, 557.0, 10.0, 542.0, 7.0, -109.77249200050075, 119.0, 555.0],\n",
       " [119.0, 555.0, 97.0, 558.0, 6.0, -16.278820596099706, 113.0, 555.0],\n",
       " [113.0, 555.0, 222.0, 513.0, 4.0, -117.5457357797381, 113.0, 557.0],\n",
       " [113.0, 557.0, 96.0, 489.0, 7.0, -65.73431371817918, 111.0, 553.0],\n",
       " [111.0, 553.0, 355.0, 347.0, 7.0, -324.0061727807049, 97.0, 543.0],\n",
       " [97.0, 543.0, 339.0, 308.0, 1.0, -355.6754138255834, 87.0, 559.0],\n",
       " [87.0, 559.0, 259.0, 382.0, 2.0, -229.83689869122406, 99.0, 547.0],\n",
       " [99.0, 547.0, 247.0, 481.0, 2.0, -131.52946437965906, 131.0, 543.0],\n",
       " [131.0, 543.0, 307.0, 307.0, 2.0, -263.6436989575135, 145.0, 515.0],\n",
       " [145.0, 515.0, 59.0, 548.0, 7.0, -116.21101496846157, 175.0, 541.0],\n",
       " [175.0, 541.0, 297.0, 440.0, 1.0, -152.50245899656832, 181.0, 539.0],\n",
       " [181.0, 539.0, 135.0, 547.0, 6.0, -59.22837157984339, 193.0, 535.0],\n",
       " [193.0, 535.0, 357.0, 289.0, 5.0, -299.2607558635111, 191.0, 538.0],\n",
       " [191.0, 538.0, 97.0, 558.0, 1.0, -105.09519494249011, 191.0, 511.0],\n",
       " [191.0, 511.0, 305.0, 312.0, 3.0, -223.0896680709351, 217.0, 517.0],\n",
       " [217.0, 517.0, 260.0, 417.0, 6.0, -105.6882207249228, 223.0, 516.0],\n",
       " [223.0, 516.0, 34.0, 545.0, 1.0, -193.3416664870767, 225.0, 515.0],\n",
       " [225.0, 515.0, 27.0, 543.0, 6.0, -214.40149253211834, 239.0, 511.0],\n",
       " [239.0, 511.0, 287.0, 342.0, 9.0, -176.81911661356077, 235.0, 511.0],\n",
       " [235.0, 511.0, 305.0, 312.0, 7.0, -226.77080940897133, 217.0, 521.0],\n",
       " [217.0, 521.0, 135.0, 547.0, 4.0, -70.9365914038728, 201.0, 521.0],\n",
       " [201.0, 521.0, 97.0, 558.0, 3.0, -118.40608092492548, 211.0, 526.0],\n",
       " [211.0, 526.0, 139.0, 485.0, 8.0, -82.85529554590944, 211.0, 526.0],\n",
       " [211.0, 526.0, 261.0, 423.0, 4.0, -118.96217886370441, 207.0, 529.0],\n",
       " [207.0, 529.0, 295.0, 332.0, 2.0, -212.32286735064596, 211.0, 527.0],\n",
       " [211.0, 527.0, 301.0, 325.0, 9.0, -220.22942582679545, 211.0, 526.0],\n",
       " [211.0, 526.0, 124.0, 479.0, 1.0, -79.60527620704548, 195.0, 515.0],\n",
       " [195.0, 515.0, 260.0, 417.0, 1.0, -104.44615837837216, 207.0, 507.0],\n",
       " [207.0, 507.0, 227.0, 470.0, 1.0, -34.828149534535996, 249.0, 497.0],\n",
       " [249.0, 497.0, 217.0, 483.0, 5.0, -46.389654018972806, 263.0, 489.0],\n",
       " [263.0, 489.0, 79.0, 536.0, 2.0, -192.09372712298546, 265.0, 488.0],\n",
       " [265.0, 488.0, 355.0, 302.0, 4.0, -182.6608879864543, 281.0, 469.0],\n",
       " [281.0, 469.0, 305.0, 312.0, 6.0, -155.04837954651444, 287.0, 466.0],\n",
       " [287.0, 466.0, 297.0, 440.0, 9.0, -40.80441152620633, 273.0, 473.0],\n",
       " [273.0, 473.0, 287.0, 342.0, 8.0, -149.64290828502365, 259.0, 489.0],\n",
       " [259.0, 489.0, 243.0, 455.0, 4.0, -41.7612260356422, 255.0, 495.0],\n",
       " [255.0, 495.0, 124.0, 479.0, 4.0, -135.2368293032634, 259.0, 487.0],\n",
       " [259.0, 487.0, 361.0, 321.0, 8.0, -196.5400722499104, 259.0, 489.0],\n",
       " [259.0, 489.0, 361.0, 321.0, 3.0, -205.4555913086816, 255.0, 497.0],\n",
       " [255.0, 497.0, 14.0, 537.0, 1.0, -229.91520175925731, 233.0, 467.0],\n",
       " [233.0, 467.0, 337.0, 385.0, 4.0, -111.12605455067681, 255.0, 460.0],\n",
       " [255.0, 460.0, 361.0, 321.0, 2.0, -158.3161394173064, 291.0, 463.0],\n",
       " [291.0, 463.0, 301.0, 325.0, 8.0, -130.24592124131948, 293.0, 455.0],\n",
       " [293.0, 455.0, 87.0, 558.0, 8.0, -213.85976713725282, 281.0, 468.0],\n",
       " [281.0, 468.0, 52.0, 559.0, 1.0, -239.1359446005556, 277.0, 478.0],\n",
       " [277.0, 478.0, 17.0, 544.0, 2.0, -289.67568071897233, 291.0, 450.0],\n",
       " [291.0, 450.0, 165.0, 527.0, 1.0, -160.86018774078315, 291.0, 427.0],\n",
       " [291.0, 427.0, 295.0, 332.0, 9.0, -79.02531240052139, 293.0, 411.0],\n",
       " [293.0, 411.0, 261.0, 423.0, 8.0, -32.31098884280702, 291.0, 435.0],\n",
       " [291.0, 435.0, 150.0, 542.0, 3.0, -168.0773631397161, 295.0, 457.0],\n",
       " [295.0, 457.0, 135.0, 547.0, 2.0, -188.60540819393276, 291.0, 441.0],\n",
       " [291.0, 441.0, 227.0, 494.0, 1.0, -104.9952379872535, 295.0, 414.0],\n",
       " [295.0, 414.0, 252.0, 439.0, 5.0, -75.13321502504735, 319.0, 405.0],\n",
       " [319.0, 405.0, 203.0, 495.0, 9.0, -135.07405376311175, 297.0, 398.0],\n",
       " [297.0, 398.0, 34.0, 545.0, 5.0, -302.80356668969404, 307.0, 414.0],\n",
       " [307.0, 414.0, 107.0, 559.0, 2.0, -253.50345165302977, 317.0, 417.0],\n",
       " [317.0, 417.0, 97.0, 558.0, 8.0, -253.40284134160768, 299.0, 405.0],\n",
       " [299.0, 405.0, 291.0, 337.0, 6.0, -74.10802925459562, 295.0, 411.0],\n",
       " [295.0, 411.0, 288.0, 457.0, 9.0, -18.027756377319946, 289.0, 439.0],\n",
       " [289.0, 439.0, 367.0, 257.0, 6.0, -217.947241322298, 293.0, 462.0],\n",
       " [293.0, 462.0, 79.0, 559.0, 6.0, -221.96396103872357, 281.0, 467.0],\n",
       " [281.0, 467.0, 361.0, 321.0, 2.0, -171.7672844286711, 281.0, 473.0],\n",
       " [281.0, 473.0, 47.0, 495.0, 8.0, -241.19701490690136, 287.0, 471.0],\n",
       " [287.0, 471.0, 260.0, 417.0, 9.0, -64.93843238021688, 271.0, 481.0],\n",
       " [271.0, 481.0, 288.0, 457.0, 2.0, -48.60041152089147, 259.0, 496.0],\n",
       " [259.0, 496.0, 97.0, 558.0, 8.0, -177.92414113885727, 261.0, 489.0],\n",
       " [261.0, 489.0, 52.0, 559.0, 7.0, -208.4346420343797, 251.0, 497.0],\n",
       " [251.0, 497.0, 97.0, 558.0, 9.0, -149.57606760441325, 239.0, 511.0],\n",
       " [239.0, 511.0, 201.0, 520.0, 8.0, -7.810249675906654, 207.0, 515.0],\n",
       " [207.0, 515.0, 271.0, 471.0, 5.0, -85.70297544426332, 207.0, 528.0],\n",
       " [207.0, 528.0, 10.0, 542.0, 8.0, -188.52055590836773, 198.0, 528.0],\n",
       " [198.0, 528.0, 14.0, 537.0, 8.0, -163.11039206623224, 177.0, 543.0],\n",
       " [177.0, 543.0, 309.0, 398.0, 7.0, -216.44860821913363, 152.0, 547.0],\n",
       " [152.0, 547.0, 247.0, 481.0, 7.0, -125.39936203984452, 138.0, 543.0],\n",
       " [138.0, 543.0, 287.0, 342.0, 7.0, -260.0480724789169, 135.0, 553.0],\n",
       " [135.0, 553.0, 302.0, 317.0, 9.0, -296.2043213729334, 123.0, 553.0],\n",
       " [123.0, 553.0, 175.0, 531.0, 4.0, -59.09314681077663, 121.0, 555.0],\n",
       " [121.0, 555.0, 357.0, 289.0, 6.0, -352.61877431583247, 121.0, 551.0],\n",
       " [121.0, 551.0, 291.0, 337.0, 9.0, -277.68327281274975, 119.0, 555.0],\n",
       " [119.0, 555.0, 287.0, 342.0, 5.0, -274.5541840875859, 115.0, 556.0],\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['sparse_categorical_accuracy']\n",
    "# val_acc = history.history['val_sparse_categorical_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一种新的训练方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 12ms/step - loss: 29270.6495 - mae: 144.8190\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 29879.6174 - mae: 144.9623\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27290.0665 - mae: 138.7931\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27332.8110 - mae: 139.4525\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 28928.4044 - mae: 143.1573\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 29145.1592 - mae: 143.4204\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28542.3134 - mae: 142.6366\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 28758.7273 - mae: 143.0967\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 29779.0160 - mae: 145.4079\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29550.6360 - mae: 145.1963\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29222.3351 - mae: 145.4293\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28728.3991 - mae: 144.6976\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 27912.8514 - mae: 141.5535\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29174.5408 - mae: 146.9657\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 26597.2950 - mae: 137.7018\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29565.4528 - mae: 145.5391\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 27884.1587 - mae: 141.2524\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 28076.8033 - mae: 142.1074\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27012.9492 - mae: 139.5384\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27909.2576 - mae: 143.9762\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27411.7241 - mae: 140.9213\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 29004.3339 - mae: 146.2168\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 26843.0838 - mae: 139.7489\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 27635.4220 - mae: 141.9761\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 28848.2293 - mae: 146.4383\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26395.6461 - mae: 138.3175\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27433.9871 - mae: 141.1958\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26206.3426 - mae: 138.5643\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26376.9998 - mae: 138.9606\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25353.2518 - mae: 134.7121\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24594.4634 - mae: 134.6306\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25931.9149 - mae: 138.0551\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27490.4409 - mae: 142.3732\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27515.9081 - mae: 142.7951\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26556.1834 - mae: 140.4140\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25934.9130 - mae: 138.6812\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25795.4332 - mae: 138.0832\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 25260.4989 - mae: 137.1562\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25675.8881 - mae: 136.9044\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 25393.9692 - mae: 138.2055\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 25911.4858 - mae: 139.5474\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 25646.6096 - mae: 138.6134\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25135.6793 - mae: 136.6295\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 27280.2237 - mae: 143.2494\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 24886.9554 - mae: 136.9252\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25138.8803 - mae: 136.5385\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24677.4350 - mae: 136.5464\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 23817.9446 - mae: 133.4294\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 24379.6567 - mae: 135.8905\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 24402.6080 - mae: 134.8990\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 23979.5639 - mae: 134.5763\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 22937.9777 - mae: 131.7000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 23648.7873 - mae: 133.2059\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24709.3878 - mae: 137.3010\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25195.8265 - mae: 137.4546\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 24053.0679 - mae: 135.7783\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 23364.8899 - mae: 133.0022\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 23011.5771 - mae: 131.3437\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 23776.2047 - mae: 134.5647\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23841.9762 - mae: 135.5041\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 22373.5471 - mae: 129.9252\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 22114.4179 - mae: 130.0041\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 22057.2652 - mae: 128.7189\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 22665.9704 - mae: 130.5012\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 22725.4203 - mae: 130.7259\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 22450.8442 - mae: 130.8177\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 21313.2611 - mae: 127.6940\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 21248.0727 - mae: 127.4873\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 21350.7429 - mae: 127.7450\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 21115.2051 - mae: 126.9309\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 22632.2883 - mae: 132.1030\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 21821.4143 - mae: 129.7839\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 20376.6221 - mae: 124.4183\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 21710.1312 - mae: 130.2203\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 20983.4660 - mae: 128.3179\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 19951.7755 - mae: 124.9831\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20858.5568 - mae: 127.7145\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 19996.9673 - mae: 125.2760\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20608.1027 - mae: 126.1512\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 20226.1290 - mae: 124.6150\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 20466.3663 - mae: 125.9441\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20046.1006 - mae: 124.5280\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20173.9985 - mae: 124.5480\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20167.4715 - mae: 125.1550\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 19902.6790 - mae: 125.3710\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 18561.7621 - mae: 120.1675\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 18629.4214 - mae: 119.6985\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 19382.3428 - mae: 123.5304\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 18942.2069 - mae: 122.4630\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20948.5680 - mae: 128.5473\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19930.2192 - mae: 125.7435\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18329.6210 - mae: 120.3497\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 19668.1033 - mae: 125.1474\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18718.4505 - mae: 121.7141\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19234.2084 - mae: 123.3451\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 18399.6753 - mae: 119.6329\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18461.3728 - mae: 120.8422\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 18547.7204 - mae: 121.1260\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17457.8474 - mae: 117.3008\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 17330.2069 - mae: 116.8738\n",
      "0\n",
      "___________target network update___________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 11ms/step - loss: 42825.2516 - mae: 169.8996\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 41322.1912 - mae: 165.5293\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 41661.3389 - mae: 164.9286\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 44898.1094 - mae: 172.1950\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 41218.2764 - mae: 164.5220\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 42711.7822 - mae: 167.7417\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 40309.6039 - mae: 163.0184\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 40406.4800 - mae: 165.8390\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 42021.9830 - mae: 167.6313\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 40686.4602 - mae: 164.5143\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40639.9301 - mae: 165.1747\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 39822.8637 - mae: 163.4263\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 39293.6045 - mae: 160.9073\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 42501.9490 - mae: 167.6143\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 41565.9979 - mae: 167.3613\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 39982.3447 - mae: 163.9171\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 40236.7146 - mae: 163.3289\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40054.8991 - mae: 161.8148\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40282.7213 - mae: 163.9624\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 41098.1696 - mae: 165.4828\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 38847.8543 - mae: 160.8049\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 38523.6036 - mae: 160.0717\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 40506.2424 - mae: 164.3323\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 41445.6363 - mae: 167.0706\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 40880.9529 - mae: 165.6950\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 42038.7004 - mae: 167.5361\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 39269.0889 - mae: 160.9470\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 39600.8274 - mae: 163.2221\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 37674.5540 - mae: 158.5170\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 38433.3389 - mae: 160.2854\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 40888.2941 - mae: 166.6186\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40145.4991 - mae: 163.2101\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 35738.3799 - mae: 155.6016\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 36882.2213 - mae: 157.3733\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 38894.2702 - mae: 160.9755\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 38613.3658 - mae: 160.0177\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 37325.3463 - mae: 158.2163\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 40456.2335 - mae: 164.6769\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 39998.7649 - mae: 165.3659\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 37017.3447 - mae: 158.0420\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 37026.2270 - mae: 157.8457\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 36711.7231 - mae: 157.5015\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 36191.4984 - mae: 154.9755\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 37446.9003 - mae: 160.3027\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 36023.2870 - mae: 157.4460\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 36867.4936 - mae: 158.4578\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 38330.5813 - mae: 161.5165\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 36138.3176 - mae: 157.1852\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 35187.2846 - mae: 154.2753\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 37620.8842 - mae: 160.0329\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 35962.7006 - mae: 158.2935\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 37549.1438 - mae: 160.5440\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35738.4455 - mae: 155.9455\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 38528.2167 - mae: 163.8209\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34858.3865 - mae: 155.1341\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34604.7138 - mae: 153.0421\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 33080.3079 - mae: 150.6575\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 33371.5278 - mae: 151.4372\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 34693.2847 - mae: 155.6218\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 35025.4596 - mae: 155.9977\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 35913.3660 - mae: 157.4769\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 33867.0865 - mae: 152.4832\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 35548.6916 - mae: 157.9998\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 35427.1427 - mae: 156.7698\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 32701.2585 - mae: 150.9583\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 35103.3711 - mae: 157.4990\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 33686.4756 - mae: 150.6953\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 33542.5749 - mae: 152.7899\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 34440.3116 - mae: 155.1163\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 31883.5928 - mae: 147.8040\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 32677.1877 - mae: 150.9753\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 31805.8305 - mae: 148.8426\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 32155.9876 - mae: 148.9645\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 33842.2556 - mae: 154.2027\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 32057.3130 - mae: 148.4708\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 34097.9299 - mae: 155.4448\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30932.4409 - mae: 147.7014\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 33746.2348 - mae: 154.3770\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 33681.8795 - mae: 153.1776\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 32300.1106 - mae: 150.9631\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 31733.5838 - mae: 150.9960\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28256.5411 - mae: 139.4838\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30575.0338 - mae: 145.9104\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30494.8621 - mae: 145.8417\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30636.7506 - mae: 146.8854\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30566.6033 - mae: 147.0352\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29223.8216 - mae: 143.8852\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29804.0886 - mae: 144.3963\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 30947.1181 - mae: 149.8264\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 31783.4193 - mae: 151.0427\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30833.3782 - mae: 148.5489\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29464.0645 - mae: 144.2373\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28861.8338 - mae: 143.4192\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27276.3408 - mae: 138.5676\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28217.2632 - mae: 142.2166\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 28243.8446 - mae: 141.0432\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28981.2521 - mae: 141.8486\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27435.7037 - mae: 140.2876\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29663.9968 - mae: 145.1412\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28193.8397 - mae: 141.6819\n",
      "1\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28120.4473 - mae: 141.4607\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 28128.2637 - mae: 141.0539\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27760.4297 - mae: 140.6312\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27532.7695 - mae: 140.2161\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27379.2715 - mae: 139.7928\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27197.9004 - mae: 139.3812\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26992.3301 - mae: 138.9439\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26885.1152 - mae: 138.5182\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 26567.9883 - mae: 138.0870\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 26498.0469 - mae: 137.6547\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26303.2773 - mae: 137.2206\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25961.3086 - mae: 136.7821\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25957.1562 - mae: 136.3423\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 25581.5430 - mae: 135.9074\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25544.1035 - mae: 135.4576\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25282.4062 - mae: 135.0619\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25099.0605 - mae: 134.5638\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 24715.0898 - mae: 134.1138\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 24733.4355 - mae: 133.6575\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24509.8770 - mae: 133.2073\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24333.1855 - mae: 132.7573\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23984.2285 - mae: 132.2926\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23988.5938 - mae: 131.8281\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 23668.1719 - mae: 131.3658\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23502.7266 - mae: 130.9124\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 23496.5801 - mae: 130.4306\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23179.9258 - mae: 129.9625\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 23063.9961 - mae: 129.4965\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22811.1113 - mae: 129.0363\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 22602.0176 - mae: 128.5654\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22461.8008 - mae: 128.0842\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22288.4082 - mae: 127.6137\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 22130.9238 - mae: 127.1314\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 21955.7383 - mae: 126.6414\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 21544.3555 - mae: 126.1654\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 21561.4102 - mae: 125.6924\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 21363.4492 - mae: 125.2032\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 21141.7109 - mae: 124.7334\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 21080.5781 - mae: 124.2800\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20619.1367 - mae: 123.7607\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20437.1211 - mae: 123.2732\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20351.4922 - mae: 122.7615\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20305.4141 - mae: 122.2763\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 20038.9414 - mae: 121.7599\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 19865.6055 - mae: 121.2628\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19571.9453 - mae: 120.7896\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19483.7051 - mae: 120.2645\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19310.7734 - mae: 119.7574\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18948.0957 - mae: 119.2789\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18868.9785 - mae: 118.7489\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18708.3594 - mae: 118.2457\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18568.1602 - mae: 117.7434\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18335.9609 - mae: 117.2265\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18173.4824 - mae: 116.7206\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 18084.3457 - mae: 116.2306\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 17916.1191 - mae: 115.7109\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 17691.6270 - mae: 115.1882\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 17567.3711 - mae: 114.6926\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 17312.0176 - mae: 114.1801\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 17217.6426 - mae: 113.6654\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16799.1660 - mae: 113.1421\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 16789.2520 - mae: 112.6054\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 16693.7383 - mae: 112.1069\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 16408.6484 - mae: 111.5582\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 16260.2363 - mae: 111.0375\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 16162.3154 - mae: 110.5346\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 16015.7910 - mae: 110.0142\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15661.8799 - mae: 109.4856\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 15712.6934 - mae: 108.9972\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 15424.5410 - mae: 108.4485\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 15230.1191 - mae: 107.8939\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 15264.0078 - mae: 107.3769\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 15076.2695 - mae: 106.8693\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14659.7529 - mae: 106.3204\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14659.4189 - mae: 105.7912\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 14508.3535 - mae: 105.2710\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 14153.2979 - mae: 104.7169\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 14137.2002 - mae: 104.1645\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13830.6992 - mae: 103.6372\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13794.8584 - mae: 103.1175\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 13719.6436 - mae: 102.5914\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 13385.8369 - mae: 102.0507\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13452.2314 - mae: 101.4911\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 13152.4453 - mae: 100.9708\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12979.7773 - mae: 100.4481\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 13045.3789 - mae: 99.8932\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 12665.2178 - mae: 99.33 - 0s 11ms/step - loss: 12665.2178 - mae: 99.3342\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 12903.0029 - mae: 98.8966\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12388.8408 - mae: 98.2971\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12485.4043 - mae: 97.7794\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 12285.0068 - mae: 97.2026\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 12050.8740 - mae: 96.6723\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 11707.9619 - mae: 96.1337\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 11793.9873 - mae: 95.6484\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11938.9385 - mae: 95.1848\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 11434.6562 - mae: 94.5051\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11471.7100 - mae: 94.1119\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11392.6934 - mae: 93.5262\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 10890.5420 - mae: 92.8676\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 10770.8018 - mae: 92.3844\n",
      "2\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10687.8291 - mae: 92.4846\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 10642.9707 - mae: 91.9623\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10550.7793 - mae: 91.5880\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10154.0791 - mae: 90.8286\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10193.4512 - mae: 90.2948\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 10170.5283 - mae: 89.7592\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9879.8760 - mae: 89.1968\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9787.0195 - mae: 88.6977\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9845.0996 - mae: 88.1166\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9443.6680 - mae: 87.5591\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9576.0498 - mae: 87.0146\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9508.0459 - mae: 86.4624\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9268.3389 - mae: 86.0984\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9341.4883 - mae: 85.4348\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9034.2832 - mae: 84.9503\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8866.1621 - mae: 84.2862\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8766.5107 - mae: 83.7688\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8703.9863 - mae: 83.1989\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8537.7998 - mae: 82.6817\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8622.2666 - mae: 82.2644\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 8210.3926 - mae: 81.5693\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8079.4937 - mae: 81.0625\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8004.3218 - mae: 80.4821\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8430.6416 - mae: 80.4408\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7749.4268 - mae: 79.8968\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7944.6108 - mae: 79.0880\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8157.9707 - mae: 78.6957\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 7574.2251 - mae: 77.7795\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7762.2944 - mae: 77.4305\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7474.5161 - mae: 76.7142\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7149.3267 - mae: 76.1644\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7149.2793 - mae: 75.6032\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 7229.0605 - mae: 75.3577\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6937.4038 - mae: 74.5742\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6781.3516 - mae: 74.0899\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6662.2764 - mae: 73.4682\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6627.6138 - mae: 72.9917\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6540.6465 - mae: 72.4141\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6541.5366 - mae: 71.9058\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6497.9956 - mae: 71.3596\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 6282.6470 - mae: 70.8754\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 6623.4751 - mae: 70.5818\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6036.8223 - mae: 69.9886\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6170.3979 - mae: 69.3702\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6339.1094 - mae: 70.1086\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6012.5254 - mae: 68.6503\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 5820.6992 - mae: 67.8155\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 6012.7368 - mae: 67.4189\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5713.7974 - mae: 66.8662\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5890.4824 - mae: 67.6793\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5456.4722 - mae: 65.5870\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5506.4531 - mae: 65.0888\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5404.8506 - mae: 65.1070\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5210.5278 - mae: 64.0926\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5101.4448 - mae: 63.4628\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5378.3306 - mae: 63.2915\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5178.4204 - mae: 63.2326\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4661.7827 - mae: 61.8959\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4709.5732 - mae: 61.5197\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4734.9849 - mae: 60.9720\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4877.8818 - mae: 61.7164\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4871.7500 - mae: 60.7130\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4695.7227 - mae: 59.9752\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4707.9692 - mae: 59.1556\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5035.4351 - mae: 59.6162\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4613.7070 - mae: 59.3862\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4494.1348 - mae: 58.0410\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4117.6787 - mae: 57.3666\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4382.1230 - mae: 57.3484\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4215.6733 - mae: 56.8576\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4005.1912 - mae: 55.4218\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4018.1858 - mae: 55.2747\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3874.6729 - mae: 54.6228\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4063.5327 - mae: 55.3900\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3901.9854 - mae: 54.0265\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4289.7578 - mae: 55.4731\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3836.8740 - mae: 53.3105\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3863.8481 - mae: 53.9726\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3544.6125 - mae: 51.8162\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3487.2832 - mae: 51.3169\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3691.0894 - mae: 51.3844\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3256.4512 - mae: 50.3302\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3371.4707 - mae: 50.4169\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3640.6343 - mae: 50.4811\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3602.2087 - mae: 51.7659\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3150.6494 - mae: 48.5983\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3310.8818 - mae: 50.1114\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3070.5229 - mae: 47.6442\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3110.4954 - mae: 47.5227\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3182.1628 - mae: 48.3825\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3172.0964 - mae: 48.5693\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3370.3862 - mae: 49.7138\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3145.6814 - mae: 46.9773\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3092.6194 - mae: 46.5172\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2852.3337 - mae: 45.4770\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2858.8357 - mae: 45.5658\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2691.2092 - mae: 44.0847\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3191.0454 - mae: 46.5466\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3050.4331 - mae: 46.2180\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2993.2002 - mae: 45.2470\n",
      "3\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2916.9875 - mae: 44.9550\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2559.0818 - mae: 43.3500\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 2607.9343 - mae: 43.1550\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2753.4077 - mae: 43.5699\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2686.0715 - mae: 43.2785\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2403.0972 - mae: 41.2732\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2720.1599 - mae: 44.0654\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2516.8813 - mae: 43.1219\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2425.8679 - mae: 41.3528\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2431.7700 - mae: 41.3728\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2218.3521 - mae: 40.6777\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2647.8667 - mae: 42.0509\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2430.3477 - mae: 41.9644\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2125.7844 - mae: 38.7669\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2303.3149 - mae: 39.3416\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 2117.6904 - mae: 38.9824\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2024.4025 - mae: 37.4814\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2178.9685 - mae: 39.1125\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2136.0483 - mae: 37.8200\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2218.0356 - mae: 39.2039\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1901.3121 - mae: 35.5496\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2210.6973 - mae: 38.5390\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 2008.1748 - mae: 37.0562\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1904.8555 - mae: 35.1333\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2038.5725 - mae: 37.2482\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1722.3649 - mae: 34.1947\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1811.4315 - mae: 35.4460\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1785.8436 - mae: 34.1728\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1952.5674 - mae: 35.7858\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1989.1573 - mae: 35.6532\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1928.3632 - mae: 36.4633\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1555.5858 - mae: 32.5364\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1636.0236 - mae: 32.2839\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1500.6030 - mae: 31.2754\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1335.5210 - mae: 29.9726\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1791.0602 - mae: 34.1881\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1761.3474 - mae: 33.6601\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1714.3976 - mae: 34.1170\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1432.8738 - mae: 31.1861\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1970.2463 - mae: 33.9324\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1465.9763 - mae: 29.2679\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1381.3521 - mae: 29.7471\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1493.4550 - mae: 31.3275\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1548.8895 - mae: 32.5297\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1482.5394 - mae: 30.6625\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1481.5309 - mae: 30.9479\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1412.8373 - mae: 29.7725\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1370.8671 - mae: 29.4672\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1593.9783 - mae: 31.4758\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1717.5824 - mae: 32.4213\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1461.8630 - mae: 30.5314\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1137.5781 - mae: 27.3611\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1591.7878 - mae: 31.6067\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1293.6851 - mae: 28.8730\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 1121.8345 - mae: 27.1785\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1229.8375 - mae: 27.4225\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1182.8746 - mae: 27.9162\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1301.0211 - mae: 29.2794\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1194.3319 - mae: 27.4853\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1352.6572 - mae: 27.9657\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1191.1760 - mae: 26.7039\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1448.2977 - mae: 30.0102\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1227.2869 - mae: 27.5835\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 968.4747 - mae: 25.0164\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1074.8073 - mae: 25.3017\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1086.8242 - mae: 26.5093\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1178.2722 - mae: 26.0776\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1215.1530 - mae: 27.2797\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1186.9540 - mae: 27.8848\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1307.3859 - mae: 27.3608\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1246.4592 - mae: 28.6836\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 899.3636 - mae: 24.0717\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1281.0819 - mae: 28.7959\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 1131.6637 - mae: 27.2419\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 917.5311 - mae: 23.3236\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1311.2555 - mae: 28.2252\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1207.9768 - mae: 27.5622\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1209.6550 - mae: 27.2156\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1536.7305 - mae: 30.5175\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1163.6859 - mae: 27.1300\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 1185.1602 - mae: 27.5646\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 978.8908 - mae: 24.7857\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1022.9169 - mae: 24.7665\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 1053.6047 - mae: 25.7162\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1120.0768 - mae: 27.0206\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 937.6838 - mae: 24.1591\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1028.0201 - mae: 25.4024\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1127.7198 - mae: 26.3485\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1021.8114 - mae: 25.2110\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 966.4098 - mae: 24.7109\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1315.8590 - mae: 29.5956\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 906.5693 - mae: 23.6967\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 975.0121 - mae: 24.8660\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1323.4580 - mae: 28.2092\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1168.0388 - mae: 27.2316\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 918.8248 - mae: 24.3658\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1028.9341 - mae: 25.5183\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 870.8965 - mae: 23.1180\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 1253.8112 - mae: 27.9412\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 943.1195 - mae: 24.1480\n",
      "4\n",
      "___________target network update___________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 11ms/step - loss: 132180.6912 - mae: 302.0592\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 133274.0184 - mae: 303.2842\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 138691.7284 - mae: 307.6598\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 129606.6241 - mae: 298.5804\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 137882.7270 - mae: 309.1343\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 133749.4963 - mae: 306.6540\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 128425.8658 - mae: 294.9328\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 138932.3254 - mae: 311.9956\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 130138.8906 - mae: 300.6731\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 129991.4761 - mae: 298.3729\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 125060.8235 - mae: 293.0796\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 136798.7472 - mae: 306.2282\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 135429.8842 - mae: 305.4997\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 130135.7698 - mae: 299.3816\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 134941.9871 - mae: 307.8308\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 131681.5211 - mae: 302.2188\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 128903.1999 - mae: 300.2093\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 129876.7895 - mae: 301.0243\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 134696.3189 - mae: 307.8312\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 130332.6420 - mae: 300.0084\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 134088.9766 - mae: 305.1050\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 133072.4655 - mae: 305.6435\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 130286.8883 - mae: 301.3763\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 135303.1062 - mae: 306.7709\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 131763.4260 - mae: 302.7440\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 133767.6043 - mae: 303.5163\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 129023.8649 - mae: 300.9421\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 136169.5005 - mae: 313.0859\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 139384.3906 - mae: 315.8812\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 127255.3699 - mae: 299.9457\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 128704.9168 - mae: 301.0856\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 130228.2155 - mae: 299.4229\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 133279.6907 - mae: 307.5152\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 131816.5280 - mae: 305.8282\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 134340.8801 - mae: 305.5678\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 129064.5767 - mae: 300.9146\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 129820.9219 - mae: 301.3380\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 128868.0000 - mae: 299.9481\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 135315.8608 - mae: 310.9711\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 127979.5960 - mae: 299.4738\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 131049.4586 - mae: 304.5034\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 123284.5083 - mae: 294.2322\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 124886.6392 - mae: 297.0266\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 127550.8768 - mae: 298.4567\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 122894.3847 - mae: 293.9062\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 129522.5869 - mae: 303.5167\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 123414.5859 - mae: 294.9094\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 130378.1710 - mae: 303.5005\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 125813.8925 - mae: 298.0603\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 134415.8038 - mae: 307.3302\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 125790.5326 - mae: 297.7429\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 125413.6613 - mae: 298.2591\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 131282.9453 - mae: 304.6576\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 124341.9223 - mae: 296.7163\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 123169.9848 - mae: 297.0418\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 121837.0340 - mae: 293.0219\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 128199.6029 - mae: 301.6258\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 127938.7426 - mae: 299.1994\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 127017.8162 - mae: 299.9648\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 125625.3851 - mae: 296.9753\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 125849.4596 - mae: 297.1968\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 126437.9573 - mae: 297.3901\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 118021.5294 - mae: 287.3389\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 124855.7289 - mae: 299.2635\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 121522.7100 - mae: 294.2541\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 124673.9214 - mae: 297.6294\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 124462.2629 - mae: 297.2707\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 116831.3925 - mae: 288.3566\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 122523.1898 - mae: 294.2809\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 121998.6659 - mae: 294.7126\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 116418.3070 - mae: 286.3044\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 122843.0859 - mae: 296.5742\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 125372.2835 - mae: 298.3757\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 124323.9168 - mae: 297.6870\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 126874.0501 - mae: 300.2585\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 121103.5506 - mae: 294.7223\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 123055.3249 - mae: 298.1855\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 109923.0188 - mae: 279.0452\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 115933.8208 - mae: 288.6333\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 121595.1016 - mae: 294.5017\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 119841.6926 - mae: 292.7981\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 117200.9531 - mae: 289.7863\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 117748.7918 - mae: 289.4295\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 109887.9949 - mae: 278.9859\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 116511.2950 - mae: 290.6695\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 118881.8856 - mae: 290.9364\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 112468.4145 - mae: 283.2326\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 113546.9522 - mae: 285.0062\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 111202.3148 - mae: 283.0465\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 111055.3102 - mae: 282.7521\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 111762.7399 - mae: 281.8785\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 111436.6489 - mae: 283.2777\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 115934.8346 - mae: 290.0573\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 116209.1806 - mae: 288.9848\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 113314.7817 - mae: 285.8601\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 110180.4412 - mae: 282.4820\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 110291.0726 - mae: 278.6993\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 111051.2826 - mae: 282.0217\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 110008.0041 - mae: 280.1533\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 113810.5639 - mae: 286.8364\n",
      "5\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 101184.2188 - mae: 267.5682\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 100889.2344 - mae: 267.1624\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 99990.4922 - mae: 266.7261\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 99589.7344 - mae: 266.2999\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 99110.6172 - mae: 265.8699\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 98800.6875 - mae: 265.4371\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 98391.1719 - mae: 265.0003\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 98087.3594 - mae: 264.5615\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 97593.0703 - mae: 264.1207\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 97196.9453 - mae: 263.6770\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 96776.0156 - mae: 263.2295\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 96489.9453 - mae: 262.7729\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 95911.6172 - mae: 262.3205\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 95682.1797 - mae: 261.8645\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 95106.0625 - mae: 261.4048\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 94659.0469 - mae: 260.9431\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 94207.9297 - mae: 260.4772\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 93959.2891 - mae: 260.0067\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 93528.9922 - mae: 259.5349\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 93172.1328 - mae: 259.0569\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 92622.6406 - mae: 258.5807\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 92269.6797 - mae: 258.1056\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 92037.2734 - mae: 257.6242\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 91611.9453 - mae: 257.1358\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 91240.9297 - mae: 256.6499\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 90697.6641 - mae: 256.1613\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 90298.1484 - mae: 255.6665\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 89878.7656 - mae: 255.1726\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 89742.5312 - mae: 254.6742\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 89037.0781 - mae: 254.1764\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 88682.1328 - mae: 253.6719\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 88608.1875 - mae: 253.1649\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 87674.5078 - mae: 252.6604\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 87701.3750 - mae: 252.1545\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 87053.3047 - mae: 251.6431\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 86550.8281 - mae: 251.1307\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 86455.9844 - mae: 250.6100\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 85863.5078 - mae: 250.0900\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 85442.1328 - mae: 249.5733\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 84912.4922 - mae: 249.0552\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 84632.4219 - mae: 248.5259\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 84164.2109 - mae: 247.9957\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 83823.4531 - mae: 247.4676\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 13ms/step - loss: 83414.5547 - mae: 246.9433\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 82947.0312 - mae: 246.3910\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 82490.0859 - mae: 245.8548\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 82368.4922 - mae: 245.3206\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 81734.7891 - mae: 244.7837\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 81018.0703 - mae: 244.2309\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 80760.8203 - mae: 243.6931\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 80200.7266 - mae: 243.1270\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 80143.8203 - mae: 242.5697\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 79686.1406 - mae: 242.0202\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 79063.3359 - mae: 241.4722\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 79009.2812 - mae: 240.9239\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 78486.1484 - mae: 240.3679\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 77703.1797 - mae: 239.7937\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 77299.1875 - mae: 239.2281\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 77216.6875 - mae: 238.6653\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 76796.5078 - mae: 238.0939\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 76320.8672 - mae: 237.5210\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 76170.4922 - mae: 236.9648\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 75644.9453 - mae: 236.4020\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 75069.6484 - mae: 235.8144\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 74594.2969 - mae: 235.2334\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 74154.1406 - mae: 234.6497\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 73937.6016 - mae: 234.0676\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 73221.4219 - mae: 233.5051\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 73110.2500 - mae: 232.8987\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 72387.8672 - mae: 232.3177\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 72116.7422 - mae: 231.7306\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 71353.9062 - mae: 231.1432\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 71237.9531 - mae: 230.5636\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 70558.8047 - mae: 229.9610\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 70350.0547 - mae: 229.3801\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 69960.7344 - mae: 228.7631\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 69702.7891 - mae: 228.1629\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 69133.8672 - mae: 227.5604\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 68325.1016 - mae: 226.9509\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 68656.7422 - mae: 226.3388\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 67693.3438 - mae: 225.7297\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 67598.5156 - mae: 225.1325\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 67031.5312 - mae: 224.5183\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 66540.0781 - mae: 223.9074\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 66136.9219 - mae: 223.2938\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 65602.9844 - mae: 222.6792\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 65162.3672 - mae: 222.0683\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 64831.7383 - mae: 221.4412\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 64575.0312 - mae: 220.8318\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 63883.3867 - mae: 220.2015\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 63445.8477 - mae: 219.5828\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 63413.7578 - mae: 218.9562\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 62903.0859 - mae: 218.3617\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 62409.2383 - mae: 217.6951\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 62043.3203 - mae: 217.0716\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 61770.0156 - mae: 216.4429\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 61610.4453 - mae: 215.8108\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 60938.9102 - mae: 215.1670\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 60218.4453 - mae: 214.5335\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 60267.8555 - mae: 213.8994\n",
      "6\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 57240.7461 - mae: 210.8788\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 57196.2109 - mae: 210.2480\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 56656.4102 - mae: 209.7025\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 56194.8086 - mae: 208.9894\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 55695.6562 - mae: 208.3588\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 55208.5000 - mae: 207.7197\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 55136.1289 - mae: 207.1029\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 54728.1680 - mae: 206.4471\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 54157.3398 - mae: 205.8070\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 53726.6211 - mae: 205.1607\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 53619.5781 - mae: 204.5836\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 53076.5938 - mae: 203.8764\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 52897.8477 - mae: 203.2241\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 52316.2109 - mae: 202.5799\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 52711.3047 - mae: 201.9901\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 51262.9609 - mae: 201.2892\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 51215.9727 - mae: 200.6386\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 50660.7266 - mae: 199.9850\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 51000.9219 - mae: 199.3535\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 49982.9688 - mae: 198.6825\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 49995.5469 - mae: 198.0615\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 49733.4141 - mae: 197.3761\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 49195.5547 - mae: 196.7189\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 48794.9688 - mae: 196.0549\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 48323.6445 - mae: 195.4015\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 47914.6953 - mae: 194.7569\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 48111.0352 - mae: 194.0772\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 47485.7930 - mae: 193.4133\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 47404.0273 - mae: 192.7457\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 46850.0195 - mae: 192.0866\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 46714.3125 - mae: 191.4384\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 45904.6562 - mae: 190.7522\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 45728.6758 - mae: 190.0876\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 45004.5586 - mae: 189.4637\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 44846.2969 - mae: 188.7495\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 44867.0039 - mae: 188.0779\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 44107.0664 - mae: 187.4132\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 44564.7266 - mae: 186.7585\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 43641.9922 - mae: 186.0657\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 43108.3242 - mae: 185.3880\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 42932.9531 - mae: 184.7080\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 42324.7109 - mae: 184.0329\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 42478.7422 - mae: 183.3606\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 42143.5977 - mae: 182.6855\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 41659.5586 - mae: 181.9838\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40876.0938 - mae: 181.3028\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 40822.9492 - mae: 180.6184\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 40907.8906 - mae: 179.9478\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40610.8828 - mae: 179.2526\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 40268.4141 - mae: 178.5901\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 39421.0977 - mae: 177.8951\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 39288.1133 - mae: 177.3652\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 38669.1953 - mae: 176.5186\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 38396.0312 - mae: 175.8508\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 38146.4219 - mae: 175.1383\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 37552.7930 - mae: 174.4926\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 37623.3789 - mae: 173.7566\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 37343.8438 - mae: 173.0854\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 36572.8203 - mae: 172.3784\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 36615.8398 - mae: 171.6792\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 36615.6250 - mae: 171.0108\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35603.6328 - mae: 170.3066\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35743.3125 - mae: 169.6041\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35407.7344 - mae: 168.9456\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34789.7188 - mae: 168.2222\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 35182.0156 - mae: 167.5272\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 34464.5117 - mae: 166.8649\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 33462.1641 - mae: 166.1392\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 33544.0078 - mae: 165.4174\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 33425.2578 - mae: 164.7670\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 32978.0742 - mae: 164.0283\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 32526.5879 - mae: 163.3174\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 32720.9180 - mae: 162.6369\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 32599.4199 - mae: 161.9345\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 32366.9102 - mae: 161.2591\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 31916.5605 - mae: 160.7318\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 31946.2324 - mae: 159.8132\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 30963.3047 - mae: 159.1502\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 30716.4668 - mae: 158.4249\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30761.5059 - mae: 157.7144\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29988.8262 - mae: 156.9930\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 30109.7754 - mae: 156.2979\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29690.7930 - mae: 155.5867\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 29687.9805 - mae: 154.9761\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 28947.1523 - mae: 154.1947\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 29043.1328 - mae: 154.0406\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28613.2012 - mae: 152.7994\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 28825.6094 - mae: 152.0609\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 28300.5352 - mae: 151.5020\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27807.7480 - mae: 150.6387\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27459.9473 - mae: 150.0453\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27300.7168 - mae: 149.2288\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27555.6016 - mae: 148.5752\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 27328.3926 - mae: 147.9386\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26586.6387 - mae: 147.2889\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 26467.8887 - mae: 146.4757\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26478.5312 - mae: 145.8737\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25854.2949 - mae: 145.1300\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25129.9648 - mae: 144.3249\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 25882.6855 - mae: 143.7250\n",
      "7\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 27453.5273 - mae: 149.7315\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 27262.3984 - mae: 149.0648\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 26464.4668 - mae: 148.2307\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 26852.2227 - mae: 147.8805\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26254.5000 - mae: 146.8583\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26106.2676 - mae: 146.2726\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25806.0078 - mae: 145.3581\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 26226.9258 - mae: 144.9899\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 25641.4570 - mae: 143.9246\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24446.3594 - mae: 142.9813\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24681.2461 - mae: 142.2742\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24782.0020 - mae: 141.6331\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 24031.6406 - mae: 140.7501\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 24446.4121 - mae: 140.2152\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 24369.7734 - mae: 139.2786\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 22852.3438 - mae: 138.5652\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 22793.5547 - mae: 137.8183\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 23387.3516 - mae: 137.5277\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 23249.5469 - mae: 136.3615\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 22471.6836 - mae: 135.5763\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 22174.4102 - mae: 134.9524\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 21670.4648 - mae: 134.0926\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 21712.2305 - mae: 133.3954\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 22091.5840 - mae: 132.8201\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 21483.6582 - mae: 132.2139\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20852.4883 - mae: 131.2296\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20867.2891 - mae: 130.4434\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20352.6289 - mae: 129.6710\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20153.9668 - mae: 128.8915\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 20062.4062 - mae: 128.2689\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19973.3418 - mae: 127.9165\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 19529.4082 - mae: 126.7255\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 18783.6035 - mae: 126.0244\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 19223.1855 - mae: 125.3153\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 19403.5273 - mae: 124.5403\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 19854.3867 - mae: 125.4541\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 19358.0957 - mae: 123.7320\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 18055.9883 - mae: 122.3045\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 18476.4375 - mae: 122.0131\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 17619.0996 - mae: 121.7823\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 17237.4316 - mae: 120.6177\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 17020.8008 - mae: 119.6345\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 17527.7539 - mae: 120.5211\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 17055.3730 - mae: 118.6739\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 16879.8184 - mae: 117.8499\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 17079.0449 - mae: 117.1346\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 16353.7803 - mae: 116.7699\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 16142.1406 - mae: 115.3663\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 16158.6826 - mae: 115.9058\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 16298.6035 - mae: 115.0292\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 15323.6064 - mae: 113.3845\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15494.0635 - mae: 112.7248\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 15016.3281 - mae: 111.9842\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15479.1016 - mae: 112.0686\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15551.6484 - mae: 110.8701\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 14920.7773 - mae: 110.2313\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 15090.0254 - mae: 110.7112\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15259.2500 - mae: 109.2823\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 15705.0410 - mae: 112.3723\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 15620.8057 - mae: 111.8632\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14187.0117 - mae: 107.3015\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 13353.5703 - mae: 105.7519\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 13503.5254 - mae: 104.9794\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14055.5791 - mae: 106.1676\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 13034.0068 - mae: 103.9215\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 14032.9570 - mae: 104.3894\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14049.4834 - mae: 103.3952\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 13078.4043 - mae: 102.7031\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 12280.0146 - mae: 101.0717\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 12372.6807 - mae: 101.6921\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 12981.6328 - mae: 102.1968\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 12815.5195 - mae: 99.8990\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 11866.9502 - mae: 98.1955\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 12346.0430 - mae: 99.4085\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 12084.6230 - mae: 97.9257\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 12954.5361 - mae: 97.2828\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 12069.7432 - mae: 99.0013\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 10938.7979 - mae: 95.2620\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 11204.9365 - mae: 95.6917\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 12424.4199 - mae: 97.1829\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 10938.6816 - mae: 93.4902\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 11097.4482 - mae: 93.2020\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 10825.9785 - mae: 92.6486\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 10565.8945 - mae: 93.2269\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 10345.6309 - mae: 91.5953\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 10540.9824 - mae: 90.1414\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 10356.5146 - mae: 90.3148\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 10290.0879 - mae: 88.9377: 0s - loss: 10290.0879 - mae: 88.93\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9849.1729 - mae: 88.5327\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 10300.5361 - mae: 88.4000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9752.6719 - mae: 87.2875\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9509.7725 - mae: 86.4178\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9976.0527 - mae: 87.4358\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9148.7363 - mae: 85.0848\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9665.9092 - mae: 85.8570\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9445.7646 - mae: 85.2250\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9089.2441 - mae: 83.8989\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 10163.6055 - mae: 87.8054\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8752.7285 - mae: 82.4766\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9229.4473 - mae: 83.4115\n",
      "8\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8761.4482 - mae: 82.2596\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9196.1641 - mae: 84.0047\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8782.0752 - mae: 81.8515\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9056.4023 - mae: 82.6641\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9698.0225 - mae: 82.6377\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9258.2842 - mae: 82.5613\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8215.9346 - mae: 80.0321\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8014.8589 - mae: 78.1474\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8903.9629 - mae: 80.2425\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8535.7490 - mae: 79.7059\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8658.7051 - mae: 78.0874\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8394.8584 - mae: 78.2745\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8594.3418 - mae: 79.4010\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7424.7246 - mae: 75.4667\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8345.2158 - mae: 77.6910\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 8105.6626 - mae: 76.0904\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6762.9248 - mae: 72.2217\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7701.2402 - mae: 74.8446\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7607.3359 - mae: 74.1706\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7165.7910 - mae: 71.4803\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8440.0576 - mae: 74.5762\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7914.1572 - mae: 74.8058\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7107.0288 - mae: 70.5483\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6740.3032 - mae: 70.2944\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6993.3926 - mae: 71.3561\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6807.0425 - mae: 69.3580\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6557.2090 - mae: 68.7238\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6105.8418 - mae: 65.4347\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6726.2080 - mae: 67.2795\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7124.5161 - mae: 70.6114\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6548.3354 - mae: 67.8188\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6401.1470 - mae: 67.3301\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7262.5386 - mae: 69.0572\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5717.7646 - mae: 63.7636\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5776.3320 - mae: 62.8969\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6006.0303 - mae: 63.9321\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5627.5615 - mae: 62.1222\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6329.4473 - mae: 63.9236\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5618.9189 - mae: 63.3667\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5685.0273 - mae: 63.6090\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 5553.3955 - mae: 62.1889\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6011.8271 - mae: 62.2568\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5634.9756 - mae: 62.5684\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4942.4780 - mae: 59.1502\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 5911.9458 - mae: 62.0961\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5774.4229 - mae: 61.9196\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 5130.9927 - mae: 60.2780\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5189.1182 - mae: 59.4474\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 4573.9243 - mae: 55.9200\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4651.6509 - mae: 56.9747\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5391.7847 - mae: 58.3531\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 5935.4624 - mae: 63.8518\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4495.0620 - mae: 54.6853\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4655.1914 - mae: 54.8372\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5222.6108 - mae: 57.7474\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5282.1763 - mae: 57.3577\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 5205.3750 - mae: 57.8177\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4243.3174 - mae: 53.0138\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4753.1870 - mae: 56.1658\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3736.8269 - mae: 49.1685\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4837.3042 - mae: 57.0432\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4918.2441 - mae: 56.7617\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4415.3198 - mae: 52.6866\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4065.7134 - mae: 51.1129\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step - loss: 4907.6968 - mae: 59.1190\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4570.4233 - mae: 52.8683\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4086.7004 - mae: 50.0415\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 4414.4248 - mae: 53.1132\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4322.7769 - mae: 54.7531\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4636.6616 - mae: 54.0213\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3725.7852 - mae: 48.3780\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4861.8081 - mae: 55.9296\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3945.0718 - mae: 49.3615\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3278.0203 - mae: 46.2407\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4537.6191 - mae: 53.6654\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3703.1418 - mae: 49.2019\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3291.0942 - mae: 46.5889\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 4046.5820 - mae: 50.5702\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3736.3523 - mae: 47.4090\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 4274.7451 - mae: 52.3500\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3566.4702 - mae: 47.5817\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3859.6289 - mae: 47.9018\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3037.1997 - mae: 43.6907\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3490.2095 - mae: 47.0377\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3112.4753 - mae: 45.6552\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 3871.5696 - mae: 49.8317\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 4660.9644 - mae: 56.2937\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3111.2290 - mae: 44.4198\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3834.0359 - mae: 49.3470\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3806.0959 - mae: 48.2297\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3636.3416 - mae: 47.1777\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3552.8352 - mae: 46.9037\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3433.9629 - mae: 46.7439\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3822.0471 - mae: 49.4677\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 2814.7039 - mae: 40.6757\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3918.3496 - mae: 48.1780\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2970.4065 - mae: 43.0056\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3691.4143 - mae: 47.4676\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3035.1484 - mae: 43.9428\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3206.4695 - mae: 44.6614\n",
      "9\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2977.4148 - mae: 42.8109\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3202.0044 - mae: 43.7015\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3025.9629 - mae: 42.7400\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3781.2717 - mae: 48.6990\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2796.3315 - mae: 40.0153\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2450.5417 - mae: 39.0019\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2482.3999 - mae: 39.6737\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2935.4783 - mae: 42.5648\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3436.0938 - mae: 44.9699\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3267.3496 - mae: 45.3001\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3082.3188 - mae: 44.7557\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3137.3457 - mae: 45.2643\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3475.9297 - mae: 47.4061\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2865.4512 - mae: 41.0332\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2478.0330 - mae: 38.8421\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3124.1206 - mae: 42.8282\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2689.1006 - mae: 41.3420\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2370.3015 - mae: 37.2885\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2012.7754 - mae: 34.9422\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2574.6272 - mae: 39.6020\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3004.2915 - mae: 43.2887\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3337.9150 - mae: 43.7486\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 2946.4414 - mae: 41.0363\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2652.0044 - mae: 40.2723\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3279.0825 - mae: 44.3385\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2530.1763 - mae: 38.9151\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2197.4517 - mae: 37.2899\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3489.8167 - mae: 45.6407\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3248.8408 - mae: 44.2382\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 3516.6851 - mae: 47.6548\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2737.2839 - mae: 39.3436\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3014.7410 - mae: 43.8892\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2673.6335 - mae: 42.0944\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3117.1321 - mae: 43.5190\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2291.4214 - mae: 36.8520\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2700.4990 - mae: 40.7742\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2465.6157 - mae: 37.6613\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3336.8401 - mae: 43.8717\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2480.3313 - mae: 39.5837\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2668.2256 - mae: 41.7204\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2637.8716 - mae: 40.5605\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 2872.6521 - mae: 42.1092\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 3135.3359 - mae: 43.5253\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2901.1943 - mae: 42.7138\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2444.4893 - mae: 38.6358\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2588.9915 - mae: 38.7010\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 3162.1958 - mae: 43.7032\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2766.0151 - mae: 39.7376\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2319.6467 - mae: 37.3664\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2350.3513 - mae: 37.4632\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2903.8689 - mae: 43.4559\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2431.5061 - mae: 38.6601\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3475.4231 - mae: 47.8641\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2478.9778 - mae: 38.6471\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2276.7371 - mae: 38.3241\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2545.8442 - mae: 37.9930\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2240.7834 - mae: 37.3327\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2657.6641 - mae: 40.0488\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2382.5696 - mae: 38.3265\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2292.7388 - mae: 37.1764\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2421.1782 - mae: 38.6361\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2769.5298 - mae: 39.5428\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2820.5903 - mae: 41.3338\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2438.9526 - mae: 38.3956\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2230.3623 - mae: 37.3637\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2312.6216 - mae: 36.8671\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2093.0940 - mae: 36.3113\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2422.0984 - mae: 37.9227\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2624.8726 - mae: 38.9140\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2423.2646 - mae: 38.4961\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2374.6465 - mae: 38.2358\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1928.9449 - mae: 35.1603\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 3612.3518 - mae: 46.2328\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1919.5035 - mae: 33.8025\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 2535.3591 - mae: 39.9629\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3430.1306 - mae: 46.2962\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2730.8540 - mae: 41.2662\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2327.8862 - mae: 37.1092\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2457.8669 - mae: 38.1869\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2321.7534 - mae: 36.0906\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3384.1914 - mae: 44.9019\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2019.9493 - mae: 35.1969\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2216.8022 - mae: 36.8595\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2657.3745 - mae: 39.7718\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2408.7766 - mae: 37.1740\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1983.9353 - mae: 34.3308\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2718.4470 - mae: 40.7985\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2911.3301 - mae: 40.8502\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2358.9490 - mae: 36.8738\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1809.3230 - mae: 32.6257\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2394.1157 - mae: 38.8724\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2721.8950 - mae: 41.1930\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2208.5115 - mae: 36.8864\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2700.9414 - mae: 39.7109\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3046.4214 - mae: 41.1484\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2899.5315 - mae: 40.2971\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2210.1140 - mae: 37.5153\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2429.1025 - mae: 38.6625\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 3282.7581 - mae: 43.9873\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2439.8743 - mae: 38.6512\n",
      "10\n",
      "___________target network update___________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 12ms/step - loss: 255758.9724 - mae: 423.0661\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 269552.1774 - mae: 438.6572\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 252198.9210 - mae: 421.7629\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 262805.6691 - mae: 431.2841\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 248908.7316 - mae: 418.2447\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 253767.1369 - mae: 422.3111\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 252593.6673 - mae: 423.5634\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 276789.8493 - mae: 445.3789\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 253496.1719 - mae: 424.2105\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 250189.2610 - mae: 418.0296\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 257162.5607 - mae: 427.4424\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 258172.1048 - mae: 429.3311\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 252221.7996 - mae: 425.0513\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 261777.0956 - mae: 433.6492\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 241237.9963 - mae: 414.2037\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 264999.2702 - mae: 437.0572\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 264368.3888 - mae: 430.6585\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 257300.0699 - mae: 428.5108\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 257500.2730 - mae: 425.7779\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 253478.5809 - mae: 426.0788\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 242474.8943 - mae: 412.6648\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 254579.8125 - mae: 426.3624\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 254741.2840 - mae: 424.1703\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 250045.0938 - mae: 421.3242\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 247103.5119 - mae: 421.2501\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 262150.2877 - mae: 433.9545\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 248761.2123 - mae: 421.9041\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 246713.5846 - mae: 419.6787\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 263552.4697 - mae: 438.2195\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 250436.9697 - mae: 423.5137\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 243159.9062 - mae: 416.8053\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 245848.1195 - mae: 417.4759\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 243996.7757 - mae: 416.4779\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 250119.1195 - mae: 423.3201\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 253404.6774 - mae: 425.9995\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 263993.2647 - mae: 435.0211\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 242438.9127 - mae: 417.1987\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 247977.1103 - mae: 423.3842\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 236375.7243 - mae: 411.1991\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 236222.7914 - mae: 411.5370\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 249284.1544 - mae: 425.0391\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 246009.1204 - mae: 418.0876\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 245784.2619 - mae: 418.0353\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 238662.3217 - mae: 413.8202\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 241158.9614 - mae: 414.2372\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 249700.0873 - mae: 424.2329\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 244433.7914 - mae: 421.0838\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 258015.8061 - mae: 434.1138\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 247006.3888 - mae: 421.5775\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 234090.3088 - mae: 412.1308\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 250907.4954 - mae: 425.7221\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 251636.8640 - mae: 426.8365\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 259817.0772 - mae: 436.6118\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 236156.3070 - mae: 411.1212\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 249841.7298 - mae: 424.5781\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 232713.8483 - mae: 408.5451\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 247589.0331 - mae: 423.8486\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 237329.3235 - mae: 413.2934\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 245613.9596 - mae: 421.6307\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 245140.2711 - mae: 422.9826\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 244932.1765 - mae: 419.6765\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 225410.2353 - mae: 401.4950\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 254006.7868 - mae: 430.7376\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 236269.9991 - mae: 410.9535\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 241506.2767 - mae: 420.4054\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 235134.6884 - mae: 412.3324\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 223416.1618 - mae: 401.6735\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 232222.6801 - mae: 412.3829\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 238465.1471 - mae: 415.0271\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 236074.9697 - mae: 411.1622\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 237286.4945 - mae: 416.9531\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 232473.4154 - mae: 410.9002\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 224589.0542 - mae: 404.7000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 228560.2831 - mae: 406.2941\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 237120.6287 - mae: 417.1786\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 223938.3162 - mae: 404.4234\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 226838.3713 - mae: 406.3507\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 217556.1002 - mae: 397.4039\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 241688.5055 - mae: 418.5821\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 237535.1342 - mae: 418.7992\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 237575.2178 - mae: 416.4695\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 231357.0800 - mae: 408.7384\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 224836.5074 - mae: 404.8703\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 234293.6857 - mae: 416.3413\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 213062.7142 - mae: 392.5755\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 232796.6627 - mae: 413.9522\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 223559.7050 - mae: 401.3778\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 232243.7040 - mae: 412.5744\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 218924.4577 - mae: 401.5345\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 222502.6305 - mae: 404.1577\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 228963.0892 - mae: 410.1171\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 224182.3805 - mae: 406.2417\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 231586.2077 - mae: 409.5195\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 212321.7996 - mae: 395.1050\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 228551.7684 - mae: 411.2714\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 224807.4384 - mae: 406.3295\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 225742.7868 - mae: 410.0180\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 220099.3006 - mae: 399.6159\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 201045.0634 - mae: 383.8936\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 227645.1241 - mae: 408.1691\n",
      "11\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 235022.2344 - mae: 409.8599\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 234520.7500 - mae: 409.4135\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 233741.1250 - mae: 408.9614\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 233005.0312 - mae: 408.5020\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 232473.8281 - mae: 408.0400\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 231750.3438 - mae: 407.5742\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 231126.5938 - mae: 407.1116\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 230501.8750 - mae: 406.6418\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 229854.9688 - mae: 406.1696\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 229017.0156 - mae: 405.6927\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 228480.5000 - mae: 405.2137\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 227968.3125 - mae: 404.7344\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 227297.4688 - mae: 404.2519\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 226325.1406 - mae: 403.7643\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 225856.1094 - mae: 403.2756\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 225337.5000 - mae: 402.7864\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 224446.1406 - mae: 402.2868\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 224037.7188 - mae: 401.7852\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 223182.8750 - mae: 401.2881\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 222339.2031 - mae: 400.7875\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 221564.2188 - mae: 400.2816\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 221393.4062 - mae: 399.7679\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 220515.0156 - mae: 399.2605\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 219425.1250 - mae: 398.7485\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 219181.9688 - mae: 398.2337\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 218129.7344 - mae: 397.7137\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 217471.0625 - mae: 397.1951\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 216679.6094 - mae: 396.6732\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 216406.5312 - mae: 396.1437\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 215662.9844 - mae: 395.6145\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 214632.8125 - mae: 395.0806\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 214375.6250 - mae: 394.5470\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 213564.6406 - mae: 394.0095\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 212701.7500 - mae: 393.4687\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 211803.5312 - mae: 392.9252\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 211134.1562 - mae: 392.3796\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 210331.7188 - mae: 391.8310\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 210092.5312 - mae: 391.2817\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 209048.1250 - mae: 390.7347\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 208546.5312 - mae: 390.1774\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 207514.1406 - mae: 389.6201\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 207151.8750 - mae: 389.0590\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 205867.5781 - mae: 388.4954\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 205479.5312 - mae: 387.9296\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 204633.7656 - mae: 387.3617\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 204357.6250 - mae: 386.7907\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 203340.1406 - mae: 386.2160\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 202682.2188 - mae: 385.6469\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 201814.8281 - mae: 385.0721\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 200905.3281 - mae: 384.4879\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 200113.7188 - mae: 383.9054\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 199566.9844 - mae: 383.3277\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 199144.4219 - mae: 382.7406\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 197973.7969 - mae: 382.1545\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 197520.7344 - mae: 381.5653\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 196499.6406 - mae: 380.9721\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 196009.8438 - mae: 380.3722\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 195125.9219 - mae: 379.7716\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 194702.4062 - mae: 379.1749\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 193867.5781 - mae: 378.5757\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 193275.8594 - mae: 377.9758\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 192438.6562 - mae: 377.3700\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 191291.9062 - mae: 376.7580\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 191111.8438 - mae: 376.1965\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 191315.1719 - mae: 375.5391\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 190029.6250 - mae: 374.9355\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 188808.4531 - mae: 374.3232\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 188028.9688 - mae: 373.7023\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 187158.5312 - mae: 373.0787\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 186274.4531 - mae: 372.4573\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 185639.9688 - mae: 371.8322\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 185322.0469 - mae: 371.2048\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 184587.3125 - mae: 370.5799\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 183170.9844 - mae: 369.9484\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 182970.1719 - mae: 369.3130\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 182475.6562 - mae: 368.6778\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 181292.6250 - mae: 368.0377\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 180284.1094 - mae: 367.3965\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 180236.0312 - mae: 366.7538\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 179254.6719 - mae: 366.1133\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 179063.8281 - mae: 365.4747\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 178158.5312 - mae: 364.8216\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 177050.2812 - mae: 364.1701\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 176203.2344 - mae: 363.5243\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 175634.7500 - mae: 362.8647\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 174513.9688 - mae: 362.2166\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 173809.7812 - mae: 361.5622\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 173342.8438 - mae: 360.8954\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 173181.4062 - mae: 360.2403\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 171679.9531 - mae: 359.5722\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 170705.2500 - mae: 358.9049\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 169908.0156 - mae: 358.2588\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 169557.5312 - mae: 357.5871\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 168813.5781 - mae: 356.8947\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 167797.4375 - mae: 356.2245\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 167489.0938 - mae: 355.5892\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 166766.2500 - mae: 354.8789\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 165901.3438 - mae: 354.2059\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 164405.9688 - mae: 353.5189\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 164040.1719 - mae: 352.8339\n",
      "12\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 154075.5469 - mae: 344.9966\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 153189.0469 - mae: 344.3224\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 152675.5938 - mae: 343.6576\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 152019.5312 - mae: 342.9914\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 151866.2500 - mae: 342.3161\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 150873.6875 - mae: 341.6415\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 149760.5938 - mae: 340.9654\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 149942.7969 - mae: 340.2885\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 148733.0312 - mae: 339.6078\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 148109.9844 - mae: 338.9311\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 147391.7344 - mae: 338.2428\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 146187.2969 - mae: 337.5615\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 145444.2344 - mae: 336.8778\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 144899.3594 - mae: 336.1851\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 144520.8438 - mae: 335.5173\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 144009.2031 - mae: 334.8052\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 143261.9844 - mae: 334.1133\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 141823.2188 - mae: 333.4126\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 141857.8594 - mae: 332.7114\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 141683.1406 - mae: 332.0129\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 140526.0000 - mae: 331.3112\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 139318.2812 - mae: 330.6050\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 139192.3594 - mae: 329.8989\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 138925.2031 - mae: 329.1899\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 137278.6094 - mae: 328.4823\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 136917.7812 - mae: 327.7786\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 135751.7188 - mae: 327.1065\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 135334.3906 - mae: 326.3498\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 134854.7188 - mae: 325.6388\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 134692.4375 - mae: 324.9292\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 133187.3438 - mae: 324.1992\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 132766.4688 - mae: 323.4791\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 131620.9844 - mae: 322.7582\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 131529.7656 - mae: 322.0219\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 130892.9688 - mae: 321.3210\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 129889.5078 - mae: 320.5699\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 128464.8281 - mae: 319.8358\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 128757.2422 - mae: 319.1044\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 127283.0391 - mae: 318.3699\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 126958.8984 - mae: 317.6348\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 127025.1328 - mae: 316.8954\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 126689.8828 - mae: 316.1632\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 124898.9609 - mae: 315.4211\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 124707.0547 - mae: 314.6802\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 124296.8281 - mae: 313.9347\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 123312.7422 - mae: 313.2331\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 122504.6484 - mae: 312.4569\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 122329.5234 - mae: 311.7405\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 120902.5625 - mae: 310.9670\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 120301.4141 - mae: 310.2175\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 120559.5312 - mae: 309.4677\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 119573.6953 - mae: 308.7184\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 118502.1562 - mae: 307.9744\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 117476.5234 - mae: 307.2234\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 116423.2031 - mae: 306.4649\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 116497.6562 - mae: 305.7054\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 115582.9141 - mae: 304.9471\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 115282.8125 - mae: 304.1877\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 113755.4219 - mae: 303.4158\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 113666.3359 - mae: 302.6527\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 113245.1875 - mae: 301.8903\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 112446.5781 - mae: 301.1266\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 111597.4688 - mae: 300.3627\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step - loss: 111370.8828 - mae: 299.5993\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 110417.9453 - mae: 298.8200\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 110442.9766 - mae: 298.0494\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 110458.5156 - mae: 297.3109\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 108853.3594 - mae: 296.5653\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 107685.0625 - mae: 295.7346\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 107635.9141 - mae: 294.9580\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 107350.6953 - mae: 294.1781\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 106239.1172 - mae: 293.4049\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 105064.2891 - mae: 292.6310\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 104711.8047 - mae: 291.9154\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 103755.1797 - mae: 291.0651\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 103171.7891 - mae: 290.2945\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 102373.3594 - mae: 289.4909\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 102754.5156 - mae: 288.7202\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 101200.9453 - mae: 287.9077\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 100443.2188 - mae: 287.1262\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 99813.7656 - mae: 286.3454\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 99740.1797 - mae: 285.5402\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 99305.2109 - mae: 284.7557\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 98488.0703 - mae: 283.9610\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 98055.6719 - mae: 283.1586\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 97274.9531 - mae: 282.3615\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 96616.9453 - mae: 281.5613\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 97442.4531 - mae: 280.7694\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 96150.2734 - mae: 279.9770\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 94371.0078 - mae: 279.1713\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 95016.4766 - mae: 278.3786\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 94316.8750 - mae: 277.6734\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 92455.5156 - mae: 276.7732\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 93101.5391 - mae: 275.9627\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 91021.4062 - mae: 275.1567\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 92774.2656 - mae: 274.3586\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 90764.4688 - mae: 273.5454\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 89853.1172 - mae: 272.7334\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 88725.1719 - mae: 271.9256\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 89363.2109 - mae: 271.1122\n",
      "13\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 87274.0078 - mae: 272.9496\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 87767.0000 - mae: 272.1401\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 86253.4531 - mae: 271.3312\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 86453.5391 - mae: 270.5119\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 86378.8984 - mae: 269.7026\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 83753.7500 - mae: 268.8946\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 84181.4062 - mae: 268.0776\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 83420.0391 - mae: 267.2700\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 84450.9531 - mae: 266.4866\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 82352.7812 - mae: 265.6302\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 81750.9375 - mae: 264.8214\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 83573.8203 - mae: 264.0119\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 81469.9922 - mae: 263.1929\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 81413.0938 - mae: 262.3657\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 81118.9141 - mae: 261.5609\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 78902.5078 - mae: 260.7470\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 78522.7812 - mae: 259.9226\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 78365.4219 - mae: 259.1166\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 77193.3203 - mae: 258.2690\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 76215.4531 - mae: 257.4510\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 77523.5625 - mae: 256.6132\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 75783.2578 - mae: 255.7868\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 76527.0000 - mae: 254.9784\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 75290.1250 - mae: 254.1210\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 74721.6328 - mae: 253.3192\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 73859.9297 - mae: 252.4738\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 72692.4141 - mae: 251.6354\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 72411.2891 - mae: 250.8131\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 72289.3047 - mae: 249.9759\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 71828.3359 - mae: 249.1425\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 71111.6016 - mae: 248.2994\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 72304.4609 - mae: 247.4637\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 69800.7188 - mae: 246.6379\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 70432.6172 - mae: 245.8028\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 69841.1250 - mae: 244.9699\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 68301.2734 - mae: 244.1452\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 67435.5391 - mae: 243.3113\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 67531.6172 - mae: 242.4495\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 67998.6172 - mae: 241.6090\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 69349.0078 - mae: 240.9724\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 65891.1094 - mae: 239.9347\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 67619.3359 - mae: 239.1680\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 65655.0391 - mae: 238.2541\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 65169.2617 - mae: 237.4117\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 65241.4453 - mae: 236.6684\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 64777.1523 - mae: 235.7375\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 63793.6836 - mae: 234.9320\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 63460.1055 - mae: 234.1116\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 61569.7539 - mae: 233.2095\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 63457.3789 - mae: 232.4223\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 62907.6016 - mae: 231.5161\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 61352.3125 - mae: 230.6786\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 60010.7422 - mae: 229.8162\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 60533.5273 - mae: 229.0362\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 60469.9961 - mae: 228.1249\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 59705.5234 - mae: 227.2932\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 58993.2070 - mae: 226.4413\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 57806.7852 - mae: 225.5895\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 58533.3945 - mae: 224.7398\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 57525.6641 - mae: 223.8839\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 57056.2930 - mae: 223.1915\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 57396.0625 - mae: 222.3260\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 55785.5430 - mae: 221.3420\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 55930.7812 - mae: 220.5181\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 55055.2891 - mae: 219.7158\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 54754.2266 - mae: 218.8085\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 54042.8906 - mae: 217.9706\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 53995.5352 - mae: 217.1517\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 53910.5000 - mae: 216.2517\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 53242.4258 - mae: 215.4733\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 52503.8320 - mae: 214.5712\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 52234.7109 - mae: 213.6920\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 51536.7773 - mae: 212.8642\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 51614.8047 - mae: 211.9798\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 52674.8281 - mae: 211.3352\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 50334.5312 - mae: 210.5180\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 50915.2812 - mae: 209.6664\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 48782.4844 - mae: 208.5802\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 49045.5469 - mae: 207.7261\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 48008.8750 - mae: 206.8805\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 49447.9492 - mae: 206.3610\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 48539.7344 - mae: 205.2019\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 48168.4453 - mae: 204.3522\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 48711.3125 - mae: 203.5033\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 47795.2031 - mae: 202.7318\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 47765.8789 - mae: 202.6757\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 46927.0586 - mae: 200.9207\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 45928.2852 - mae: 200.0918\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 44986.1719 - mae: 199.2138\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 44627.3438 - mae: 198.3367\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 46514.1211 - mae: 197.4864\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 45731.8945 - mae: 197.3381\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 45543.6055 - mae: 196.1577\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 43450.6719 - mae: 194.9281\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 45509.3750 - mae: 195.7405\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 43360.9531 - mae: 193.2209\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 42734.6758 - mae: 192.5464\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 43139.7188 - mae: 193.0925\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 43150.9961 - mae: 190.7183\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 41582.5430 - mae: 189.8133\n",
      "14\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 38853.2344 - mae: 182.3648\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 39160.7539 - mae: 181.8280\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 39507.5234 - mae: 182.6211\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 37486.4805 - mae: 179.9332\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 37942.2188 - mae: 179.5564\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 36631.8164 - mae: 178.6643\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 37415.7461 - mae: 177.7703\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 37284.8867 - mae: 177.1388\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 34965.8516 - mae: 175.7042\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 36059.7852 - mae: 175.3857\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 35132.6406 - mae: 174.4929\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34825.4336 - mae: 173.4949\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34797.9453 - mae: 172.4969\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 35489.4141 - mae: 172.0694\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 35066.2656 - mae: 173.2382\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 33665.1133 - mae: 170.9280\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33485.0781 - mae: 169.5900\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 34406.8672 - mae: 170.0535\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 33139.4648 - mae: 168.0487\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32414.3418 - mae: 167.2747\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 34713.0391 - mae: 168.9261\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 33274.5938 - mae: 166.0993\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 32774.7969 - mae: 165.5040\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 14ms/step - loss: 31738.3574 - mae: 164.0643\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 32119.1973 - mae: 163.4243\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 32129.2305 - mae: 162.8212\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 31083.4980 - mae: 161.3104\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 32052.2637 - mae: 161.6194\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 30331.9395 - mae: 160.6362\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28505.2637 - mae: 158.4832\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28143.7539 - mae: 157.7208\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29582.1309 - mae: 158.5207\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 32775.0508 - mae: 161.2278\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 29945.7441 - mae: 157.4475\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28953.9434 - mae: 154.8323\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28253.8242 - mae: 154.4018\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 29522.7109 - mae: 153.4715\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 26966.2715 - mae: 152.2901\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28055.2246 - mae: 152.5402\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 29970.8301 - mae: 154.5002\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 27703.2129 - mae: 150.8163\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 25924.5508 - mae: 149.3885\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 28582.1816 - mae: 150.1277\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 27226.4141 - mae: 149.2336\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 25965.8340 - mae: 147.3004\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 27249.7188 - mae: 148.7372\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 27546.4551 - mae: 148.9866\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 26049.3730 - mae: 146.0877\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 25834.0156 - mae: 143.6911\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 25416.7793 - mae: 144.3065\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 24359.1953 - mae: 142.4134\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 24141.3105 - mae: 141.3826\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 25389.4648 - mae: 142.0631\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 24076.1406 - mae: 139.8443\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 23931.5449 - mae: 139.0732\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 25517.2227 - mae: 142.2356\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 24571.7051 - mae: 140.3832\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 23965.1973 - mae: 138.4957\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 23113.7578 - mae: 136.8573\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 22712.3066 - mae: 136.0594\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 22087.9375 - mae: 134.2644\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 23149.6289 - mae: 135.8381\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 22620.9121 - mae: 134.6865\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 22519.3496 - mae: 132.4513\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 21998.0527 - mae: 132.3237\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 21592.2109 - mae: 133.2465\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20782.7227 - mae: 130.4532\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 21456.3926 - mae: 129.4060\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 21543.3574 - mae: 133.2822\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 21049.3691 - mae: 127.4938\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 22173.1113 - mae: 131.3974\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 20515.5488 - mae: 129.2551\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 19445.1113 - mae: 126.2139\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 19245.7637 - mae: 124.5980\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 20665.9707 - mae: 128.3639\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 19858.8066 - mae: 124.8963\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 19706.3008 - mae: 123.7116\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 19229.0332 - mae: 124.0405\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 18038.0527 - mae: 120.3731: 0s - loss: 19673.5879 - mae: 123.\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 19483.4355 - mae: 123.6877\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17678.7305 - mae: 119.0068\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 17988.6582 - mae: 118.1679\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 19742.0918 - mae: 119.4486\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 20242.8203 - mae: 123.9839\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 20571.0918 - mae: 121.5846\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16282.4697 - mae: 115.0500\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 19681.7266 - mae: 120.6949\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 16852.5605 - mae: 113.3354\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17949.9434 - mae: 118.6882\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 17113.8105 - mae: 113.4108\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 17299.9102 - mae: 114.0165\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 16428.3223 - mae: 111.9678\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16166.8682 - mae: 111.9028\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 16424.4863 - mae: 112.7453\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16207.9980 - mae: 110.2461\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15568.2363 - mae: 108.3327\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 16540.5645 - mae: 108.5822\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14967.0586 - mae: 105.8896\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 14003.4033 - mae: 105.1379\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15530.6270 - mae: 108.8638\n",
      "15\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17507.3555 - mae: 115.4005\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16187.1191 - mae: 112.9013\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 18220.6387 - mae: 117.5379\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 16ms/step - loss: 17591.8223 - mae: 113.1675\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 19167.2363 - mae: 118.2012\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17076.7949 - mae: 112.0944\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 17781.1445 - mae: 113.3488\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15849.4756 - mae: 109.1992\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16350.3994 - mae: 110.1031\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 15895.7666 - mae: 109.0462\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14324.4121 - mae: 105.6341\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14507.2910 - mae: 105.1060\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 17316.2129 - mae: 112.6650\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 16968.4844 - mae: 107.6905\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14912.8662 - mae: 104.7613\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14570.5020 - mae: 102.7849\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 15495.9180 - mae: 104.76210s - loss: 18204.1348 - mae: 112.9\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 14139.2715 - mae: 103.1885\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14223.7002 - mae: 103.2922\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13681.2637 - mae: 100.9959\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14618.2900 - mae: 101.9467\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 12488.5195 - mae: 97.0497\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12897.0889 - mae: 97.4558\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 14095.4980 - mae: 99.6740\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 14146.4600 - mae: 101.5686\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12696.9014 - mae: 97.8694\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13260.2402 - mae: 95.9355\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13973.5283 - mae: 101.0792\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 14730.1943 - mae: 101.7600\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12224.1650 - mae: 94.9610\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 11647.6650 - mae: 93.2895\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 15111.0596 - mae: 99.1814\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12740.4307 - mae: 95.1651\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 12126.5059 - mae: 93.1548\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 13482.9326 - mae: 100.2719\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12853.1445 - mae: 91.8518\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13411.5947 - mae: 94.6297\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 13649.0293 - mae: 98.3416\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 12336.1602 - mae: 92.1523\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 11116.1494 - mae: 88.8921\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 11622.5742 - mae: 89.2943\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 11973.6641 - mae: 91.2351\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 9233.3066 - mae: 82.5166\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 13292.9834 - mae: 94.2563\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 11546.0469 - mae: 86.6821\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 11094.1533 - mae: 87.3628\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9191.1084 - mae: 80.6998\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 12701.5830 - mae: 88.1635\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9706.3789 - mae: 81.8918\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 10674.1416 - mae: 84.6334\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 10581.8389 - mae: 84.1627\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9282.5840 - mae: 80.6188\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 11751.4678 - mae: 91.6049\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9406.8926 - mae: 78.7799\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 10449.9824 - mae: 82.6779\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 10893.4619 - mae: 82.9134\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8996.6582 - mae: 79.8660\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 10241.8184 - mae: 80.5048\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 11609.6279 - mae: 86.3822\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 10305.0088 - mae: 82.5963\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8665.6670 - mae: 76.0507\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 11494.4658 - mae: 87.3850\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 8505.9482 - mae: 76.3720\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8391.2900 - mae: 75.0946\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9123.9189 - mae: 78.3278\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7649.5747 - mae: 71.2828\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8582.7227 - mae: 74.3925\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 9675.0078 - mae: 76.1786\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8373.0908 - mae: 72.4238\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 9190.4775 - mae: 75.8912\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9696.8857 - mae: 78.6299\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9128.7344 - mae: 76.7806\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9234.9297 - mae: 77.9727\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7411.5981 - mae: 69.6367\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6777.3887 - mae: 66.8370\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 9753.0684 - mae: 78.7714\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6750.2598 - mae: 67.8022\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6476.6436 - mae: 65.7128\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 9422.1699 - mae: 78.2806\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 8811.8945 - mae: 74.3336\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 8040.5176 - mae: 70.6391\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 9911.4238 - mae: 80.6114\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 7019.9214 - mae: 67.1641\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8147.8452 - mae: 71.0126\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 16ms/step - loss: 7421.8262 - mae: 69.7244\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8793.9824 - mae: 75.8174\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 7592.6152 - mae: 67.5006\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 8112.5737 - mae: 73.4155\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 6765.9800 - mae: 67.5433\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6467.2559 - mae: 63.9066\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 5996.6553 - mae: 61.7086\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 8744.7852 - mae: 73.8988\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6399.6265 - mae: 63.2019\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 6905.5518 - mae: 65.6685\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6969.5913 - mae: 65.7832\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6447.1211 - mae: 61.7163\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 6969.8931 - mae: 67.3969\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 6014.7983 - mae: 59.7383\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5942.7905 - mae: 61.5051\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 6585.5898 - mae: 61.5501\n",
      "16\n",
      "___________target network update___________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b8e5fffeaecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mvalue_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mvalue_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-5593e3409e64>\u001b[0m in \u001b[0;36mget_best\u001b[1;34m(self, state_current, target_pos, get_action)\u001b[0m\n\u001b[0;32m     49\u001b[0m             inputs = tf.constant([[state_current[0], state_current[1], \n\u001b[0;32m     50\u001b[0m                                target_pos[0], target_pos[1], action_0, action_1]])\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mvalue_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mvalue_new\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-5593e3409e64>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#         x = self.dense2(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m     outputs = nn.batch_normalization(inputs, _broadcast(mean),\n\u001b[0m\u001b[0;32m    892\u001b[0m                                      \u001b[0m_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                                      self.epsilon)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36mbatch_normalization\u001b[1;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     \u001b[1;31m# Note: tensorflow/contrib/quantize/python/fold_batch_norms.py depends on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m     \u001b[1;31m# the precise order of ops that are generated by the expression below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1563\u001b[1;33m     return x * math_ops.cast(inv, x.dtype) + math_ops.cast(\n\u001b[0m\u001b[0;32m   1564\u001b[0m         offset - mean * inv if offset is not None else -mean * inv, x.dtype)\n\u001b[0;32m   1565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6061\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6062\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6063\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6064\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[0;32m   6065\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "envir = environment()\n",
    "model = DQNet()\n",
    "model.save_weights(\"./predict_model_home_night\")\n",
    "model_ = DQNet()\n",
    "model_.load_weights(\"./predict_model_home_night\")\n",
    "model_.save_weights(\"./target_model_home_night\")\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "model_.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "            loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')\n",
    "\n",
    "mae_list = []\n",
    "up_step = -100\n",
    "\n",
    "for step in range(33):\n",
    "    \n",
    "    x_train, y_train = [], []\n",
    "    minibatch = GetMinibatch(1000, replay_memory)\n",
    "    for (i, mini) in enumerate(minibatch):\n",
    "        if mini[5] >= -10:\n",
    "            y_train.append(mini[5])\n",
    "        else:\n",
    "            value_ = model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False, is_training = True)\n",
    "            y_train.append(mini[5] + 0.99*value_)\n",
    "            \n",
    "        action_0 = 0.1 * (-1 + (mini[4] - 1)//3)\n",
    "        action_1 = 0.1 * (-1 + (mini[4] - 1) %3)\n",
    "        x_train.append([mini[0], mini[1], mini[2], mini[3], action_0, action_1])\n",
    "        \n",
    "    history = model.fit(np.array(x_train), np.array(y_train), batch_size = 64, epochs = 100)\n",
    "#     model.fit(np.array(x_train), np.array(y_train), callbacks=[LearningRateReducerCb(step)], epochs = 100)\n",
    "    model.save_weights(\"./predict_model_home_night\")\n",
    "    mae_list.append(history.history['mae'])\n",
    "    \n",
    "    print(step)\n",
    "    if (min(history.history['mae']) <= 30 or (step - up_step) >= 8):\n",
    "        print(\"___________target network update___________\")\n",
    "        up_step = step\n",
    "        model_.load_weights(\"./predict_model_home_night\")\n",
    "        model_.save_weights(\"./target_model_home_night\")\n",
    "        model = DQNet()\n",
    "        model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                      loss = tf.keras.losses.MeanSquaredError(), metrics = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ea95f710a0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(mae_list).reshape((-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[351.0, 307.0, 119.0, 537.0, 6.0, -323.88269481403296, 351.0, 311.0]\n"
     ]
    }
   ],
   "source": [
    "mini = replay_memory[0]\n",
    "print(mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-926.78394\n",
      "-909.78906\n",
      "-892.00653\n",
      "-920.48236\n",
      "-903.13666\n",
      "-884.99835\n",
      "-913.85394\n",
      "-896.1464\n",
      "-877.6412\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for at in range(1, 10):\n",
    "    action_0 = 0.1 * (-1 + (at - 1)//3)\n",
    "    action_1 = 0.1 * (-1 + (at - 1) %3)\n",
    "    print(model.call(inputs = tf.constant([[mini[0], mini[1], mini[2], mini[3], action_0, action_1]])).numpy()[0][0])\n",
    "print(model.get_best([mini[0], mini[1]], [mini[2], mini[3]], get_action = True, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1186.772290150947"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini[5] + 0.99*(model_.get_best([mini[6], mini[7]], [mini[2], mini[3]], get_action = False, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-891.37756, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.get_best([133.0, 527.0], [333.0, 321.0], get_action = False, is_training = True), \n",
    " model.get_best([133.0, 527.0], [333.0, 321.0], get_action = True, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21.674927\n",
      "-16.795517\n",
      "-13.68084\n",
      "-18.911213\n",
      "-14.16647\n",
      "-11.187223\n",
      "-15.7210655\n",
      "-11.1097355\n",
      "-8.264572\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for at in range(1, 10):\n",
    "    action_0 = 0.1 * (-1 + (at - 1)//3)\n",
    "    action_1 = 0.1 * (-1 + (at - 1) %3)\n",
    "    print(model.call(inputs = tf.constant([[274.0, 515.0, 274.0, 515.0, action_0, action_1]])).numpy()[0][0])\n",
    "print(model.get_best([274.0, 515.0], [274.0, 515.0], get_action = True, is_training = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "84ac1aa0e324239271716ea4bc0f1972974f6d8d50c2a2c3470023e155096e31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
